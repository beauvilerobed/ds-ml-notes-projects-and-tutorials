{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tutorial: Deep Learning in Python (Predict Wine Type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Keras tutorial introduces you to deep learning in python: learn to preprocess your data, model, evaluate and optimize neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest neural network is the **perceptron**, consists of a single neuron. It is a simple tree structure which\n",
    "has input nodes and a single output node, which is connected to each input node.\n",
    "\n",
    "1. Input nodes: Each input node is associated with a numerical value.\n",
    "2. Connections: Each connection that departs from the input node has a weight associated with it.\n",
    "3. All values and weights of the connection are brought together: \n",
    "$$\n",
    "y = f\\bigg(\\sum_{i=1}^D w_i * x_i\\bigg)\n",
    "$$\n",
    "4. This result will be the input for a transfer or **activation** function. The most intuitive way that one can think of\n",
    "it is by devising a system like the following:\n",
    "\n",
    "\\begin{dcases}\n",
    "    f(x) = 0 & x < 0 \\\\\n",
    "    f(x) = \\frac{1}{2} & x = 0 \\\\\n",
    "    f(x) = 1 & x > 0 \\\\\n",
    "\\end{dcases}\n",
    "\n",
    "Of course, this is discontinuous function. Because of this we choose a continuous variant, the sigmoid function.\n",
    "5. As a result, you have the output node, which is associated with the function (such as the sigmoid function) of the \n",
    "weighted sum of the input nodes.\n",
    "6. Lastly, the perceptron may have an additional parameter, called a bias, which you can consider as the weight associated\n",
    "with an additional input node that is permanently set to 1. The bias value is critical because it allows you to shift the\n",
    "activation function to the left or right, which can make a determine the success of your learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Networks of perceptrons are multi-layer perceptrons aslo known as **feed-foward neural networks**. These are more complex networks than\n",
    "the perceptron, as they consist of multiple neurons that are organized in layers. The number of layers in usually limited to two or\n",
    "three. Multi-layer perceptrons are often fully connected.\n",
    "\n",
    "Note that while the perceptron could only represent linear seperations between classes, the multi-layer perceptron overcomes that limitation\n",
    "and can also represent more complex decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Wine Types: Red or White?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "white = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep=';')\n",
    "red = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(white.info())\n",
    "print(red.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].hist(red.alcohol, 10, facecolor='red', alpha=0.5, label=\"Red wine\")\n",
    "ax[1].hist(white.alcohol, 10, facecolor='white', ec=\"black\", lw=0.5, alpha=0.5, label=\"White wine\")\n",
    "\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05, wspace=1)\n",
    "ax[0].set_ylim([0, 1000])\n",
    "ax[0].set_xlabel(\"Alcohol in % Vol\")\n",
    "ax[0].set_ylabel(\"Frequency\")\n",
    "ax[1].set_xlabel(\"Alcohol in % Vol\")\n",
    "ax[1].set_ylabel(\"Frequency\")\n",
    "ax[0].legend(loc='best')\n",
    "ax[1].legend(loc='best')\n",
    "fig.suptitle(\"Distribution of Alcohol in % Vol\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the image below, you see that the alcohol levels between the red and white wine are mostly the same:\n",
    "they have around 9% of alcohol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sulfates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "ax[0].scatter(red['quality'], red[\"sulphates\"], color=\"red\")\n",
    "ax[1].scatter(white['quality'], white['sulphates'], color=\"white\", edgecolors=\"black\", lw=0.5)\n",
    "\n",
    "ax[0].set_title(\"Red Wine\")\n",
    "ax[1].set_title(\"White Wine\")\n",
    "ax[0].set_xlabel(\"Quality\")\n",
    "ax[1].set_xlabel(\"Quality\")\n",
    "ax[0].set_ylabel(\"Sulphates\")\n",
    "ax[1].set_ylabel(\"Sulphates\")\n",
    "ax[0].set_xlim([0,10])\n",
    "ax[1].set_xlim([0,10])\n",
    "ax[0].set_ylim([0,2.5])\n",
    "ax[1].set_ylim([0,2.5])\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "fig.suptitle(\"Wine Quality by Amount of Sulphates\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the image below, the red wine seems to contain more sulfates than the white wine, which has \n",
    "fewer sulfates above $1g/dm^3$. For the white wine, there only seem to be a couple of exceptions that fall just\n",
    "above $1g/dm^3$, while this is definitely more for the red wines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(570)\n",
    "\n",
    "redlabels = np.unique(red['quality'])\n",
    "whitelabels = np.unique(white['quality'])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "redcolors = np.random.rand(6,4)\n",
    "whitecolors = np.append(redcolors, np.random.rand(1,4), axis=0)\n",
    "\n",
    "for i in range(len(redcolors)):\n",
    "    redy = red['alcohol'][red.quality == redlabels[i]]\n",
    "    redx = red['volatile acidity'][red.quality == redlabels[i]]\n",
    "    ax[0].scatter(redx, redy, c=redcolors[i])\n",
    "for i in range(len(whitecolors)):\n",
    "    whitey = white['alcohol'][white.quality == whitelabels[i]]\n",
    "    whitex = white['volatile acidity'][white.quality == whitelabels[i]]\n",
    "    ax[1].scatter(whitex, whitey, c=whitecolors[i])\n",
    "    \n",
    "ax[0].set_title(\"Red Wine\")\n",
    "ax[1].set_title(\"White Wine\")\n",
    "ax[0].set_xlim([0,1.7])\n",
    "ax[1].set_xlim([0,1.7])\n",
    "ax[0].set_ylim([5,15.5])\n",
    "ax[1].set_ylim([5,15.5])\n",
    "ax[0].set_xlabel(\"Volatile Acidity\")\n",
    "ax[0].set_ylabel(\"Alcohol\")\n",
    "ax[1].set_xlabel(\"Volatile Acidity\")\n",
    "ax[1].set_ylabel(\"Alcohol\") \n",
    "ax[0].legend(redlabels, loc='best', bbox_to_anchor=(1.3, 1))\n",
    "ax[1].legend(whitelabels, loc='best', bbox_to_anchor=(1.3, 1))\n",
    "fig.suptitle(\"Alcohol - Volatile Acidity\")\n",
    "fig.subplots_adjust(top=0.85, wspace=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the image above, you see that the levels that you have read about above especially hold for the white wine: most \n",
    "wines with label 8 have volatile acidity levels of 0.5 or below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red['type'] = 1\n",
    "white['type'] = 0\n",
    "\n",
    "wines = red.append(white, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "corr = wines.corr()\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some variables that correlate, such as **density** and **residual sugar**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = wines.iloc[:,0: 11]\n",
    "y = np.ravel(wines.type)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler1 = StandardScaler().fit(X_train)\n",
    "scaler2 = StandardScaler().fit(X_test)\n",
    "\n",
    "X_train = scaler1.transform(X_train)\n",
    "X_test = scaler2.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "\n",
    "model = Sequential()\n",
    "model.add (Dense(12, activation='relu', input_shape=(11,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.output_shape\n",
    "model.summary()\n",
    "model.get_config()\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data is somewhat imbalanced. The accuracy might just be reflecting the class distribution of the data\n",
    "because it'll just predict white since those observations are abundantly present!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
