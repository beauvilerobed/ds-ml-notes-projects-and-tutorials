{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data\n",
    "\n",
    "**Outcomes**\n",
    "- Be able to use string methods to clean data that comes as a string\n",
    "- Be able to drop missing data\n",
    "- Use cleaning methods to prepare and analyze a real dataset\n",
    "\n",
    "**Data**\n",
    "- Item information from about 3,000 Chipotle meals from about 1,800 Grubhub orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data\n",
    "For many data projects, a significant proportion of time is spent collecting and cleaning the data — not performing the analysis.\n",
    "This non-analysis work is often called “data cleaning”.\n",
    "pandas provides very powerful data cleaning tools, which we will demonstrate using the following dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"numbers\": [\"#23\", \"#24\", \"#18\", \"#14\", \"#12\", \"#10\", \"#35\"],\n",
    "                   \"nums\": [\"23\", \"24\", \"18\", \"14\", np.nan, \"XYZ\", \"35\"],\n",
    "                   \"colors\": [\"green\", \"red\", \"yellow\", \"orange\", \"purple\", \"blue\", \"pink\"],\n",
    "                   \"other_column\": [0, 1, 0, 2, 1, 0, 2]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would happen if we wanted to try and compute the mean of numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"numbers\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It throws an error!\n",
    "\n",
    "Can you figure out why?\n",
    "\n",
    "> Hint\n",
    ">\n",
    "> When looking at error messages, start at the very bottom.\n",
    "\n",
    "The final error says, `TypeError: Could not convert #23#24... to numeric`.\n",
    "\n",
    "# String Methods\n",
    "Our solution to the previous exercise was to remove the `#` by using the replace string method: `int(c2n.replace(\"#\", \"\"))`.\n",
    "One way to make this change to every element of a column would be to loop through all elements of the column and apply the desired string methods…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Iterate over all rows\n",
    "for row in df.iterrows():\n",
    "\n",
    "    # `iterrows` method produces a tuple with two elements...\n",
    "    # The first element is an index and the second is a Series with the data from that row\n",
    "    index_value, column_values = row\n",
    "\n",
    "    # Apply string method\n",
    "    clean_number = int(column_values[\"numbers\"].replace(\"#\", \"\"))\n",
    "\n",
    "    # The `at` method is very similar to the `loc` method, but it is specialized\n",
    "    # for accessing single elements at a time... We wanted to use it here to give\n",
    "    # the loop the best chance to beat a faster method which we show you next.\n",
    "    df.at[index_value, \"numbers_loop\"] = clean_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is fast for a small dataset like this, this method slows for larger datasets.\n",
    "One *significantly* faster (and easier) method is to apply a string method to an entire column of data.\n",
    "Most methods that are available to a Python string (we learned a few of them in the [strings lecture](https://datascience.quantecon.org/python_fundamentals/basics.html)) are also available to a pandas Series that has `dtype` object.\n",
    "We access them by doing `s.str.method_name` where `method_name` is the name of the method.\n",
    "When we apply the method to a Series, it is applied to all rows in the Series in one shot!\n",
    "Let’s redo our previous example using a pandas `.str` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# ~2x faster than loop... However, speed gain increases with size of DataFrame. The\n",
    "# speedup can be in the ballpark of ~100-500x faster for big DataFrames.\n",
    "# See appendix at the end of the lecture for an application on a larger DataFrame\n",
    "df[\"numbers_str\"] = df[\"numbers\"].str.replace(\"#\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `.str` to access almost any string method that works on normal strings. (See the [official documentation](https://pandas.pydata.org/pandas-docs/stable/text.html) for more information.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"colors\"].str.contains(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"colors\"].str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type Conversions\n",
    "In our example above, the `dtype` of the `numbers_str` column shows that pandas still treats it as a string even after we have removed the \"#\".\n",
    "We need to convert this column to numbers.\n",
    "The best way to do this is using the `pd.to_numeric` function.\n",
    "This method attempts to convert whatever is stored in a Series into numeric values\n",
    "For example, after the \"#\" removed, the numbers of column \"numbers\" are ready to be converted to actual numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"numbers_numeric\"] = pd.to_numeric(df[\"numbers_str\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert to other types well.\n",
    "Using the astype method, we can convert to any of the supported pandas dtypes (recall the [intro notebook](https://datascience.quantecon.org/pandas/intro.html)).\n",
    "Below are some examples. (Pay attention to the reported `dtype`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"numbers_numeric\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df[\"numbers_numeric\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Data\n",
    "Many datasets have missing data.\n",
    "In our example, we are missing an element from the \"nums\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find missing data by using the isnull method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to know whether particular rows or columns have any missing data.\n",
    "To do this we can use the .any method on the boolean DataFrame `df.isnull()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many approaches have been developed to deal with missing data, but the two most commonly used (and the corresponding DataFrame method) are:\n",
    "\n",
    "- Exclusion: Ignore any data that is missing (`.dropna`).\n",
    "- Imputation: Compute “predicted” values for the data that is missing (`.fillna`).\n",
    "\n",
    "For the advantages and disadvantages of these (and other) approaches, consider reading the [Wikipedia article](https://en.wikipedia.org/wiki/Missing_data).\n",
    "\n",
    "For now, let’s see some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows containing a missing observation\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the missing values with a specific value\n",
    "df.fillna(value=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the _next_ valid observation to fill the missing data\n",
    "df.bfill() # in new versions of pandas, bfill will directly fill missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the _previous_ valid observation to fill missing data\n",
    "df.ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see more examples of dealing with missing data in future chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study\n",
    "We will now use data from an [article](https://www.nytimes.com/interactive/2015/02/17/upshot/what-do-people-actually-order-at-chipotle.html) written by The Upshot at the NYTimes.\n",
    "\n",
    "This data has order information from almost 2,000 Chipotle orders and includes information on what was ordered and how much it cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://datascience.quantecon.org/assets/data/chipotle_raw.csv.zip\"\n",
    "chipotle = pd.read_csv(url)\n",
    "chipotle.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Performance of `.str` Methods\n",
    "Let’s repeat the “remove the #” example from above, but this time on a much larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test = pd.DataFrame({\"floats\": np.round(100*np.random.rand(100000), 2)})\n",
    "test[\"strings\"] = test[\"floats\"].astype(str) + \"%\"\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for row in test.iterrows():\n",
    "    index_value, column_values = row\n",
    "    clean_number = column_values[\"strings\"].replace(\"%\", \"\")\n",
    "    test.at[index_value, \"numbers_loop\"] = clean_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test[\"numbers_str_method\"] = test[\"strings\"].str.replace(\"%\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"numbers_str_method\"].equals(test[\"numbers_loop\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got the exact same result in a fraction of the time!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
