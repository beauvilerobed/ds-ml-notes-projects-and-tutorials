{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means From Scratch\n",
    "\n",
    "## The Basic Idea\n",
    "\n",
    "Given a dataset where each observed example has a set of features, but has\n",
    "**no** labels. What can we do? \n",
    "\n",
    "One task we can perform on a data set with no labels is to find groups of data in our dataset\n",
    "which are similar to one another -- called clusters.\n",
    "\n",
    "K Means is a clustering algorithm. It stores k centroids that it uses to define clusters. A point\n",
    "is considered to be in a particular cluster if it is closer to that cluster's centroid that any other\n",
    "centroid.\n",
    "\n",
    "## The Algorithm\n",
    "\n",
    "We are given a training set $\\{ x_1, x_2,..., x_m \\}$, and want to group the data into a few\n",
    "cohesive \"clusters\". \n",
    "\n",
    "Here, we are given feature vectors for each data point $x_i \\in\\mathbb{R}^n$\n",
    "as usual. Our goal is to classify k centroids with a label $c_i$ for each datapoint.\n",
    "\n",
    "1. Initialize **cluster centroids** $\\mu_1, \\mu_2,...,\\mu_k\\in\\mathbb{R}^n$ randomly.\n",
    "2. Repeat until convergence:\n",
    "\n",
    "$$\n",
    "\\text{Set } c_i := arg \\min_{j} \\Vert x_i - \\mu_j\\Vert ^2 \\text{ }\\text{  for every i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Set } \\mu_j := \\frac{\\sum_{i=1}^m \\chi_{\\{c_i = j\\}}x_i}{\\sum_{i=1}^m \\chi_{\\{c_i = j\\}}} \\text{ }\\text{  for every j}\n",
    "$$\n",
    "\n",
    "We can write the algorithm using 5 key steps:\n",
    "1. randomly select centroids.\n",
    "2. calculate distance at each point and assign each point to cluster.\n",
    "3. calculate average of the assigned point.\n",
    "4. move centroid to the new position.\n",
    "5. repeat steps 2-4 until cluster assignment is not changed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of steps from 1 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets._samples_generator import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITERATIONS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1\n",
    "def get_random_centroids(dataset, k):\n",
    "    temp = []\n",
    "    n_features = len(dataset[0])\n",
    "    for i in range(n_features):\n",
    "        min_col_val = np.min(dataset[:, i])\n",
    "        max_col_val = np.max(dataset[:, i])\n",
    "        rand_pos = np.random.randint(0.8 * min_col_val, 0.8 * max_col_val , size=k)\n",
    "        temp.append(rand_pos)\n",
    "\n",
    "    c_positions = np.array(temp).T\n",
    "\n",
    "    return c_positions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "\n",
    "def should_stop(old_centroids, centroids, iterations):\n",
    "    if iterations > MAX_ITERATIONS:\n",
    "        return True\n",
    "    return np.array_equal(old_centroids, centroids)\n",
    "\n",
    "def kmeans(dataset, centroids, k):\n",
    "    n = len(dataset)\n",
    "    clusters = np.zeros(n)\n",
    "    iterations = 0\n",
    "    old_centroids = None\n",
    "\n",
    "    # step 5\n",
    "    while not should_stop(old_centroids, centroids, iterations):\n",
    "        for i in range(n):\n",
    "            # step 2\n",
    "            distances = [get_dist(dataset[i],c) for c in centroids]\n",
    "            cluster = np.argmin(distances)\n",
    "            clusters[i] = cluster\n",
    "            \n",
    "        old_centroids = deepcopy(centroids)\n",
    "\n",
    "        # step 3-4\n",
    "        for j in range(k):\n",
    "            points = [dataset[i] for i in range(n) if clusters[i] == j]\n",
    "            centroids[j] = np.mean(points, axis=0)\n",
    "        iterations += 1\n",
    "\n",
    "    return centroids, clusters\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Make Some Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_centroids = 4\n",
    "n_features = 2\n",
    "dataset, _ = make_blobs(n_samples=5000, centers=num_of_centroids, n_features=n_features, random_state=195)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dataset[:,0], dataset[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_positions = get_random_centroids(dataset, num_of_centroids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dataset[:, 0], dataset[:, 1])\n",
    "plt.scatter(c_positions[:, 0], c_positions[:, 1], marker='*', s=300, c='orange')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clusters, clusters_points = kmeans(dataset, c_positions, num_of_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dataset[:, 0], dataset[:, 1])\n",
    "plt.scatter(new_clusters[:, 0], new_clusters[:, 1], marker='*', s=300, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_in_col(x, number_of_clusters, clusters_points, new_clusters):\n",
    "    for i in range(number_of_clusters):\n",
    "        col_points = np.array([x[n] for n in range(len(x)) if clusters_points[n] == i])\n",
    "        plt.scatter(col_points[:, 0], col_points[:, 1], s=10)\n",
    "    plt.scatter(new_clusters[:, 0], new_clusters[:, 1], marker='*', s=300, c='w')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_in_col(dataset, num_of_centroids, clusters_points, new_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Maximization (EM)\n",
    "### K-Means is a hard EM version of Gaussian Naive Bayes with unit variance\n",
    "\n",
    "We consider a Naive Bayes model with:  \n",
    "- Class variable $C \\in \\{1, 2, \\dots, k\\}$  \n",
    "- Feature variables $f_i \\in \\mathbb{R}$  with $i\\in\\{1,2,..., d\\}$\n",
    "\n",
    "Instead of a discrete table, assume $f_i$ is Gaussian given $C$:  \n",
    "$$\n",
    "P(f_i = x \\mid C=c) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\Big(-\\frac{(x-\\mu_{c,i})^2}{2}\\Big) \\sim \\mathcal{N}(\\mu_{c,i},1)\n",
    "$$\n",
    "\n",
    "The goal is to estimate $P(C \\mid \\mathbf{f})$. Using Bayes' rule and assuming independence between each feature variable:  \n",
    "$$\n",
    "P(C=c \\mid \\mathbf{f}) \\propto P(C=c) \\prod_i P(f_i \\mid C=c)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood Estimation (with hidden variables)\n",
    "\n",
    "Suppose we have $n$ observations $\\mathbf{x}_1, \\dots, \\mathbf{x}_n \\in \\R^d$ but unknown classes $C_1, \\dots, C_n \\in \\R$.  \n",
    "The complete-data likelihood is:  \n",
    "$$\n",
    "L(\\mu) = \\prod_{j=1}^n \\prod_{c=1}^k \\prod_{i=1}^d P(f_i = x_{j,i} \\mid C=c)^{\\mathbf{1}\\{C_j=c\\}}\n",
    "$$  \n",
    "where $\\mathbf{1}\\{C_j=c\\}$ is 1 if observation $j$ belongs to class $c$, 0 otherwise.\n",
    "\n",
    "Taking log-likelihood:  \n",
    "$$\n",
    "\\ell(\\mu) = \\sum_{j=1}^n \\sum_{c=1}^k \\mathbf{1}\\{C_j=c\\} \\sum_{i=1}^d \\log P(f_i = x_{j,i} \\mid C=c)\n",
    "$$\n",
    "\n",
    "Plug in Gaussian form:  \n",
    "$$\n",
    "\\ell(\\mu) = \\sum_{j=1}^n \\sum_{c=1}^k \\mathbf{1}\\{C_j=c\\} \\sum_{i=1}^d \\Big[-\\frac{1}{2}(x_{j,i}-\\mu_{c,i})^2 + \\text{const}\\Big]\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM Algorithm\n",
    "\n",
    "Since $C_j$ is unknown, EM iteratively estimates it:\n",
    "\n",
    "**E-step:** Compute expected value of $\\mathbf{1}\\{C_j=c\\}$ given current $\\mu^{(t)}$:  \n",
    "$$\n",
    "\\gamma_{j,c} = \\mathbb{E}[\\mathbf{1}\\{C_j=c\\} \\mid x_j, \\mu^{(t)}] \n",
    "= \\frac{P(C_j=c) \\prod_i P(x_{j,i} \\mid C_j = c, \\mu^{(t)})}{\\sum_{c'=1}^k P(C_j=c') \\prod_i P(x_{j,i} \\mid C_j = c', \\mu^{(t)})}\n",
    "$$\n",
    "\n",
    "**M-step:** Maximize expected log-likelihood w.r.t. $\\mu$:  \n",
    "$$\n",
    "\\mu^{(t+1)}_{c,i} = \\frac{\\sum_{j=1}^n \\gamma_{j,c} x_{j,i}}{\\sum_{j=1}^n \\gamma_{j,c}}\n",
    "$$\n",
    "\n",
    "This is the weighted mean of points assigned to class $c$.\n",
    "\n",
    "Repeat E and M until convergence.  \n",
    "\n",
    "### Special Case: K-Means\n",
    "\n",
    "If $P(C=c) = 1/k$ and we make a hard assignment ($\\gamma_{j,c} \\in \\{0,1\\}$), then:  \n",
    "\n",
    "- E-step: assign $x_j$ to nearest $\\mu_c$ (Euclidean distance)  \n",
    "- M-step: $\\mu_c$ = mean of assigned points  \n",
    "\n",
    "Hence K-Means is a hard EM version of Gaussian Naive Bayes with unit variance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
