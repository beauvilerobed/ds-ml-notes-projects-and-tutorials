{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicollinearity in Regression Analysis: Problems, Detection, and Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multicollinearity occurs when independent variables in a regression model are correlated. If the degree of correlation between variables is high enough, it can cause problems when you fit the model and interpret the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is Multicollinearity a Potential Problem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the goal of regression analysis is to isolate the relationship between each indpendent variable and the dependent variable.\n",
    "The regression coefficient represents the mean change in the dependent variable for each 1 unit change in an independent variable provided\n",
    "*hold all of the other independent variables constant*.\n",
    "\n",
    "When independent variables are correlated, then changes in one variable are associated with shifts in another variable. Then stronger the \n",
    "correlation the harder it is to change one variable without changing another.\n",
    "\n",
    "There are two basic kinds of multicollinearity:\n",
    "- **Structural multicollinearity**: Occurs when we create a model term using other terms. E.g. if you square term X to model curvature then X \n",
    "is correlated to $X^2$.\n",
    "- **Data Multicollinearity**: Present in data itself rather than being an artifact of our model. Oberservational experiments are more likely \n",
    "to exhibit this kind of multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Problmes Do Multicollinearity Cause?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The coefficients become very sensitive to small changes in the model.\n",
    "- It reduces the precision of the estimated coefficients. May not be able to trust the p-values to identify independent variables that are statistically significant.\n",
    "\n",
    "You don't feel like you know the actual effect of each variable! This makes it difficult to specify the correct model and to justify the  model if many of your p-values\n",
    "are not statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do I Have to Fix Multicollinearity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The need to reduce multicollinearity depends on its severity and you primary goal for your regression model. Keep in mind:\n",
    "1. The severity of the problems increase with the degree of the multicollinearity. So if you have moderate multicollinearity,\n",
    "you may not needt to resolve it.\n",
    "2. It affects only specific independent variables that are correlated. If multicollinearity is not present in independent variables\n",
    "you are interested in, you may not need to resolve it.\n",
    "3. Multicollinearity affects the coefficients and p-values, but it does not influence the predictions, precision of the predictions, \n",
    "and the goodness-of-fit statistics. If your main goal is to make predictions without understanding the role of each independent variable,\n",
    "you don't need to reduce severe multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for Multicollinearity with Variance Inflation Factors (VIF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical software calculates a VIF for each independent variable. VIFs start at 1, indicating no correlation between other indepenent variable. It has no uppper limit.\n",
    "VIFs between 1 and 5 suggest that there is moderate correlation, but not severe enough to warrant corrective measures. VIFs greater than 5 are critical enough where the \n",
    "coefficients are poorly estimated, and the p-values are questionable.\n",
    "\n",
    "Assesing VIFs is particularly important for observational studies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicollinearity Example: Predicting Bone Density in the Femur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example will show you how to detect multicollinearity as well as illustrate its effects.\n",
    "It will also show you how to remove structural multicollinearity.\n",
    "\n",
    "We'll use regression analysis to model the relationship between the independent variables(physical activity, body fat percentage,\n",
    "weight, and the interaction between weight and body fat) and the dependent variable (bone mineral density of the femoral neck)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for Implementing VIF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run a multiple regression. \n",
    "2. Calculate the VIF factors.\n",
    "3. Inspect the factors for each predictor variable, if the VIF is between 5-10, multicolinearity is likely present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Femoral_Neck  Fat_percentage  Weight_kg  Activity  Fat_percentage_S  \\\n",
      "0         0.934            25.3  52.163126   3508.44         -3.265217   \n",
      "1         0.888            29.3  61.801965   2773.54          0.734783   \n",
      "2         0.933            37.7  93.440034   1738.97          9.134783   \n",
      "3         0.757            32.8  59.874197   1665.29          4.234783   \n",
      "4         1.031            24.6  50.348756   3982.95         -3.965217   \n",
      "\n",
      "    Weight_S   Activity_S  \n",
      "0  -1.765066   946.450435  \n",
      "1   7.873772   211.550435  \n",
      "2  39.511842  -823.019565  \n",
      "3   5.946005  -896.699565  \n",
      "4  -3.579436  1420.960435  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('MulticollinearityExample.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Femoral_Neck  Fat_percentage  Weight_kg  Activity\n",
      "0         0.934            25.3  52.163126   3508.44\n",
      "1         0.888            29.3  61.801965   2773.54\n",
      "2         0.933            37.7  93.440034   1738.97\n",
      "3         0.757            32.8  59.874197   1665.29\n",
      "4         1.031            24.6  50.348756   3982.95\n"
     ]
    }
   ],
   "source": [
    "data = data[['Femoral_Neck',  'Fat_percentage',  'Weight_kg',  'Activity']]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after addition of new colulmn\n",
      "   Femoral_Neck  Fat_percentage  Weight_kg  Activity  Fat_Weight_kg\n",
      "0         0.934            25.3  52.163126   3508.44    1319.727088\n",
      "1         0.888            29.3  61.801965   2773.54    1810.797560\n",
      "2         0.933            37.7  93.440034   1738.97    3522.689297\n",
      "3         0.757            32.8  59.874197   1665.29    1963.873655\n",
      "4         1.031            24.6  50.348756   3982.95    1238.579407\n"
     ]
    }
   ],
   "source": [
    "data[\"Fat_Weight_kg\"] = data.apply(\n",
    "    lambda row: row[\"Fat_percentage\"]*row[\"Weight_kg\"], axis=1\n",
    ")\n",
    "\n",
    "print(\"DataFrame after addition of new colulmn\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices(\"Femoral_Neck ~ Fat_percentage+Weight_kg+Activity+Fat_Weight_kg\", data=data, return_type='dataframe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          VIF        variable\n",
      "0  321.088504       Intercept\n",
      "1   14.931555  Fat_percentage\n",
      "2   33.948375       Weight_kg\n",
      "3    1.053005        Activity\n",
      "4   75.059251   Fat_Weight_kg\n"
     ]
    }
   ],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif['variable'] = X.columns\n",
    "\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results show what Weight, Activity, and the interaction between them are statistically significant. The perctent body fat is not statistically significant. However, the VIFs\n",
    "indicate that our model has severe multicollinearity for some of the independent variables.\n",
    "\n",
    "Notice that Activity has a VIF near 1, which shows that multicollinearity does not affect it and we can trust the coefficient and p-value with no further action.\n",
    "\n",
    "Additionally, at least some of the multicollinearity in our model is the structural type. The term Fat_Weight_kg is the product of body fat and weight. Clearly, there is a correlation between the interaction term and both of the main effect terms.\n",
    "The VIFs relfect these relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Center the Independt Variable to Reduce Structural Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our model, the interaction term is at least partially repsonsible for the high VIFs, since these terms\n",
    "include the main effects.\n",
    "\n",
    "Centering the variables (standardizing the variables) by subtracting the mean. This process involves calculating\n",
    "the mean for each continous independent variable and then subtracting the mean from all observed values of that \n",
    "variable.\n",
    "\n",
    "The advantage of just subtracting the mean is that the interpretation of the coefficients remains the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with Centered Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Femoral_Neck  Fat_percentage  Weight_kg  Activity  Fat_percentage_S  \\\n",
      "0         0.934            25.3  52.163126   3508.44         -3.265217   \n",
      "1         0.888            29.3  61.801965   2773.54          0.734783   \n",
      "2         0.933            37.7  93.440034   1738.97          9.134783   \n",
      "3         0.757            32.8  59.874197   1665.29          4.234783   \n",
      "4         1.031            24.6  50.348756   3982.95         -3.965217   \n",
      "\n",
      "    Weight_S   Activity_S  \n",
      "0  -1.765066   946.450435  \n",
      "1   7.873772   211.550435  \n",
      "2  39.511842  -823.019565  \n",
      "3   5.946005  -896.699565  \n",
      "4  -3.579436  1420.960435  \n"
     ]
    }
   ],
   "source": [
    "c_data = pd.read_csv('MulticollinearityExample.csv')\n",
    "print(c_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Femoral_Neck  Fat_percentage_S   Weight_S   Activity_S\n",
      "0         0.934         -3.265217  -1.765066   946.450435\n",
      "1         0.888          0.734783   7.873772   211.550435\n",
      "2         0.933          9.134783  39.511842  -823.019565\n",
      "3         0.757          4.234783   5.946005  -896.699565\n",
      "4         1.031         -3.965217  -3.579436  1420.960435\n"
     ]
    }
   ],
   "source": [
    "c_data = c_data[['Femoral_Neck',  'Fat_percentage_S',  'Weight_S',  'Activity_S']]\n",
    "print(c_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after addition of new colulmn\n",
      "   Femoral_Neck  Fat_percentage_S   Weight_S   Activity_S  Fat_Weight_kg_S\n",
      "0         0.934         -3.265217  -1.765066   946.450435         5.763324\n",
      "1         0.888          0.734783   7.873772   211.550435         5.785511\n",
      "2         0.933          9.134783  39.511842  -823.019565       360.932090\n",
      "3         0.757          4.234783   5.946005  -896.699565        25.180037\n",
      "4         1.031         -3.965217  -3.579436  1420.960435        14.193241\n"
     ]
    }
   ],
   "source": [
    "c_data[\"Fat_Weight_kg_S\"] = c_data.apply(\n",
    "    lambda row: row[\"Fat_percentage_S\"]*row[\"Weight_S\"], axis=1\n",
    ")\n",
    "\n",
    "print(\"DataFrame after addition of new colulmn\")\n",
    "print(c_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_y, c_X = dmatrices(\"Femoral_Neck ~ Fat_percentage_S+Weight_S+Activity_S+Fat_Weight_kg_S\", data=c_data, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        VIF          variable\n",
      "0  1.753396         Intercept\n",
      "1  3.323870  Fat_percentage_S\n",
      "2  4.745648          Weight_S\n",
      "3  1.053005        Activity_S\n",
      "4  1.991063   Fat_Weight_kg_S\n"
     ]
    }
   ],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['VIF'] = [variance_inflation_factor(c_X.values, i) for i in range(c_X.shape[1])]\n",
    "vif['variable'] = c_X.columns\n",
    "\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that all VIFs are less than 5. By removing the stuctural multicollinearity, we can see that there is some multicollinearity in our data, but\n",
    "it is not severe enough to warrant further corrective measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Regression Models to Reveal Multicollinearity Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Femoral_Neck   R-squared:                       0.562\n",
      "Model:                            OLS   Adj. R-squared:                  0.542\n",
      "Method:                 Least Squares   F-statistic:                     27.95\n",
      "Date:                Wed, 09 Feb 2022   Prob (F-statistic):           6.24e-15\n",
      "Time:                        11:45:47   Log-Likelihood:                 116.01\n",
      "No. Observations:                  92   AIC:                            -222.0\n",
      "Df Residuals:                      87   BIC:                            -209.4\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          0.1549      0.132      1.176      0.243      -0.107       0.417\n",
      "Fat_percentage     0.0056      0.004      1.363      0.176      -0.003       0.014\n",
      "Weight_kg          0.0145      0.003      5.073      0.000       0.009       0.020\n",
      "Activity        2.238e-05   7.28e-06      3.075      0.003    7.92e-06    3.68e-05\n",
      "Fat_Weight_kg     -0.0002   7.39e-05     -2.898      0.005      -0.000   -6.73e-05\n",
      "==============================================================================\n",
      "Omnibus:                        4.307   Durbin-Watson:                   2.035\n",
      "Prob(Omnibus):                  0.116   Jarque-Bera (JB):                3.849\n",
      "Skew:                           0.331   Prob(JB):                        0.146\n",
      "Kurtosis:                       3.752   Cond. No.                     5.70e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.7e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           Femoral_Neck   R-squared:                       0.562\n",
      "Model:                            OLS   Adj. R-squared:                  0.542\n",
      "Method:                 Least Squares   F-statistic:                     27.95\n",
      "Date:                Wed, 09 Feb 2022   Prob (F-statistic):           6.24e-15\n",
      "Time:                        11:46:03   Log-Likelihood:                 116.01\n",
      "No. Observations:                  92   AIC:                            -222.0\n",
      "Df Residuals:                      87   BIC:                            -209.4\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept            0.8216      0.010     84.403      0.000       0.802       0.841\n",
      "Fat_percentage_S    -0.0060      0.002     -3.103      0.003      -0.010      -0.002\n",
      "Weight_S             0.0083      0.001      7.829      0.000       0.006       0.010\n",
      "Activity_S        2.238e-05   7.28e-06      3.075      0.003    7.92e-06    3.68e-05\n",
      "Fat_Weight_kg_S     -0.0002   7.39e-05     -2.898      0.005      -0.000   -6.73e-05\n",
      "==============================================================================\n",
      "Omnibus:                        4.307   Durbin-Watson:                   2.035\n",
      "Prob(Omnibus):                  0.116   Jarque-Bera (JB):                3.849\n",
      "Skew:                           0.331   Prob(JB):                        0.146\n",
      "Kurtosis:                       3.752   Cond. No.                     1.38e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.38e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "c_X2 = sm.add_constant(c_X)\n",
    "c_est = sm.OLS(c_y, c_X2)\n",
    "c_est2 = c_est.fit()\n",
    "print(c_est2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first independent variable we'll look at is Activity. This variable was the only to have\n",
    "almost no multicollinearity in the first models. Compare the Activity coefficients and p-values between the\n",
    "two models and you'll see that they are the same(coefficient = 0.000022, p-value = 0.003). This illustrates how only\n",
    "the variables that are highly correlated are affected by its problems.\n",
    "\n",
    "Let's look at the variables that had high VIFs in the first model. The standard error of the coefficient measures\n",
    "the precision of the estimates. Lower values indicates more precise estimates. The standard errors in the second model\n",
    "are lower for both fat percentage and weights. Additionally, fat percentage is significant in the second model even though\n",
    "it wasn't in the first model. Not only that, but the coefficient sign for fat percentage has changed from positive to negative!\n",
    "\n",
    "The lower percision, switched signs, and a lack of statistical significance are typical problems associated with multicollinearity.\n",
    "\n",
    "Now, take a look at the OLS Regression Results of both models. You'll notice that the standard error of the regression, R-squared,\n",
    "adjusted R-squared, and predicted R-squared are all identical. Multicollinearity doesn't affect the predictions or goodness-to-fit.\n",
    "If you just want to make predictions, the model with severe multicollinearity is just as good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Deal with Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you have severe multicollinearity in your data and you find that you must deal with it?\n",
    "The answer isn't always clear but potential solutions include the following:\n",
    "- Remove some of the highly correlated independent variables.\n",
    "- Linearly combine the independent variables, such as adding them together.\n",
    "- Perform an analysis designed for highly correlated variables (e.g. PCA or Partial least squares regression).\n",
    "- LASSO and Ridge regression are advanced forms of regression analysis that can handle multicollinearity.\n",
    "\n",
    "Remember that all of these have downsides. If you can accept less precise coefficients, or a regression model with \n",
    "high R-squared but hardly any statistically significant variables, then not doing anything about the multicollinearity might \n",
    "be the best solution."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
