{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuitive and Visual Explanation on the differences between L1 and L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The L1 and L2 regularization are widely used methods to control the model complexity and restrict over-fitting.\n",
    "There are some interesting comparisons between the L1 and L2 regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why we need regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use linear regression as an example. Given a linear model to predict Y\n",
    "$$\n",
    "y \\approx \\hat{y} = a_0 + a_1 x_1 + \\cdots + a_n x_n\n",
    "$$\n",
    "\n",
    "where $a_i$ are the estimated coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that\n",
    "1. The observed Y has some random noise in it.\n",
    "2. For observed Ys, the more variables we use, the more complex model we will build, and the better estimation we will have\n",
    "smaller MSE) to approximate observed Ys, including **approximating Ys random noise part**.\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y_i})^2\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
