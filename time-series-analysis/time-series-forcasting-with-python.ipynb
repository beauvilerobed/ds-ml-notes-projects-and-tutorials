{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0ae86eb",
   "metadata": {},
   "source": [
    "# Time Series Forcasting w/ Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c5208",
   "metadata": {},
   "source": [
    "## Content\n",
    "- Time series analysis\n",
    "    - ACF plot\n",
    "    - PACF plot\n",
    "    - Time seriees decomposition\n",
    "- Statistical tests\n",
    "    - ADF test - Test for stationarity\n",
    "    - Ljung-Box test - Residuals analysis\n",
    "    - Granger causality - Multivariate forecasting\n",
    "- Forcasting - Statistical models\n",
    "    - Moving average model - MA(q)\n",
    "    - Autoregressive model - AR(q)\n",
    "    - ARMA(p,q)\n",
    "    - ARIMA(p,d,q)\n",
    "    - SARIMA(p,d,q)(P,D,Q)$_m$\n",
    "    - SARIMAX\n",
    "    - VARMAX\n",
    "    - BATS and TBATS\n",
    "    - Exponential smoothing\n",
    "- Forcasting - Deep learning models\n",
    "    - Deep neural network (DNN)\n",
    "    - Long short-term memory - LSTM\n",
    "    - Convolutional neural network - CNN\n",
    "    - Autoregressive deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bd33d9",
   "metadata": {},
   "source": [
    "## Time series analysis\n",
    "\n",
    "### ACF plot\n",
    "\n",
    "The autocorrelation function (ACF) plot shows the autocorrelation coefficients as a function of the lag.\n",
    "\n",
    "Example use case:\n",
    "- Use it to determine the order q of a stationary MA(q) process\n",
    "- A stationary MA(q) process has significant coefficients up until lag q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ddb618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# Parameters\n",
    "n = 500     # Number of observations\n",
    "q = 3       # MA order\n",
    "\n",
    "# Generate white noise\n",
    "white_noise = np.random.standard_normal(n)\n",
    "\n",
    "# Define MA coefficients\n",
    "thetas = np.array([1]+list(range(2,2+q)))\n",
    "\n",
    "# Generate MA(q) time series\n",
    "ma_series = np.array([\n",
    "    sum(white_noise[i - j] * thetas[j] for j in range(q+1) if i - j >= 0)\n",
    "    for i in range(n)\n",
    "])\n",
    "\n",
    "# Plot the autocorrelation function (ACF)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plot_acf(ma_series, lags=40)\n",
    "plt.title(f\"Autocorrelation Function of MA({q}) Process\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc05fcb",
   "metadata": {},
   "source": [
    "### PACF plot\n",
    "\n",
    "The partial autocorrelation function (PACF) plot shows the partial autocorrelation coefficients as a function of the lag.\n",
    "\n",
    "Example use case:\n",
    "- Use it to determine the order p of a stationary AR(p) process\n",
    "- A stationary AR(p) process has significant coefficients up until lag p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e44b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "# Parameters\n",
    "n = 500     # Number of observations\n",
    "p = 3       # AR order\n",
    "\n",
    "# Generate white noise\n",
    "white_noise = np.random.standard_normal(n)\n",
    "\n",
    "# Define AR coefficients\n",
    "def generate_stable_polynomial(p, radius_min=0.5, radius_max=0.95):\n",
    "    \"\"\"\n",
    "    Generate a polynomial of degree p with all roots inside the unit circle (|z| < 1).\n",
    "    This ensures no root lies on |z| = 1.\n",
    "    \n",
    "    Parameters:\n",
    "        p (int): Order of the polynomial\n",
    "        radius_min (float): Minimum modulus of roots (to avoid very small values)\n",
    "        radius_max (float): Maximum modulus of roots (< 1 to avoid unit circle)\n",
    "\n",
    "    Returns:\n",
    "        coeffs (np.ndarray): Polynomial coefficients\n",
    "        roots (np.ndarray): Roots of the polynomial\n",
    "    \"\"\"\n",
    "    # Generate random complex roots inside the unit circle (|z| < 1)\n",
    "    angles = np.random.uniform(0, 2 * np.pi, p)\n",
    "    radii = np.random.uniform(radius_min, radius_max, p)\n",
    "    roots = radii * np.exp(1j * angles)\n",
    "\n",
    "    # Get polynomial coefficients from roots\n",
    "    coeffs = np.poly(roots).real  # Use .real to discard negligible imaginary part due to numerical error\n",
    "\n",
    "    return coeffs, roots\n",
    "\n",
    "p = 5\n",
    "coeffs, roots = generate_stable_polynomial(p)\n",
    "\n",
    "phis = coeffs\n",
    "\n",
    "# Initialize time series with zeros (extra p values for warm-up)\n",
    "ar_series = np.zeros(n)\n",
    "\n",
    "# Generate AR(p) time series\n",
    "for i in range(n):\n",
    "    ar_series[i] = white_noise[i] + sum(ar_series[i - j] * phis[j] if i - j >= 0 else 0 for j in range(p))\n",
    "\n",
    "# Plot the partial autocorrelation function (PACF)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plot_pacf(ar_series)\n",
    "plt.title(f\"Partial Autocorrelation Function of AR({p}) Process\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d973a2f",
   "metadata": {},
   "source": [
    "### Time series decomposition\n",
    "Separate the series into 3 components: trend, seasonality, and residuals\n",
    "- Trend: long-term changes in the series\n",
    "- Seasonality: periodical variations in the series\n",
    "- Residuals: what is not explained by trend and seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13162bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# m is the frequency of data (i.e., how many observations per season)\n",
    "m = 5\n",
    "\n",
    "n = 500\n",
    "\n",
    "t = np.arange(1, n + 1)\n",
    "\n",
    "# Generate series\n",
    "white_noise = np.random.standard_normal(n)\n",
    "trend = 1 + 0.05 * t\n",
    "seasonal = 2 * np.cos(np.pi * t / 5) + 3 * np.sin(np.pi * t / 3)\n",
    "\n",
    "series = trend + seasonal + white_noise\n",
    "\n",
    "# Perform STL decomposition\n",
    "decomp = STL(series, period=m).fit()\n",
    "\n",
    "# Plot the results\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=4, ncols=1, sharex=True, figsize=(10, 8))\n",
    "\n",
    "ax1.plot(decomp.observed)\n",
    "ax1.set_ylabel('Observed')\n",
    "\n",
    "ax2.plot(decomp.trend)\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "ax3.plot(decomp.seasonal)\n",
    "ax3.set_ylabel('Seasonal')\n",
    "\n",
    "ax4.plot(decomp.resid)\n",
    "ax4.set_ylabel('Residuals')\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7155ce7",
   "metadata": {},
   "source": [
    "## Statistical tests\n",
    "\n",
    "### ADF test – Test for stationarity\n",
    "A series is stationary it its **mean**, **variance**, and **autocorrelation** are constant over time. Test for stationarity with augmented Dickey-Fuller (ADF) test.\n",
    "- Null hypothesis: a unit root is present (i.e., the series is not stationary)\n",
    "- We want a p-value < 0.05\n",
    "\n",
    "> Notes: \n",
    "\n",
    "> The null hypothesis of the Augmented Dickey-Fuller is that there is a unit\n",
    "root, with the alternative that there is no unit root. If the pvalue is\n",
    "above a critical size, then we cannot reject that there is a unit root.\n",
    "\n",
    "> The p-values are obtained through regression surface approximation from\n",
    "MacKinnon 1994, but using the updated 2010 tables. If the p-value is close\n",
    "to significant, then the critical values should be used to judge whether\n",
    "to reject the null.\n",
    "\n",
    "> The autolag option and maxlag for it are described in Greene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a984c387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# m is the frequency of data (i.e., how many observations per season)\n",
    "m = 5\n",
    "\n",
    "n = 500\n",
    "\n",
    "t = np.arange(1, n + 1)\n",
    "\n",
    "# Generate series\n",
    "white_noise = np.random.standard_normal(n)\n",
    "trend = 1 + 0.05 * t\n",
    "seasonal = 2 * np.cos(np.pi * t / 5) + 3 * np.sin(np.pi * t / 3)\n",
    "\n",
    "series = trend + seasonal + white_noise\n",
    "\n",
    "\n",
    "adf_test_stat, pvalue, usedlag, nobs, crit_val, icbest = adfuller(series)\n",
    "print(f\"adf_test_stat: {adf_test_stat}, \\\n",
    "      \\n pvalue: {pvalue}, \\\n",
    "      \\n usedlag: {usedlag}, \\\n",
    "      \\n nobs: {nobs}, \\\n",
    "      \\n crit_val: {crit_val}, \\\n",
    "      \\n icbest: {icbest}\")\n",
    "\n",
    "if pvalue < .05:\n",
    "      print('We have a stationary process')\n",
    "else: \n",
    "      print('We have a non-stationary process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12825928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Parameters\n",
    "n = 500     # Number of observations\n",
    "q = 3       # MA order\n",
    "\n",
    "# Generate white noise\n",
    "white_noise = np.random.standard_normal(n)\n",
    "\n",
    "# Define MA coefficients (e.g., θ1=2.0, θ2=3.0, θ3=4.0)\n",
    "thetas = np.array([1]+list(range(2,2+q)))\n",
    "\n",
    "# Generate MA(q) time series\n",
    "ma_series = np.array([\n",
    "    sum(white_noise[i - j] * thetas[j] for j in range(q+1) if i - j >= 0)\n",
    "    for i in range(n)\n",
    "])\n",
    "\n",
    "\n",
    "adf_test_stat, pvalue, usedlag, nobs, crit_val, icbest = adfuller(ma_series)\n",
    "print(f\"adf_test_stat: {adf_test_stat}, \\\n",
    "      \\n pvalue: {pvalue}, \\\n",
    "      \\n usedlag: {usedlag}, \\\n",
    "      \\n nobs: {nobs}, \\\n",
    "      \\n crit_val: {crit_val}, \\\n",
    "      \\n icbest: {icbest}\")\n",
    "\n",
    "if pvalue < .05:\n",
    "      print('We have a stationary process')\n",
    "else: \n",
    "      print('We have a non-stationary process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8784c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "\n",
    "# Parameters\n",
    "n = 500     # Number of observations\n",
    "p = 3       # AR order\n",
    "\n",
    "# Generate white noise\n",
    "white_noise = np.random.standard_normal(n)\n",
    "\n",
    "# Define AR coefficients\n",
    "def generate_stable_polynomial(p, radius_min=0.5, radius_max=0.95):\n",
    "    \"\"\"\n",
    "    Generate a polynomial of degree p with all roots inside the unit circle (|z| < 1).\n",
    "    This ensures no root lies on |z| = 1.\n",
    "    \n",
    "    Parameters:\n",
    "        p (int): Order of the polynomial\n",
    "        radius_min (float): Minimum modulus of roots (to avoid very small values)\n",
    "        radius_max (float): Maximum modulus of roots (< 1 to avoid unit circle)\n",
    "\n",
    "    Returns:\n",
    "        coeffs (np.ndarray): Polynomial coefficients\n",
    "        roots (np.ndarray): Roots of the polynomial\n",
    "    \"\"\"\n",
    "    # Generate random complex roots inside the unit circle (|z| < 1)\n",
    "    angles = np.random.uniform(0, 2 * np.pi, p)\n",
    "    radii = np.random.uniform(radius_min, radius_max, p)\n",
    "    roots = radii * np.exp(1j * angles)\n",
    "\n",
    "    # Get polynomial coefficients from roots\n",
    "    coeffs = np.poly(roots).real  # Use .real to discard negligible imaginary part due to numerical error\n",
    "\n",
    "    return coeffs, roots\n",
    "\n",
    "coeffs, roots = generate_stable_polynomial(p)\n",
    "\n",
    "phis = coeffs\n",
    "\n",
    "# Initialize time series with zeros (extra p values for warm-up)\n",
    "ar_series = np.zeros(n)\n",
    "\n",
    "# Generate AR(p) time series\n",
    "for i in range(n):\n",
    "    ar_series[i] = white_noise[i] + sum(ar_series[i - j] * phis[j] if i - j >= 0 else 0 for j in range(p))\n",
    "\n",
    "adf_test_stat, pvalue, usedlag, nobs, crit_val, icbest = adfuller(ar_series)\n",
    "print(f\"adf_test_stat: {adf_test_stat}, \\\n",
    "      \\n pvalue: {pvalue}, \\\n",
    "      \\n usedlag: {usedlag}, \\\n",
    "      \\n nobs: {nobs}, \\\n",
    "      \\n crit_val: {crit_val}, \\\n",
    "      \\n icbest: {icbest}\")\n",
    "\n",
    "if pvalue < .05:\n",
    "      print('We have a stationary process')\n",
    "else: \n",
    "      print('We have a non-stationary process')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3e544f",
   "metadata": {},
   "source": [
    "\n",
    "Note: to make a series stationary, use differencing.\n",
    "- n = 1: difference between consecutive timesteps\n",
    "- n = 4: difference between values 4 timesteps apart\n",
    "Differencing removes n data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b025bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# m is the frequency of data (i.e., how many observations per season)\n",
    "m = 5\n",
    "\n",
    "n = 500\n",
    "\n",
    "t = np.arange(1, n + 1)\n",
    "\n",
    "# Generate series\n",
    "white_noise = np.random.standard_normal(n)\n",
    "trend = 1 + 0.05 * t\n",
    "seasonal = 2 * np.cos(np.pi * t / 5) + 3 * np.sin(np.pi * t / 3)\n",
    "\n",
    "series = trend + seasonal + white_noise\n",
    "\n",
    "diff_1_series = np.diff(series, n=1)\n",
    "diff_4_series = np.diff(series, n=4)\n",
    "\n",
    "adf_test_stat, pvalue, usedlag, nobs, crit_val, icbest = adfuller(diff_1_series)\n",
    "print(f\"diff_1_series\\\n",
    "      \\n adf_test_stat: {adf_test_stat}, \\\n",
    "      \\n pvalue: {pvalue}, \\\n",
    "      \\n usedlag: {usedlag}, \\\n",
    "      \\n nobs: {nobs}, \\\n",
    "      \\n crit_val: {crit_val}, \\\n",
    "      \\n icbest: {icbest}\")\n",
    "\n",
    "if pvalue < .05:\n",
    "      print('We have a stationary process')\n",
    "else: \n",
    "      print('We have a non-stationary process')\n",
    "\n",
    "\n",
    "adf_test_stat, pvalue, usedlag, nobs, crit_val, icbest = adfuller(diff_4_series)\n",
    "print(f\"\\n diff_4_series\\\n",
    "      \\n adf_test_stat: {adf_test_stat}, \\\n",
    "      \\n pvalue: {pvalue}, \\\n",
    "      \\n usedlag: {usedlag}, \\\n",
    "      \\n nobs: {nobs}, \\\n",
    "      \\n crit_val: {crit_val}, \\\n",
    "      \\n icbest: {icbest}\")\n",
    "\n",
    "if pvalue < .05:\n",
    "      print('We have a stationary process')\n",
    "else: \n",
    "      print('We have a non-stationary process')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254a040",
   "metadata": {},
   "source": [
    "### Ljung-Box test – Residuals analysis\n",
    "Used to determine if the autocorrelation of a group of data is significantly different from 0. Use it on the residuals to check if they are independent.\n",
    "- Null hypothesis: the data is independently distributed (i.e., there is no autocorrelation)\n",
    "- We want a p-value > 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f20149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "\n",
    "# Parameters\n",
    "n = 500  # Number of observations\n",
    "\n",
    "# Generate white noise\n",
    "white_noise = np.random.standard_normal(n)\n",
    "\n",
    "res = ARIMA(white_noise).fit()\n",
    "\n",
    "# Ljung-Box test\n",
    "results = acorr_ljungbox(res.resid, lags=[10], return_df=True)\n",
    "\n",
    "# Interpretation\n",
    "if results['lb_pvalue'].iloc[-1] > 0.05:\n",
    "    print(\"The data appears to be independently distributed (no significant autocorrelation).\")\n",
    "else:\n",
    "    print(\"Evidence of autocorrelation found (reject H0 at 5% level).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb38bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "\n",
    "# Parameters\n",
    "n = 500     # Number of observations\n",
    "p = 3       # AR order\n",
    "\n",
    "# Generate white noise\n",
    "white_noise = np.random.standard_normal(n)\n",
    "\n",
    "# Define AR coefficients\n",
    "def generate_stable_polynomial(p, radius_min=0.5, radius_max=0.95):\n",
    "    \"\"\"\n",
    "    Generate a polynomial of degree p with all roots inside the unit circle (|z| < 1).\n",
    "    This ensures no root lies on |z| = 1.\n",
    "    \n",
    "    Parameters:\n",
    "        p (int): Order of the polynomial\n",
    "        radius_min (float): Minimum modulus of roots (to avoid very small values)\n",
    "        radius_max (float): Maximum modulus of roots (< 1 to avoid unit circle)\n",
    "\n",
    "    Returns:\n",
    "        coeffs (np.ndarray): Polynomial coefficients\n",
    "        roots (np.ndarray): Roots of the polynomial\n",
    "    \"\"\"\n",
    "    # Generate random complex roots inside the unit circle (|z| < 1)\n",
    "    angles = np.random.uniform(0, 2 * np.pi, p)\n",
    "    radii = np.random.uniform(radius_min, radius_max, p)\n",
    "    roots = radii * np.exp(1j * angles)\n",
    "\n",
    "    # Get polynomial coefficients from roots\n",
    "    coeffs = np.poly(roots).real  # Use .real to discard negligible imaginary part due to numerical error\n",
    "\n",
    "    return coeffs, roots\n",
    "\n",
    "coeffs, roots = generate_stable_polynomial(p)\n",
    "\n",
    "phis = coeffs\n",
    "\n",
    "# Initialize time series with zeros (extra p values for warm-up)\n",
    "ar_series = np.zeros(n)\n",
    "\n",
    "# Generate AR(p) time series\n",
    "for i in range(n):\n",
    "    ar_series[i] = white_noise[i] + sum(ar_series[i - j] * phis[j] if i - j >= 0 else 0 for j in range(p))\n",
    "\n",
    "res = ARIMA(ar_series).fit()\n",
    "\n",
    "# Ljung-Box test\n",
    "results = acorr_ljungbox(res.resid, lags=[10], return_df=True)\n",
    "\n",
    "# Interpretation\n",
    "if results['lb_pvalue'].iloc[-1] > 0.05:\n",
    "    print(\"The data appears to be independently distributed (no significant autocorrelation).\")\n",
    "else:\n",
    "    print(\"Evidence of autocorrelation found (reject H0 at 5% level).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484cb923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "\n",
    "# Parameters\n",
    "n = 500     # Number of observations\n",
    "q = 3       # MA order\n",
    "\n",
    "# Generate white noise\n",
    "white_noise = np.random.standard_normal(n)\n",
    "\n",
    "# Define MA coefficients\n",
    "thetas = np.array([1]+list(range(2,2+q)))\n",
    "\n",
    "# Generate MA(q) time series\n",
    "ma_series = np.array([\n",
    "    sum(white_noise[i - j] * thetas[j] for j in range(q+1) if i - j >= 0)\n",
    "    for i in range(n)\n",
    "])\n",
    "\n",
    "res = ARIMA(ma_series).fit()\n",
    "\n",
    "# Ljung-Box test\n",
    "results = acorr_ljungbox(res.resid, lags=[10], return_df=True)\n",
    "\n",
    "# Interpretation\n",
    "if results['lb_pvalue'].iloc[-1] > 0.05:\n",
    "    print(\"The data appears to be independently distributed (no significant autocorrelation).\")\n",
    "else:\n",
    "    print(\"Evidence of autocorrelation found (reject H0 at 5% level).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffa1692",
   "metadata": {},
   "source": [
    "## Forecasting – Statistical models\n",
    "\n",
    "### Moving average model – MA(q)\n",
    "\n",
    "The moving average model: the current value depends on the mean of the series, the current error term, and past error terms.\n",
    "- Denoted as MA(q) where q is the order\n",
    "- Use ACF plot to find q\n",
    "- Assumes stationarity. Use only on stationary data\n",
    "\n",
    "**Equation**\n",
    "$$\n",
    "y_t = \\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1} + \\theta_2\\epsilon_{t-2} + \\cdots + \\theta_q\\epsilon_{t-q}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc4f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Simulated stationary data: white noise\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "n = 500     # Number of observations\n",
    "q = 5       # MA order\n",
    "\n",
    "# Generate white noise\n",
    "white_noise = np.random.standard_normal(n)\n",
    "\n",
    "# Define MA coefficients\n",
    "thetas = np.array([1]+list(range(2,2+q)))\n",
    "\n",
    "# Generate MA(q) time series\n",
    "ma_series = np.array([\n",
    "    sum(white_noise[i - j] * thetas[j] for j in range(q+1) if i - j >= 0)\n",
    "    for i in range(n)\n",
    "])\n",
    "\n",
    "# Convert to pandas Series\n",
    "date_range = pd.date_range(start='2020-01-01', periods=n, freq='d')\n",
    "series = pd.Series(ma_series, index=date_range)\n",
    "\n",
    "split = int(series.shape[0] * .96)\n",
    "\n",
    "# Train-test split\n",
    "train = series[:split]\n",
    "test = series[split:]\n",
    "\n",
    "# Fit MA model (ARIMA with p=0, d=0)\n",
    "model = ARIMA(train, order=(0, 0, q))  # MA(q) model\n",
    "results = model.fit()\n",
    "\n",
    "# Forecast\n",
    "forecast = results.get_forecast(steps=len(test))\n",
    "predicted_mean = forecast.predicted_mean\n",
    "conf_int = forecast.conf_int()\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(series, label='Actual')\n",
    "plt.plot(predicted_mean, label='Forecast', color='red')\n",
    "plt.fill_between(predicted_mean.index, conf_int.iloc[:, 0], conf_int.iloc[:, 1], color='pink', alpha=0.3)\n",
    "plt.axvline(test.index[0], color='gray', linestyle='--', label='Forecast Start')\n",
    "plt.title('MA Forecast on Stationary Series')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c94051",
   "metadata": {},
   "source": [
    "### Autoregressive model – AR(p)\n",
    "\n",
    "The autoregressive model is a regression against itself. This means that the present value depends on past values.\n",
    "- Denoted as AR(p) where p is the order\n",
    "- Use PACF to find p\n",
    "- Assumes stationarity. Use only on stationary data\n",
    "\n",
    "**Equation**\n",
    "$$\n",
    "y_t = C + \\phi_1y_{t-1} + \\phi_2y_{t-2} + \\cdots + \\phi_qy_{t-q} + \\epsilon_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ecd892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Simulated stationary data: white noise\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "n = 500     # Number of observations\n",
    "p = 5       # AR order\n",
    "\n",
    "# Generate white noise\n",
    "white_noise = np.random.standard_normal(n)\n",
    "\n",
    "# Define AR coefficients\n",
    "def generate_stable_polynomial(p, radius_min=0.5, radius_max=0.95):\n",
    "    \"\"\"\n",
    "    Generate a polynomial of degree p with all roots inside the unit circle (|z| < 1).\n",
    "    This ensures no root lies on |z| = 1.\n",
    "    \n",
    "    Parameters:\n",
    "        p (int): Order of the polynomial\n",
    "        radius_min (float): Minimum modulus of roots (to avoid very small values)\n",
    "        radius_max (float): Maximum modulus of roots (< 1 to avoid unit circle)\n",
    "\n",
    "    Returns:\n",
    "        coeffs (np.ndarray): Polynomial coefficients\n",
    "        roots (np.ndarray): Roots of the polynomial\n",
    "    \"\"\"\n",
    "    # Generate random complex roots inside the unit circle (|z| < 1)\n",
    "    angles = np.random.uniform(0, 2 * np.pi, p)\n",
    "    radii = np.random.uniform(radius_min, radius_max, p)\n",
    "    roots = radii * np.exp(1j * angles)\n",
    "\n",
    "    # Get polynomial coefficients from roots\n",
    "    coeffs = np.poly(roots).real  # Use .real to discard negligible imaginary part due to numerical error\n",
    "\n",
    "    return coeffs, roots\n",
    "\n",
    "coeffs, roots = generate_stable_polynomial(p)\n",
    "\n",
    "phis = coeffs\n",
    "\n",
    "# Initialize time series with zeros (extra p values for warm-up)\n",
    "ar_series = np.zeros(n)\n",
    "\n",
    "# Generate AR(p) time series\n",
    "for i in range(n):\n",
    "    ar_series[i] = white_noise[i] + sum(ar_series[i - j] * phis[j] if i - j >= 0 else 0 for j in range(p))\n",
    "\n",
    "# Convert to pandas Series\n",
    "date_range = pd.date_range(start='2020-01-01', periods=n, freq='M')\n",
    "series = pd.Series(ar_series, index=date_range)\n",
    "\n",
    "split = int(series.shape[0] * .96)\n",
    "\n",
    "# Train-test split\n",
    "train = series[:split]\n",
    "test = series[split:]\n",
    "\n",
    "# Fit AR model (ARIMA with q=0, d=0)\n",
    "model = ARIMA(train, order=(p, 0, 0))  # AR(p) model\n",
    "results = model.fit()\n",
    "\n",
    "# Forecast\n",
    "forecast = results.get_forecast(steps=len(test))\n",
    "predicted_mean = forecast.predicted_mean\n",
    "conf_int = forecast.conf_int()\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(series, label='Actual')\n",
    "plt.plot(predicted_mean, label='Forecast', color='red')\n",
    "plt.fill_between(predicted_mean.index, conf_int.iloc[:, 0], conf_int.iloc[:, 1], color='pink', alpha=0.3)\n",
    "plt.axvline(test.index[0], color='gray', linestyle='--', label='Forecast Start')\n",
    "plt.title('AR Forecast on Stationary Series')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f18df72",
   "metadata": {},
   "source": [
    "### ARMA(p,q)\n",
    "\n",
    "The autoregressive moving average model (ARMA) is the combination of the autoregressive model AR(p), and the moving average model MA(q).\n",
    "- Denoted as ARMA(p,q) where p is the order of the autoregressive portion, and q is the order of the moving average portion\n",
    "- Cannot use ACF or PACF to find the order p, and q. Must try different (p,q) value and select the model with the lowest AIC (Akaike’s Information Criterion)\n",
    "- Assumes stationarity. Use only on stationary data.\n",
    "\n",
    "**Equation**\n",
    "$$\n",
    "y_t = C + \\phi_1y_{t-1} + \\phi_2y_{t-2} + \\cdots + \\phi_qy_{t-q} + \\theta_1\\epsilon_{t-1} + \\theta_2\\epsilon_{t-2} + \\cdots + \\theta_q\\epsilon_{t-q} + \\epsilon_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e39eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Simulated stationary data: noise only\n",
    "np.random.seed(42)\n",
    "n_points = 100\n",
    "data = np.random.normal(0, 1, n_points)\n",
    "\n",
    "# Convert to pandas Series\n",
    "date_range = pd.date_range(start='2020-01-01', periods=n_points, freq='M')\n",
    "series = pd.Series(data, index=date_range)\n",
    "\n",
    "# Train-test split\n",
    "train = series[:80]\n",
    "test = series[80:]\n",
    "\n",
    "# Fit ARMA model (ARIMA with d=0)\n",
    "model = ARIMA(train, order=(2, 0, 2))  # ARMA(p,q) => ARIMA(p,0,q)\n",
    "results = model.fit()\n",
    "\n",
    "# Forecast\n",
    "forecast = results.get_forecast(steps=len(test))\n",
    "predicted_mean = forecast.predicted_mean\n",
    "conf_int = forecast.conf_int()\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(series, label='Actual')\n",
    "plt.plot(predicted_mean, label='Forecast', color='red')\n",
    "plt.fill_between(predicted_mean.index, conf_int.iloc[:, 0], conf_int.iloc[:, 1], color='pink', alpha=0.3)\n",
    "plt.axvline(test.index[0], color='gray', linestyle='--', label='Forecast Start')\n",
    "plt.title('ARMA Forecast on Stationary Series')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cda93b",
   "metadata": {},
   "source": [
    "### ARIMA(p,d,q)\n",
    "\n",
    "The autoregressive integrated moving average (ARIMA) model is the combination of the autoregressive model AR(p), and the moving average model MA(q), but in terms of the differenced series.\n",
    "- Denoted as ARMA(p,d,q), where p is the order of the autoregressive portion, d is the order of integration, and q is the order of the moving average portion\n",
    "- Can use on non-stationary data \n",
    "\n",
    "**Equation**\n",
    "$$\n",
    "y_t = C + \\phi_1y_{t-1} + \\phi_2y_{t-2} + \\cdots + \\phi_qy_{t-q} + \\theta_1\\epsilon_{t-1} + \\theta_2\\epsilon_{t-2} + \\cdots + \\theta_q\\epsilon_{t-q} + \\epsilon_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8badcb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Simulated non-stationary data: upward trend + noise\n",
    "np.random.seed(42)\n",
    "n_points = 100\n",
    "trend = np.linspace(10, 50, n_points)\n",
    "noise = np.random.normal(0, 2, n_points)\n",
    "data = trend + noise\n",
    "\n",
    "# Convert to pandas Series\n",
    "date_range = pd.date_range(start='2020-01-01', periods=n_points, freq='M')\n",
    "series = pd.Series(data, index=date_range)\n",
    "\n",
    "# Train-test split\n",
    "train = series[:80]\n",
    "test = series[80:]\n",
    "\n",
    "# Fit ARIMA model\n",
    "model = ARIMA(train, order=(2, 3, 2))  # ARIMA(p,d,q)\n",
    "results = model.fit()\n",
    "\n",
    "# Forecast\n",
    "forecast = results.get_forecast(steps=len(test))\n",
    "predicted_mean = forecast.predicted_mean\n",
    "conf_int = forecast.conf_int()\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(series, label='Actual')\n",
    "plt.plot(predicted_mean, label='Forecast', color='red')\n",
    "plt.fill_between(predicted_mean.index, conf_int.iloc[:, 0], conf_int.iloc[:, 1], color='pink', alpha=0.3)\n",
    "plt.axvline(test.index[0], color='gray', linestyle='--', label='Forecast Start')\n",
    "plt.title('ARIMA Forecast on Non-Stationary Series')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7620a12",
   "metadata": {},
   "source": [
    "Note: the order of integration d is simply the number of time a series was differenced to become stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8787990",
   "metadata": {},
   "source": [
    "### SARIMA(p,d,q)(P,D,Q)$_m$\n",
    "\n",
    "The seasonal autoregressive integrated moving average (SARIMA) model includes a seasonal component on top of the ARIMA model.\n",
    "- Denoted as SARIMA(p,d,q)(P,D,Q)m. Here, p, d, and q have the same meaning as in the ARIMA model.\n",
    "- P is the seasonal order of the autoregressive portion\n",
    "- D is the seasonal order of integration\n",
    "- Q is the seasonal order of the moving average portion\n",
    "- m is the frequency of the data (i.e., the number of data points in one season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d1638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Simulated monthly sales data with seasonality\n",
    "np.random.seed(42)\n",
    "n_months = 120\n",
    "seasonal_pattern = np.tile([1.0, 1.2, 1.5, 1.3, 1.0, 0.9, 0.8, 0.85, 0.95, 1.1, 1.3, 1.4], n_months // 12)\n",
    "trend = np.linspace(50, 100, n_months)\n",
    "noise = np.random.normal(scale=2, size=n_months)\n",
    "\n",
    "sales = trend * seasonal_pattern + noise\n",
    "date_index = pd.date_range(start='2015-01-01', periods=n_months, freq='M')\n",
    "sales_series = pd.Series(sales, index=date_index)\n",
    "\n",
    "# Train-test split\n",
    "train = sales_series[:100]\n",
    "test = sales_series[100:]\n",
    "\n",
    "# Fit SARIMA model\n",
    "model = SARIMAX(train,\n",
    "                order=(1, 1, 1),            # ARIMA part (p,d,q)\n",
    "                seasonal_order=(1, 1, 1, 12),  # Seasonal part (P,D,Q,m)\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False)\n",
    "results = model.fit(disp=False)\n",
    "\n",
    "# Forecast\n",
    "forecast = results.get_forecast(steps=len(test))\n",
    "predicted_mean = forecast.predicted_mean\n",
    "conf_int = forecast.conf_int()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(sales_series, label='Actual')\n",
    "plt.plot(predicted_mean, label='Forecast', color='red')\n",
    "plt.fill_between(predicted_mean.index, conf_int.iloc[:, 0], conf_int.iloc[:, 1], color='pink', alpha=0.3)\n",
    "plt.axvline(test.index[0], color='gray', linestyle='--', label='Forecast Start')\n",
    "plt.legend()\n",
    "plt.title('SARIMA Forecast: Monthly Sales with Yearly Seasonality (m=12)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e97715b",
   "metadata": {},
   "source": [
    "### SARIMAX\n",
    "\n",
    "SARIMAX is the most general model. It combines seasonality, a moving average portion, an autoregressive portion, and exogenous variables.\n",
    "- Can use external variables to forecast a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc970098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Simulated data\n",
    "np.random.seed(42)\n",
    "n_periods = 100\n",
    "\n",
    "# Exogenous variable: daily average temperature (with seasonality)\n",
    "temperature = 10 + 15 * np.sin(np.linspace(0, 3 * np.pi, n_periods)) + np.random.normal(0, 2, n_periods)\n",
    "\n",
    "# Target variable: energy consumption influenced by temperature\n",
    "energy = 200 - 3 * temperature + np.random.normal(0, 5, n_periods)\n",
    "\n",
    "# Convert to pandas Series\n",
    "date_range = pd.date_range(start='2023-01-01', periods=n_periods, freq='D')\n",
    "energy_series = pd.Series(energy, index=date_range)\n",
    "temperature_series = pd.Series(temperature, index=date_range)\n",
    "\n",
    "# Train-test split\n",
    "train_size = 80\n",
    "energy_train = energy_series[:train_size]\n",
    "energy_test = energy_series[train_size:]\n",
    "temp_train = temperature_series[:train_size]\n",
    "temp_test = temperature_series[train_size:]\n",
    "\n",
    "# Fit SARIMAX model\n",
    "model = SARIMAX(energy_train,\n",
    "                exog=temp_train,\n",
    "                order=(1, 0, 1),        # ARIMA(p,d,q)\n",
    "                seasonal_order=(1, 0, 1, 7))  # Weekly seasonality\n",
    "results = model.fit()\n",
    "\n",
    "# Forecast\n",
    "forecast = results.get_forecast(steps=len(energy_test), exog=temp_test)\n",
    "predicted_mean = forecast.predicted_mean\n",
    "conf_int = forecast.conf_int()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(energy_series, label='Actual')\n",
    "plt.plot(predicted_mean, label='Forecast', color='red')\n",
    "plt.fill_between(predicted_mean.index, conf_int.iloc[:, 0], conf_int.iloc[:, 1], color='pink', alpha=0.3)\n",
    "plt.axvline(energy_test.index[0], color='gray', linestyle='--', label='Forecast Start')\n",
    "plt.legend()\n",
    "plt.title('SARIMAX Forecast with Exogenous Variable (Temperature)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914f7718",
   "metadata": {},
   "source": [
    "> Caveat: SARIMAX predicts the next timestep. If your horizon is longer than one timestep, then you must forecast your exogenous variables too, which can amplify the error in your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c8aeaa",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
