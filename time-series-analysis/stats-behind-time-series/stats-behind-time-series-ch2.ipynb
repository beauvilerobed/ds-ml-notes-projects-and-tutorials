{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Stationary Processes\n",
    "\n",
    "## 2.1 Measure of Dependence\n",
    "\n",
    "Denote the mean function of $\\{X_t\\}$ as  \n",
    "$$\n",
    "\\mu_X(t) = \\mathbb{E}(X_t),\n",
    "$$  \n",
    "provided it exists. And the autocovariance function of $\\{X_t\\}$ is  \n",
    "$$\n",
    "\\gamma_X(s, t) = \\text{Cov}(X_s, X_t) = \\mathbb{E} \\big[ (X_s - \\mu_X(s)) (X_t - \\mu_X(t)) \\big].\n",
    "$$\n",
    "\n",
    "Preliminary results of covariance and correlation: for any random variables $X, Y$, and $Z$,  \n",
    "$$\n",
    "\\text{Cov}(X, Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y), \\quad \\text{and} \\quad \\text{Corr}(X, Y) = \\rho_{XY} = \\frac{\\text{Cov}(X, Y)}{\\sqrt{\\text{Var}(X) \\text{Var}(Y)}}.\n",
    "$$\n",
    "\n",
    "1. $-1 \\leq \\rho_{XY} \\leq 1$ for any $X$ and $Y$.  \n",
    "2. $\\text{Cov}(X, X) = \\text{Var}(X)$.  \n",
    "3. $\\text{Cov}(X, Y) = \\text{Cov}(Y, X)$.  \n",
    "4. $\\text{Cov}(aX, Y) = a \\, \\text{Cov}(X, Y)$.  \n",
    "5. $\\text{Cov}(a + X, Y) = \\text{Cov}(X, Y)$.  \n",
    "6. If $X$ and $Y$ are independent, then $\\text{Cov}(X, Y) = 0$.  \n",
    "7. $\\text{Cov}(X, Y) = 0$ does **not** imply $X$ and $Y$ are independent.  \n",
    "8. $\\text{Cov}(X + Y, Z) = \\text{Cov}(X, Z) + \\text{Cov}(Y, Z)$.  \n",
    "9. \n",
    "$$\n",
    "\\text{Cov}\\left(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_j Y_j\\right) = \\sum_{i=1}^n \\sum_{j=1}^m a_i b_j \\, \\text{Cov}(X_i, Y_j).\n",
    "$$\n",
    "\n",
    "Verify 1–9 as a homework problem.\n",
    "\n",
    "The time series $\\{X_t\\}$ is (weakly) stationary if  \n",
    "1. $\\mu_X(t)$ is independent of $t$;  \n",
    "2. $\\gamma_X(t + h, h)$ is independent of $t$ for each $h$.\n",
    "\n",
    "We say $\\{X_t\\}$ is strictly (or strongly) stationary if  \n",
    "$$\n",
    "(X_{t_1}, \\ldots, X_{t_k}) \\quad \\text{and} \\quad (X_{t_1 + h}, \\ldots, X_{t_k + h})\n",
    "$$  \n",
    "have the same joint distributions for all $k = 1, 2, \\ldots$, $h = 0, \\pm 1, \\pm 2, \\ldots$, and time points $t_1, \\ldots, t_k$. This is a very strong condition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 2.1.** Basic properties of a strictly stationary time series $\\{X_t\\}$:  \n",
    "1. $X_t$'s are from the same distribution.  \n",
    "2. $(X_t, X_{t+h}) \\stackrel{d}{=} (X_1, X_{1+h})$ for all integers $t$ and $h$.  \n",
    "3. $\\{X_t\\}$ is weakly stationary if $\\mathbb{E}(X_t^2) < \\infty$ for all $t$.  \n",
    "4. Weak stationarity does **not** imply strict stationarity.  \n",
    "5. An iid sequence is strictly stationary.\n",
    "\n",
    "*Proof.* The proof is quite straightforward and thus left as a homework problem.\n",
    "\n",
    "\n",
    "**Example 2.1 (q-dependent strictly stationary time series):**  \n",
    "One of the simplest ways to construct a time series $\\{X_t\\}$ that is strictly stationary is to “filter” an iid sequence. Let $\\{Z_t\\} \\sim \\text{IID}(0, \\sigma^2)$, define  \n",
    "$$\n",
    "X_t = g(Z_t, Z_{t-1}, \\ldots, Z_{t-q})\n",
    "$$  \n",
    "for some real-valued function $g$. Then $\\{X_t\\}$ is strictly stationary and also $q$-dependent; i.e., $X_s$ and $X_t$ are independent whenever $|t - s| > q$.\n",
    "\n",
    "\n",
    "A process $\\{X_t\\}$ is said to be a **Gaussian process** if the $n$-dimensional vector $\\mathbf{X} = (X_{t_1}, \\ldots, X_{t_n})$, for every collection of time points $t_1, \\ldots, t_n$, and every positive integer $n$, has a multivariate normal distribution.\n",
    "\n",
    "\n",
    "**Lemma 2.1.** For Gaussian processes, weak stationarity is equivalent to strict stationarity.\n",
    "\n",
    "*Proof.* It suffices to show that every weakly stationary Gaussian process $\\{X_t\\}$ is strictly stationary. Suppose it is not, then there must exist $(t_1, t_2)^\\top$ and $(t_1 + h, t_2 + h)^\\top$ such that $(X_{t_1}, X_{t_2})^\\top$ and $(X_{t_1+h}, X_{t_2+h})^\\top$ have different distributions, which contradicts the assumption of weak stationarity.\n",
    "\n",
    "\n",
    "In the following, unless indicated specifically, **stationary** always refers to weak stationarity.\n",
    "\n",
    "Note, when $\\{X_t\\}$ is stationary, $r_X(t + h, h)$ can be written as $\\gamma_X(h)$ for simplicity since $\\gamma_X(t + h, h)$ does not depend on $t$ for any given $h$.\n",
    "\n",
    "Let $\\{X_t\\}$ be a stationary time series. Its mean is $\\mu_X = \\mu_X(t)$. Its autocovariance function (ACVF) of $\\{X_t\\}$ at lag $h$ is  \n",
    "$$\n",
    "\\gamma_X(h) = \\text{Cov}(X_{t+h}, X_t).\n",
    "$$  \n",
    "Its autocorrelation function (ACF) of $\\{X_t\\}$ at lag $h$ is  \n",
    "$$\n",
    "\\rho_X(h) = \\frac{\\gamma_X(h)}{\\gamma_X(0)} = \\text{Corr}(X_{t+h}, X_t).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 2.2.** Basic properties of $\\gamma_X(\\cdot)$:  \n",
    "1. $\\gamma_X(0) \\geq 0$;  \n",
    "2. $|\\gamma_X(h)| \\leq \\gamma_X(0)$ for all $h$;  \n",
    "3. $\\gamma_X(h) = \\gamma_X(-h)$ for all $h$;  \n",
    "4. $\\gamma_X$ is nonnegative definite; i.e., a real valued function $K$ defined on the integers is nonnegative definite if and only if  \n",
    "$$\n",
    "\\sum_{i,j=1}^n a_i K(i-j) a_j \\geq 0\n",
    "$$  \n",
    "for all positive integers $n$ and real vectors $a = (a_1, \\ldots, a_n)^\\top \\in \\mathbb{R}^n$.\n",
    "\n",
    "*Proof.* The first one is trivial since  \n",
    "$$\n",
    "\\gamma_X(0) = \\mathrm{Cov}(X_t, X_t) = \\mathrm{Var}(X_t) \\geq 0 \\quad \\text{for all } t.\n",
    "$$  \n",
    "The second is based on the Cauchy–Schwarz inequality:  \n",
    "$$\n",
    "|\\gamma_X(h)| = |\\mathrm{Cov}(X_{t+h}, X_t)| \\leq \\sqrt{\\mathrm{Var}(X_{t+h})} \\sqrt{\\mathrm{Var}(X_t)} = \\gamma_X(0).\n",
    "$$  \n",
    "The third one is established by observing that  \n",
    "$$\n",
    "\\gamma_X(h) = \\mathrm{Cov}(X_{t+h}, X_t) = \\mathrm{Cov}(X_t, X_{t+h}) = \\gamma_X(-h).\n",
    "$$  \n",
    "The last statement can be verified by  \n",
    "$$\n",
    "0 \\leq \\mathrm{Var}\\big(a^\\top X_n\\big) = a^\\top \\Gamma_n a = \\sum_{i,j=1}^n a_i \\gamma_X(i-j) a_j\n",
    "$$  \n",
    "where  \n",
    "$$\n",
    "X_n = (X_n, \\ldots, X_1)^\\top\n",
    "$$  \n",
    "and  \n",
    "$$\n",
    "\\Gamma_n = \\mathrm{Var}(X_n) = \n",
    "\\begin{pmatrix}\n",
    "\\mathrm{Cov}(X_n, X_n) & \\mathrm{Cov}(X_n, X_{n-1}) & \\cdots & \\mathrm{Cov}(X_n, X_2) & \\mathrm{Cov}(X_n, X_1) \\\\\n",
    "\\mathrm{Cov}(X_{n-1}, X_n) & \\mathrm{Cov}(X_{n-1}, X_{n-1}) & \\cdots & \\mathrm{Cov}(X_{n-1}, X_2) & \\mathrm{Cov}(X_{n-1}, X_1) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "\\mathrm{Cov}(X_2, X_n) & \\mathrm{Cov}(X_2, X_{n-1}) & \\cdots & \\mathrm{Cov}(X_2, X_2) & \\mathrm{Cov}(X_2, X_1) \\\\\n",
    "\\mathrm{Cov}(X_1, X_n) & \\mathrm{Cov}(X_1, X_{n-1}) & \\cdots & \\mathrm{Cov}(X_1, X_2) & \\mathrm{Cov}(X_1, X_1)\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "\\gamma_X(0) & \\gamma_X(1) & \\cdots & \\gamma_X(n-2) & \\gamma_X(n-1) \\\\\n",
    "\\gamma_X(1) & \\gamma_X(0) & \\cdots & \\gamma_X(n-3) & \\gamma_X(n-2) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "\\gamma_X(n-2) & \\gamma_X(n-3) & \\cdots & \\gamma_X(0) & \\gamma_X(1) \\\\\n",
    "\\gamma_X(n-1) & \\gamma_X(n-2) & \\cdots & \\gamma_X(1) & \\gamma_X(0)\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "\n",
    "**Remark 2.1.** An autocorrelation function $\\rho(\\cdot)$ has all the properties of an autocovariance function and satisfies the additional condition $\\rho(0) = 1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem 2.3.** A real-valued function defined on the integers is the autocovariance function of a stationary time series if and only if it is even and non-negative definite.\n",
    "\n",
    "*Proof.* We only need prove that for any even and non-negative definite $K(\\cdot)$, we can find a stationary process $\\{X_t\\}$ such that  \n",
    "$$\n",
    "\\gamma_X(h) = K(h)\n",
    "$$  \n",
    "for any integer $h$. It is quite trivial to choose $\\{X_t\\}$ to be a Gaussian process such that  \n",
    "$$\n",
    "\\mathrm{Cov}(X_i, X_j) = K(i - j)\n",
    "$$  \n",
    "for any $i$ and $j$.\n",
    "\n",
    "\n",
    "### 2.1.1 Examples\n",
    "\n",
    "**Example 2.2.** Consider  \n",
    "$$\n",
    "X_t = A \\cos(\\theta t) + B \\sin(\\theta t)\n",
    "$$  \n",
    "where $A$ and $B$ are two uncorrelated random variables with zero means and unit variances with $\\theta \\in [-\\pi, \\pi]$. Then  \n",
    "$$\n",
    "\\mu_X(t) = 0\n",
    "$$  \n",
    "and  \n",
    "\\[\n",
    "\\begin{aligned}\n",
    "\\gamma_X(t + h, t) &= \\mathbb{E}(X_{t+h} X_t) \\\\\n",
    "&= \\mathbb{E}\\big[ (A \\cos(\\theta t + \\theta h) + B \\sin(\\theta t + \\theta h)) (A \\cos(\\theta t) + B \\sin(\\theta t)) \\big] \\\\\n",
    "&= \\cos(\\theta t + \\theta h) \\cos(\\theta t) + \\sin(\\theta t + \\theta h) \\sin(\\theta t) \\\\\n",
    "&= \\cos(\\theta t + \\theta h - \\theta t) = \\cos(\\theta h),\n",
    "\\end{aligned}\n",
    "\\]\n",
    "which is free of $t$. Thus $\\{X_t\\}$ is a stationary process. Further,  \n",
    "$$\n",
    "\\rho_X(h) = \\cos(\\theta h).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
