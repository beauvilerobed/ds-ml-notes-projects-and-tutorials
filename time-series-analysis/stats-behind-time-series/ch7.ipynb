{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f574fbb",
   "metadata": {},
   "source": [
    "# 7 Nonstationary Process\n",
    "\n",
    "## 7.1 Introduction of ARIMA Process\n",
    "\n",
    "If the data exhibits no apparent deviations from stationarity and has a rapidly decreasing autocorrelation function, we shall seek a suitable ARMA process to represent the mean-correlated data. If not, then we shall first look for a transformation of the data which generates a new series with the above properties. This can frequently be achieved by differencing, leading us to consider the class of ARIMA (autoregressive-integrated moving average) processes.\n",
    "\n",
    "**Definition of intrinsically stationary process:**  \n",
    "A stochastic process $\\{X_t\\}$ is said to be intrinsically stationary of integer order $d > 0$ if $\\{X_t\\}, \\{\\nabla X_t\\}, \\ldots, \\{\\nabla^{d-1} X_t\\}$ are non-stationary, but $\\{\\nabla^d X_t\\}$ is a stationary process.\n",
    "\n",
    "Note that:\n",
    "\n",
    "- $\\nabla X_t = (1 - B)X_t = X_t - X_{t-1}$\n",
    "- $\\nabla^2 X_t = \\nabla(\\nabla X_t) = (1 - B)^2 X_t = (X_t - X_{t-1}) - (X_{t-1} - X_{t-2}) = X_t - 2X_{t-1} + X_{t-2}$\n",
    "- $\\vdots$\n",
    "- $\\nabla^d X_t = (1 - B)^d X_t = \\sum_{k=0}^{d} \\binom{d}{k} (-1)^k B^k X_t = \\sum_{k=0}^{d} \\binom{d}{k} (-1)^k X_{t-k}$\n",
    "\n",
    "Any stationary process is intrinsically stationary of order $d = 0$.\n",
    "\n",
    "**Definition of the ARIMA(p, d, q) process:**  \n",
    "If $d$ is a non-negative integer, then $\\{X_t\\}$ is said to be an $ARIMA(p, d, q)$ process if:\n",
    "\n",
    "1. $\\{X_t\\}$ is intrinsically stationary of order $d$, and  \n",
    "2. $\\{\\nabla^d X_t\\}$ is a causal $ARMA(p, q)$ process.\n",
    "\n",
    "With $\\{W_t\\} \\sim WN(0, \\sigma^2)$, we can express the model as:\n",
    "\n",
    "$$\n",
    "\\phi(B)(1 - B)^d X_t = \\theta(B) W_t\n",
    "$$\n",
    "\n",
    "or equivalently, as:\n",
    "\n",
    "$$\n",
    "\\phi^*(B) X_t = \\theta(B) W_t\n",
    "$$\n",
    "\n",
    "where $\\phi^*(B) = \\phi(B)(1 - B)^d$, and $\\phi(z)$ and $\\theta(z)$ are polynomials of degrees $p$ and $q$, respectively, and $\\phi(z) \\ne 0$ for $|z| \\le 1$.  \n",
    "\n",
    "Note that if $d > 0$, then $\\phi^*(z)$ has a zero of order $d$ at $z = 1$ (on the unit circle).\n",
    "\n",
    "### Example 7.1\n",
    "\n",
    "A simplest example of ARIMA process is $ARIMA(0, 1, 0)$:\n",
    "\n",
    "$$\n",
    "(1 - B)X_t = X_t - X_{t-1} = W_t\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a2be0a",
   "metadata": {},
   "source": [
    "For which, assuming existence of $X_0$ and $t \\ge 1$:\n",
    "\n",
    "- $X_1 = X_0 + W_1$\n",
    "- $X_2 = X_1 + W_2 = X_0 + W_1 + W_2$\n",
    "- $X_3 = X_2 + W_3 = X_0 + W_1 + W_2 + W_3$\n",
    "- $\\vdots$\n",
    "- $X_t = X_0 + \\sum_{k=1}^{t} W_k$\n",
    "\n",
    "Above is a **random walk starting from** $X_0$. Assuming $X_0$ is uncorrelated with $W_t$'s, we have:\n",
    "\n",
    "$$\n",
    "\\text{Var}(X_t) = \\text{Var} \\left( X_0 + \\sum_{k=1}^{t} W_k \\right) = \\text{Var}(X_0) + \\sum_{k=1}^{t} \\text{Var}(W_k) = \\text{Var}(X_0) + t\\sigma^2\n",
    "$$\n",
    "\n",
    "which is either **time-dependent** or **infinite** if $\\text{Var}(X_0) = \\infty$.\n",
    "\n",
    "Further:\n",
    "\n",
    "$$\n",
    "\\text{Cov}(X_{t+h}, X_t) = \\text{Cov} \\left( X_0 + \\sum_{k=1}^{t+h} W_k,\\ X_0 + \\sum_{k=1}^{t} W_k \\right) = \\text{Var}(X_0) + \\min(t, t+h)\\sigma^2\n",
    "$$\n",
    "\n",
    "Thus, **ARIMA(0, 1, 0) is a non-stationary process**. The same is true for all **ARIMA(p, d, q) processes** when $d$ is a positive integer.\n",
    "\n",
    "A realization of white noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de089731",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Set the number of observations\n",
    "N <- 1000\n",
    "\n",
    "par(bg = \"white\")        \n",
    "\n",
    "# Generate a white noise series\n",
    "Wt <- rnorm(N, 0, 1)\n",
    "\n",
    "# Set up the plotting area\n",
    "par(mfrow = c(3, 1))\n",
    "par(mar = c(4.5, 4.5, 0.1, 0.1))\n",
    "\n",
    "# Plot the white noise time series\n",
    "plot.ts(Wt, col = \"blue\", ylab = expression(X[t]))\n",
    "\n",
    "# Plot the autocorrelation function (ACF)\n",
    "acf(Wt, type = \"correlation\")\n",
    "\n",
    "# Plot the partial autocorrelation function (PACF)\n",
    "acf(Wt, type = \"partial\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7214b20",
   "metadata": {},
   "source": [
    "A realizaiton of random walk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211eeb0b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Set the number of observations\n",
    "N <- 1000\n",
    "\n",
    "par(bg = \"white\")        \n",
    "\n",
    "# Generate a white noise series\n",
    "Wt <- rnorm(N, 0, 1)\n",
    "\n",
    "# Generate a random walk by cumulatively summing the white noise\n",
    "Xt <- cumsum(Wt)\n",
    "\n",
    "# Set up the plotting area\n",
    "par(mfrow = c(3, 1))\n",
    "par(mar = c(4.5, 4.5, 0.1, 0.1))\n",
    "\n",
    "# Plot the random walk time series\n",
    "plot.ts(Xt, col = \"blue\", ylab = expression(X[t]))\n",
    "\n",
    "# Plot the autocorrelation function (ACF)\n",
    "acf(Xt, type = \"correlation\")\n",
    "\n",
    "# Plot the partial autocorrelation function (PACF)\n",
    "acf(Xt, type = \"partial\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be14966e",
   "metadata": {},
   "source": [
    "Another realization of random walk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3805fbd7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Set the number of observations\n",
    "N <- 1000\n",
    "\n",
    "par(bg = \"white\")        \n",
    "\n",
    "# Generate white noise\n",
    "Wt <- rnorm(N, 0, 1)\n",
    "\n",
    "# Create a random walk by cumulative summation of white noise\n",
    "Xt <- cumsum(Wt)\n",
    "\n",
    "# Set up the plotting area: 3 plots in one column\n",
    "par(mfrow = c(3, 1))\n",
    "par(mar = c(4.5, 4.5, 0.1, 0.1))  # Margins\n",
    "\n",
    "# Plot the random walk time series\n",
    "plot.ts(Xt, col = \"blue\", ylab = expression(X[t]))\n",
    "\n",
    "# Plot the autocorrelation function (ACF)\n",
    "acf(Xt, type = \"correlation\")\n",
    "\n",
    "# Plot the partial autocorrelation function (PACF)\n",
    "acf(Xt, type = \"partial\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53041f72",
   "metadata": {},
   "source": [
    "### Example 7.2\n",
    "\n",
    "$\\{X_t\\}$ is an ARIMA(1, 1, 0) process if for some $\\phi \\in (-1, 1)$,\n",
    "\n",
    "$$(1 - \\phi B)(1 - B)X_t = W_t,\\quad \\{W_t\\} \\sim WN(0, \\sigma^2).$$\n",
    "\n",
    "We can write $Y_t = (1 - B)X_t$ which is an AR(1), and thus\n",
    "\n",
    "$$Y_t = \\sum_{j=0}^\\infty \\phi^j W_{t-j}.$$\n",
    "\n",
    "Back to $\\{X_t\\}$, we have\n",
    "\n",
    "$$X_t - X_{t-1} = Y_t$$\n",
    "\n",
    "and recursively,\n",
    "\n",
    "$$X_t = X_0 + \\sum_{j=1}^{t} Y_j,\\quad t \\geq 1.$$\n",
    "\n",
    "Further,\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Var}(X_t) &= \\text{Var}(X_0) + \\text{Var}\\left(\\sum_{j=1}^{t} Y_j\\right) \\\\\n",
    "&= \\text{Var}(X_0) + \\sum_{i=1}^{t} \\sum_{j=1}^{t} \\text{Cov}(Y_i, Y_j) \\\\\n",
    "&= \\text{Var}(X_0) + \\sum_{i=1}^{t} \\sum_{j=1}^{t} \\gamma_Y(i - j) \\\\\n",
    "&= \\text{Var}(X_0) + t \\gamma_Y(0) + 2 \\sum_{i=2}^{t} (t - i + 1)\\gamma_Y(i - 1) \\\\\n",
    "&= \\text{Var}(X_0) + \\gamma_Y(0)\\left(t + 2 \\sum_{i=2}^{t} (t - i + 1)\\rho_Y(i - 1)\\right) \\\\\n",
    "&= \\text{Var}(X_0) + \\frac{\\sigma^2}{1 - \\phi^2} \\left(t + 2 \\sum_{i=2}^{t} (t - i + 1)\\phi^{i - 1} \\right)\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7035cbd",
   "metadata": {},
   "source": [
    "An realization of AR(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d151340",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Set the number of observations (with 50 extra for initial condition discard)\n",
    "N <- 1050\n",
    "\n",
    "par(bg = \"white\")        \n",
    "\n",
    "# Generate white noise\n",
    "Wt <- rnorm(N, 0, 1)\n",
    "\n",
    "# Generate an AR(1) process: Yt = 0.6 * Y_{t-1} + Wt\n",
    "Yt <- filter(Wt, filter = c(0.6), method = \"recursive\")[-(1:50)]\n",
    "\n",
    "# Set up plotting layout: 3 plots in one column\n",
    "par(mfrow = c(3, 1))\n",
    "par(mar = c(4.5, 4.5, 0.1, 0.1))  # Margins\n",
    "\n",
    "# Plot the AR(1) time series\n",
    "plot.ts(Yt, col = \"blue\", ylab = expression(X[t]))\n",
    "\n",
    "# Plot the autocorrelation function (ACF)\n",
    "acf(Yt, type = \"correlation\")\n",
    "\n",
    "# Plot the partial autocorrelation function (PACF)\n",
    "acf(Yt, type = \"partial\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1b5529",
   "metadata": {},
   "source": [
    "An realization of ARIMA(1, 1, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f214497c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Set the number of observations (including extra for initialization)\n",
    "N <- 1050\n",
    "\n",
    "par(bg = \"white\")        \n",
    "\n",
    "# Generate white noise\n",
    "Wt <- rnorm(N, 0, 1)\n",
    "\n",
    "# Generate an AR(1) process: Yt = 0.6 * Y_{t-1} + Wt\n",
    "Yt <- filter(Wt, filter = c(0.6), method = \"recursive\")[-(1:50)]\n",
    "\n",
    "# Create an integrated AR(1) process (i.e., ARIMA(1,1,0)) by cumulative sum\n",
    "Xt <- cumsum(Yt)\n",
    "\n",
    "# Set up plotting layout: 3 plots in a single column\n",
    "par(mfrow = c(3, 1))\n",
    "par(mar = c(4.5, 4.5, 0.1, 0.1))  # Set plot margins\n",
    "\n",
    "# Plot the integrated AR(1) process\n",
    "plot.ts(Xt, col = \"blue\", ylab = expression(X[t]))\n",
    "\n",
    "# Plot the autocorrelation function (ACF)\n",
    "acf(Xt, type = \"correlation\")\n",
    "\n",
    "# Plot the partial autocorrelation function (PACF)\n",
    "acf(Xt, type = \"partial\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee948c99",
   "metadata": {},
   "source": [
    "### Example 7.3\n",
    "\n",
    "$\\{X_t\\}$ is an ARIMA(0, 1, 1) process, then\n",
    "\n",
    "$$(1 - B)X_t = (1 + \\theta B) W_t,\\quad \\{W_t\\} \\sim WN(0, \\sigma^2).$$\n",
    "\n",
    "We can write $Y_t = (1 + \\theta B) W_t$ which is an MA(1), thus\n",
    "\n",
    "$$X_t - X_{t-1} = Y_t$$\n",
    "\n",
    "and recursively,\n",
    "\n",
    "$$\n",
    "X_t = X_0 + \\sum_{j=1}^t Y_j = X_0 + \\sum_{j=1}^t (W_j + \\theta W_{j-1}).\n",
    "$$\n",
    "\n",
    "Then, if $X_0$ is uncorrelated with $Y_t$ s,\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Var}(X_t) &= \\text{Var}(X_0) + \\text{Var}\\left(\\sum_{j=1}^t Y_j\\right) \\\\\n",
    "&= \\text{Var}(X_0) + \\sum_{i=1}^t \\sum_{j=1}^t \\text{Cov}(Y_i, Y_j) \\\\\n",
    "&= \\text{Var}(X_0) + \\sum_{i=1}^t \\sum_{j=1}^t \\gamma_Y(i - j) \\\\\n",
    "&= \\text{Var}(X_0) + t \\gamma_Y(0) + 2 \\sum_{i=2}^t (t - i + 1) \\gamma_Y(i - 1) \\\\\n",
    "&= \\text{Var}(X_0) + t \\gamma_Y(0) + 2 (t - 1) \\gamma_Y(1) \\\\\n",
    "&= \\text{Var}(X_0) + t(1 + \\theta^2) \\sigma^2 + 2 (t - 1) \\theta \\sigma^2.\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef53049",
   "metadata": {},
   "source": [
    "An realization of MA(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516946cd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Number of observations (with extra 50 discarded at start)\n",
    "N <- 1050\n",
    "\n",
    "par(bg = \"white\")        \n",
    "\n",
    "# Generate white noise\n",
    "Wt <- rnorm(N, 0, 1)\n",
    "\n",
    "# Generate a time series using a finite impulse response filter with coefficients 1 and 0.6\n",
    "# Using sides=1 means the filter is one-sided (causal)\n",
    "Yt <- filter(Wt, sides = 1, filter = c(1, 0.6))[-(1:50)]\n",
    "\n",
    "# Set up plotting layout: 3 rows, 1 column\n",
    "par(mfrow = c(3, 1))\n",
    "par(mar = c(4.5, 4.5, 0.1, 0.1))\n",
    "\n",
    "# Plot the filtered time series\n",
    "plot.ts(Yt, col = \"blue\", ylab = expression(X[t]))\n",
    "\n",
    "# Plot autocorrelation function (ACF)\n",
    "acf(Yt, type = \"correlation\")\n",
    "\n",
    "# Plot partial autocorrelation function (PACF)\n",
    "acf(Yt, type = \"partial\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26faddd5",
   "metadata": {},
   "source": [
    "An realization of ARIMA(0, 1, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa1f95c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Number of observations (extra 50 discarded for initialization)\n",
    "N <- 1050\n",
    "\n",
    "par(bg = \"white\")        \n",
    "\n",
    "# Generate white noise\n",
    "Wt <- rnorm(N, 0, 1)\n",
    "\n",
    "# Generate an MA(1)-type process using a one-sided filter with coefficients 1 and 0.6\n",
    "Yt <- filter(Wt, sides = 1, filter = c(1, 0.6))[-(1:50)]\n",
    "\n",
    "# Create an integrated series by cumulative summation of Yt\n",
    "Xt <- cumsum(Yt)\n",
    "\n",
    "# Set up plotting area: 3 rows, 1 column\n",
    "par(mfrow = c(3, 1))\n",
    "par(mar = c(4.5, 4.5, 0.1, 0.1))\n",
    "\n",
    "# Plot the integrated time series Xt\n",
    "plot.ts(Xt, col = \"blue\", ylab = expression(X[t]))\n",
    "\n",
    "# Plot the autocorrelation function (ACF) of Xt\n",
    "acf(Xt, type = \"correlation\")\n",
    "\n",
    "# Plot the partial autocorrelation function (PACF) of Xt\n",
    "acf(Xt, type = \"partial\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d48903",
   "metadata": {},
   "source": [
    "### Example 7.4\n",
    "\n",
    "$\\{X_t\\}$ is an ARIMA(0, 1, $q$) process, then\n",
    "\n",
    "$$(1 - B)X_t = \\theta(B) W_t, \\quad \\{W_t\\} \\sim WN(0, \\sigma^2).$$\n",
    "\n",
    "We can write\n",
    "\n",
    "$$Y_t = \\theta(B) W_t,$$\n",
    "\n",
    "which is an MA($q$), thus\n",
    "\n",
    "$$\n",
    "X_t = X_0 + \\sum_{j=1}^t \\theta(B) W_j = X_0 + \\sum_{j=1}^t (W_j + \\theta W_{j-1}).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Example 7.5\n",
    "\n",
    "Moreover, if $\\{X_t\\}$ is an ARIMA($p$, 1, $q$), based on the causality assumption, we can write\n",
    "\n",
    "$$\n",
    "Y_t = (1 - B) X_t = \\sum_{j=0}^\\infty \\psi_j W_{t-j},\n",
    "$$\n",
    "\n",
    "where $\\psi(z) = \\frac{\\theta(z)}{\\phi(z)}$. Then recursively,\n",
    "\n",
    "$$\n",
    "X_t = X_0 + \\sum_{j=1}^t Y_j.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Example 7.6\n",
    "\n",
    "What if $d = 2$? For ARIMA($p$, 2, $q$), we have\n",
    "\n",
    "$$\n",
    "\\phi(B)(1 - B)^2 X_t = \\theta(B) W_t,\n",
    "$$\n",
    "\n",
    "then\n",
    "\n",
    "$$\n",
    "(1 - B)^2 X_t = Z_t = \\psi(B) W_t,\n",
    "$$\n",
    "\n",
    "where $\\psi(z) = \\frac{\\theta(z)}{\\phi(z)}$ is ARMA($p, q$). Letting $(1 - B) Y_t = Z_t$, we have\n",
    "\n",
    "$$\n",
    "(1 - B) Y_t = Z_t.\n",
    "$$\n",
    "\n",
    "Thus $\\{Y_t\\}$ is an ARIMA($p$, 1, $q$) and\n",
    "\n",
    "$$\n",
    "Y_t = Y_0 + \\sum_{j=1}^t Z_j.\n",
    "$$\n",
    "\n",
    "Since $(1 - B) X_t = Y_t$, we further have\n",
    "\n",
    "$$\n",
    "X_t = X_0 + \\sum_{j=1}^t Y_j.\n",
    "$$\n",
    "\n",
    "Notice that for any constants $\\alpha_0$ and $\\alpha_1$,\n",
    "\n",
    "$$\n",
    "X_t^* = X_t + \\alpha_0 + \\alpha_1 t\n",
    "$$\n",
    "\n",
    "is also a solution to the equation\n",
    "\n",
    "$$\n",
    "\\phi(B)(1 - B)^2 X_t = \\theta(B) W_t.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6e923a",
   "metadata": {},
   "source": [
    "An realization of ARIMA(1, 2, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e07445",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Number of observations (with 50 discarded for initialization)\n",
    "N <- 1050\n",
    "\n",
    "par(bg = \"white\")        \n",
    "\n",
    "# Generate white noise\n",
    "Wt <- rnorm(N, 0, 1)\n",
    "\n",
    "# Generate an AR(1) process with coefficient 0.6 (recursive filtering)\n",
    "Yt <- filter(Wt, filter = c(0.6), method = \"recursive\")[-(1:50)]\n",
    "\n",
    "# Double integration (cumulative sum twice) of the AR(1) series\n",
    "Xt <- cumsum(cumsum(Yt))\n",
    "\n",
    "# Set up plotting area: 3 rows, 1 column\n",
    "par(mfrow = c(3, 1))\n",
    "par(mar = c(4.5, 4.5, 0.1, 0.1))\n",
    "\n",
    "# Plot the doubly integrated process Xt\n",
    "plot.ts(Xt, col = \"blue\", ylab = expression(X[t]))\n",
    "\n",
    "# Plot autocorrelation function (ACF)\n",
    "acf(Xt, type = \"correlation\")\n",
    "\n",
    "# Plot partial autocorrelation function (PACF)\n",
    "acf(Xt, type = \"partial\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b6c00c",
   "metadata": {},
   "source": [
    "An realization of ARIMA(0, 2, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0438e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Number of observations, with extra 50 to discard initial filter effects\n",
    "N <- 1050\n",
    "\n",
    "par(bg = \"white\")        \n",
    "\n",
    "# Generate white noise\n",
    "Wt <- rnorm(N, 0, 1)\n",
    "\n",
    "# Generate MA(1) process with filter coefficients 1 and 0.6 (one-sided filter)\n",
    "Yt <- filter(Wt, sides = 1, filter = c(1, 0.6))[-(1:50)]\n",
    "\n",
    "# Double integration of the MA(1) process (cumulative sum twice)\n",
    "Xt <- cumsum(cumsum(Yt))\n",
    "\n",
    "# Set up plotting: 3 rows, 1 column\n",
    "par(mfrow = c(3, 1))\n",
    "par(mar = c(4.5, 4.5, 0.1, 0.1))\n",
    "\n",
    "# Plot the doubly integrated time series\n",
    "plot.ts(Xt, col = \"blue\", ylab = expression(X[t]))\n",
    "\n",
    "# Plot the autocorrelation function (ACF)\n",
    "acf(Xt, type = \"correlation\")\n",
    "\n",
    "# Plot the partial autocorrelation function (PACF)\n",
    "acf(Xt, type = \"partial\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf80dc",
   "metadata": {},
   "source": [
    "## 7.2 Over-differencing?\n",
    "\n",
    "While differencing a time series often seems to yield a series visually more amenable to modeling as a stationary process, **over-differencing is a danger!**\n",
    "\n",
    "If $X_t$ is ARMA($p, q$) already, and satisfies\n",
    "\n",
    "$$\n",
    "\\phi(B) X_t = \\theta(B) W_t,\n",
    "$$\n",
    "\n",
    "then one more differencing provides that\n",
    "\n",
    "$$\n",
    "(1 - B) \\phi(B) X_t = (1 - B) \\theta(B) W_t,\n",
    "$$\n",
    "\n",
    "or equivalently,\n",
    "\n",
    "$$\n",
    "\\phi(B) (1 - B) X_t = \\theta(B) (1 - B) W_t;\n",
    "$$\n",
    "\n",
    "i.e., one more difference of $X_t$, denoted by $Y_t = \\nabla X_t$, satisfies\n",
    "\n",
    "$$\n",
    "\\phi(B) Y_t = \\theta^*(B) W_t,\n",
    "$$\n",
    "\n",
    "where $\\theta^*(z) = \\theta(z)(1 - z)$. Noting that $\\theta^*(z)$ has a root on the unit circle, thus $Y_t$ is a **non-invertible** ARMA($p, q+1$) process.\n",
    "\n",
    "### Summary of evils of over-differencing:\n",
    "\n",
    "1. ARMA($p, q+1$) model usually has more complex covariance structure than ARMA($p, q$).\n",
    "2. ARMA($p, q+1$) model has one more parameter to estimate than ARMA($p, q$) model.\n",
    "3. Sample size is reduced by 1 (from $n$ to $n-1$, not a big issue you may think...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba6cbcc",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Number of observations\n",
    "N <- 5000\n",
    "\n",
    "par(bg = \"white\")        \n",
    "\n",
    "# Generate white noise\n",
    "Wt <- rnorm(N, 0, 1)\n",
    "\n",
    "# Set plot margins\n",
    "par(mar = c(4.5, 4.5, 0.1, 0.1))\n",
    "\n",
    "# Define a 3x4 layout matrix for plotting (positions 1 to 12)\n",
    "design.mat <- matrix(1:12, nrow = 3, ncol = 4)\n",
    "layout(design.mat)\n",
    "\n",
    "# Plot white noise time series\n",
    "plot.ts(Wt, col = \"blue\", ylab = expression(X[t]))\n",
    "\n",
    "# Plot ACF and PACF of white noise with y-limits -1 to 1\n",
    "acf(Wt, type = \"correlation\", ylim = c(-1, 1))\n",
    "acf(Wt, type = \"partial\", ylim = c(-1, 1))\n",
    "\n",
    "# First difference: Xt = Wt[t] - Wt[t-1]\n",
    "Xt <- Wt[-1] - Wt[-length(Wt)]\n",
    "\n",
    "# Plot first difference\n",
    "plot.ts(Xt, col = \"blue\", ylab = expression(W[t]))\n",
    "\n",
    "# Plot ACF and PACF of first difference\n",
    "acf(Xt, type = \"correlation\", ylim = c(-1, 1))\n",
    "acf(Xt, type = \"partial\", ylim = c(-1, 1))\n",
    "\n",
    "# Second difference: Xt = Xt[t] - Xt[t-1]\n",
    "Xt <- Xt[-1] - Xt[-length(Xt)]\n",
    "\n",
    "# Plot second difference\n",
    "plot.ts(Xt, col = \"blue\", ylab = expression(W[t]))\n",
    "\n",
    "# Plot ACF and PACF of second difference\n",
    "acf(Xt, type = \"correlation\", ylim = c(-1, 1))\n",
    "acf(Xt, type = \"partial\", ylim = c(-1, 1))\n",
    "\n",
    "# Third difference: Xt = Xt[t] - Xt[t-1]\n",
    "Xt <- Xt[-1] - Xt[-length(Xt)]\n",
    "\n",
    "# Plot third difference\n",
    "plot.ts(Xt, col = \"blue\", ylab = expression(W[t]))\n",
    "\n",
    "# Plot ACF and PACF of third difference\n",
    "acf(Xt, type = \"correlation\", ylim = c(-1, 1))\n",
    "acf(Xt, type = \"partial\", ylim = c(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76ee771",
   "metadata": {},
   "source": [
    "Unit root tests help determine if differencing is needed. For example, suppose $X_t$ obeys an ARIMA(0, 1, 0) model:\n",
    "\n",
    "$$(1 - B) X_t = W_t,$$\n",
    "\n",
    "where $\\{W_t\\}$ is white noise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efab366",
   "metadata": {},
   "source": [
    "This can be viewed as a special case of an AR(1) process as\n",
    "\n",
    "$$(1 - \\phi B) X_t = W_t,$$\n",
    "\n",
    "where $\\phi = 1$.\n",
    "\n",
    "Thus, we can design a test for the null hypothesis $\\phi = 1$. However, the maximum likelihood estimation (MLE) inference only holds for $|\\phi| < 1$; i.e., when the process is causal.\n",
    "\n",
    "Dickey and Fuller (1979) designed an alternative test statistic. They use ordinary least squares (OLS) to estimate $\\phi^* = \\phi - 1$, and then test the hypothesis $\\phi^* = 0$. The method is based on the equation:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\nabla X_t &= X_t - X_{t-1} \\\\\n",
    "&= (\\phi X_{t-1} + W_t) - X_{t-1} \\\\\n",
    "&= (\\phi - 1) X_{t-1} + W_t \\\\\n",
    "&= \\phi^* X_{t-1} + W_t.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Thus, the **Dickey-Fuller unit root test** uses OLS to regress $\\nabla X_t$ on $X_{t-1}$.\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** If the mean of $X_t$ is $\\mu$ (not zero), then we have\n",
    "\n",
    "$$\n",
    "\\nabla X_t = \\phi^*_0 + \\phi^*_1 X_{t-1} + W_t,\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- $\\phi^*_0 = \\mu (1 - \\phi)$,\n",
    "- $\\phi^*_1 = \\phi - 1$.\n",
    "\n",
    "The goal is now to test\n",
    "\n",
    "$$\n",
    "H_0 : \\phi^*_1 = 0 \\quad \\text{versus} \\quad H_a : \\phi^*_1 < 0,\n",
    "$$\n",
    "\n",
    "since we do not need to consider $\\phi^*_1 > 0$ (which corresponds to a non-causal AR(1) model).\n",
    "\n",
    "---\n",
    "\n",
    "In the standard regression model\n",
    "\n",
    "$$\n",
    "Y_t = a + b Z_t + e_t, \\quad t = 1, \\ldots, m,\n",
    "$$\n",
    "\n",
    "minimizing the least squares\n",
    "\n",
    "$$\n",
    "\\sum_t (Y_t - a - b Z_t)^2\n",
    "$$\n",
    "\n",
    "yields the OLS estimator of $b$ as\n",
    "\n",
    "$$\n",
    "\\hat{b} = \\frac{\\sum_t (Y_t - \\bar{Y})(Z_t - \\bar{Z})}{\\sum_t (Z_t - \\bar{Z})^2} = \\frac{\\sum_t Y_t (Z_t - \\bar{Z})}{\\sum_t (Z_t - \\bar{Z})^2},\n",
    "$$\n",
    "\n",
    "and the estimator of $a$ as\n",
    "\n",
    "$$\n",
    "\\hat{a} = \\bar{Y} - \\hat{b} \\bar{Z},\n",
    "$$\n",
    "\n",
    "where $\\bar{Y}$ and $\\bar{Z}$ are the sample means of the $Y_t$ s and $Z_t$ s respectively.\n",
    "\n",
    "The standard error of $\\hat{b}$ is\n",
    "\n",
    "$$\n",
    "SE(\\hat{b}) = \\sqrt{\\frac{\\sum_t (Y_t - \\hat{a} - \\hat{b} Z_t)^2}{(m-2) \\sum_t (Z_t - \\bar{Z})^2}}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e79176",
   "metadata": {},
   "source": [
    "Now, denote our model as\n",
    "\n",
    "$$\n",
    "\\nabla X_t = X_t - X_{t-1} = \\phi_0^* + \\phi_1^* X_{t-1} + W_t, \\quad t = 2, \\ldots, n.\n",
    "$$\n",
    "\n",
    "Define \n",
    "\n",
    "$$\n",
    "Y_t = X_t - X_{t-1} \\quad \\text{and} \\quad Z_t = X_{t-1}.\n",
    "$$\n",
    "\n",
    "We have a regression model\n",
    "\n",
    "$$\n",
    "Y_t = \\phi_0^* + \\phi_1^* Z_t + W_t, \\quad t = 2, \\ldots, n.\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "\\bar{Z} = \\frac{1}{n-1} \\sum_{t=2}^n Z_t = \\frac{1}{n-1} \\sum_{t=2}^n X_{t-1} = \\frac{1}{n-1} \\sum_{t=1}^{n-1} X_t.\n",
    "$$\n",
    "\n",
    "The OLS estimator of $\\phi_1^*$ is\n",
    "\n",
    "$$\n",
    "\\hat{\\phi}_1^* = \\frac{\\sum_{t=2}^n Y_t (Z_t - \\bar{Z})}{\\sum_{t=2}^n (Z_t - \\bar{Z})^2} \n",
    "= \\frac{\\sum_{t=2}^n (X_t - X_{t-1})(X_{t-1} - \\bar{Z})}{\\sum_{t=2}^n (X_{t-1} - \\bar{Z})^2}.\n",
    "$$\n",
    "\n",
    "Rewrite the numerator:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\sum_{t=2}^n (X_t - X_{t-1})(X_{t-1} - \\bar{Z}) &= \\sum_{t=2}^n \\big( (X_t - \\bar{Z}) - (X_{t-1} - \\bar{Z}) \\big) (X_{t-1} - \\bar{Z}) \\\\\n",
    "&= \\sum_{t=2}^n (X_t - \\bar{Z})(X_{t-1} - \\bar{Z}) - \\sum_{t=2}^n (X_{t-1} - \\bar{Z})^2,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "so\n",
    "\n",
    "$$\n",
    "\\hat{\\phi}_1^* = \\frac{\\sum_{t=2}^n (X_t - \\bar{Z})(X_{t-1} - \\bar{Z})}{\\sum_{t=2}^n (X_{t-1} - \\bar{Z})^2} - 1.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "The standard error of $\\hat{\\phi}_1^*$ is\n",
    "\n",
    "$$\n",
    "SE(\\hat{\\phi}_1^*) = \\sqrt{\\frac{\\sum_{t=2}^n \\left( \\nabla X_t - \\hat{\\phi}_0^* - \\hat{\\phi}_1^* X_{t-1} \\right)^2}{(n - 3) \\sum_{t=2}^n (X_{t-1} - \\bar{Z})^2}}.\n",
    "$$\n",
    "\n",
    "Further, \n",
    "\n",
    "$$\n",
    "\\hat{\\phi}_0^* = \\bar{Y} - \\hat{\\phi}_1^* \\bar{Z} = \\frac{X_n - X_1}{n - 1} - \\hat{\\phi}_1^* \\frac{1}{n-1} \\sum_{t=1}^{n-1} X_t.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "The test statistic for \n",
    "\n",
    "$$\n",
    "H_0 : \\phi_1^* = 0 \\quad \\text{versus} \\quad H_a : \\phi_1^* < 0\n",
    "$$\n",
    "\n",
    "is the t-like ratio\n",
    "\n",
    "$$\n",
    "t = \\frac{\\hat{\\phi}_1^*}{SE(\\hat{\\phi}_1^*)}.\n",
    "$$\n",
    "\n",
    "However, this $t$ does **not** follow a standard $t$-distribution. We reject the null hypothesis (presence of a unit root) in favor of the alternative (AR(1) is appropriate) at level $\\alpha$ if $t$ falls below the critical value from the Dickey-Fuller distribution, which assumes large $n$. The common critical values are:\n",
    "\n",
    "| Significance Level | Critical Value |\n",
    "|--------------------|----------------|\n",
    "| 1%                 | -3.43          |\n",
    "| 5%                 | -2.86          |\n",
    "| 10%                | -2.57          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9460a7c",
   "metadata": {},
   "source": [
    "# 7.3 Seasonal ARIMA Models\n",
    "\n",
    "The classical decomposition of the time series\n",
    "\n",
    "$$\n",
    "X_t = m_t + s_t + Y_t,\n",
    "$$\n",
    "\n",
    "where $m_t$ is the trend component, $ s_t$ is the seasonal component, and $Y_t$ is the random noise component. We have learned to use differencing to eliminate the trend $m_t$. (Why? One easy way to interpret that is that we can view $m_t$ as a smooth function of $t$. Then any smooth function can be approximated by a polynomial; i.e., there exist $d$, $\\alpha_0, \\ldots, \\alpha_d$ such that\n",
    "\n",
    "$$\n",
    "m_t \\approx \\sum_{k=0}^d \\alpha_k t^k.\n",
    "$$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "X_t = \\sum_{k=0}^d \\alpha_k t^k + S_t + Y_t.\n",
    "$$\n",
    "\n",
    "Taking $d$-order differencing, we have\n",
    "\n",
    "$$\n",
    "\\nabla^d X_t = \\alpha_d + \\nabla^d S_t + \\nabla^d Y_t.\n",
    "$$\n",
    "\n",
    "Further,\n",
    "\n",
    "$$\n",
    "\\nabla^{d+1} X_t = \\nabla^{d+1} S_t + \\nabla^{d+1} Y_t.\n",
    "$$\n",
    "\n",
    "Thus, the trend has been eliminated.) In this section, we learn how to handle seasonal components.\n",
    "\n",
    "---\n",
    "\n",
    "## 7.3.1 Seasonal ARMA models\n",
    "\n",
    "Seasonal models allow for randomness in the seasonal pattern from one cycle to the next. For example, we have $r$ years of monthly data which we tabulate as follows:\n",
    "\n",
    "| Year | Jan. | Feb. | ··· | Dec. |\n",
    "|-------|------|------|-----|-------|\n",
    "| 1     | $X_1$  | $X_2$  | ··· | $X_{12}$  |\n",
    "| 2     | $X_{13}$ | $X_{14}$ | ··· | $X_{24}$  |\n",
    "| 3     | $X_{25}$ | $X_{26}$ | ··· | $X_{36}$  |\n",
    "| ...   | ...  | ...  | ... | ...   |\n",
    "| $r$   | $X_{1+12(r-1)}$ | $X_{2+12(r-1)}$ | ··· | $X_{12+12(r-1)}$ |\n",
    "\n",
    "Each column in this table may itself be viewed as a realization of a time series. Suppose that each one of these twelve time series is generated by the same $ARMA(P, Q)$ model, or more specifically that the series corresponding to the $j$th month,\n",
    "\n",
    "$$\n",
    "\\{X_{j + 12t}, \\quad t = 0, 1, \\ldots, r-1\\}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066ef058",
   "metadata": {},
   "source": [
    "satisfies\n",
    "\n",
    "$$\n",
    "X_{j+12t} = \\Phi_1 X_{j+12(t-1)} + \\cdots + \\Phi_p X_{j+12(t-P)} + U_{j+12t} + \\Theta_1 U_{j+12(t-1)} + \\cdots + \\Theta_Q U_{j+12(t-Q)}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\{U_{j+12t}, \\quad t = \\ldots, -1, 0, 1, \\ldots \\} \\sim WN(0, \\sigma_U^2)\n",
    "$$\n",
    "\n",
    "holds for each $j = 1, \\ldots, 12$. Since the same $ARMA(P, Q)$ model is assumed to apply to each month, we can rewrite it as\n",
    "\n",
    "$$\n",
    "X_t = \\Phi_1 X_{t-12} + \\cdots + \\Phi_P X_{t-12P} + U_t + \\Theta_1 U_{t-12} + \\cdots + \\Theta_Q U_{t-12Q}\n",
    "$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\n",
    "\\Phi(B^{12}) X_t = \\Theta(B^{12}) U_t,\n",
    "$$\n",
    "\n",
    "(7.1)\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\Phi(z) = 1 - \\Phi_1 z - \\cdots - \\Phi_p z^p, \\quad \\Theta(z) = 1 + \\Theta_1 z + \\cdots + \\Theta_Q z^Q,\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\\{U_{j+12t}, \\quad t = \\ldots, -1, 0, 1, \\ldots \\} \\sim WN(0, \\sigma_U^2)\n",
    "$$\n",
    "\n",
    "for each $j$. Now, for simplicity, we assume\n",
    "\n",
    "$$\n",
    "U_t \\sim WN(0, \\sigma^2),\n",
    "$$\n",
    "\n",
    "then we have $X_t$ as an ARMA process:\n",
    "\n",
    "$$\n",
    "\\Phi(B^{12}) X_t = \\Theta(B^{12}) W_t, \\quad W_t \\sim WN(0, \\sigma^2).\n",
    "$$\n",
    "\n",
    "Or more generally,\n",
    "\n",
    "$$\n",
    "\\Phi(B^{s}) X_t = \\Theta(B^{s}) W_t, \\quad W_t \\sim WN(0, \\sigma^2).\n",
    "$$\n",
    "\n",
    "We call this model a Seasonal ARMA (SARMA) process with period $ s$ (an integer), denoted by $ARMA(P, Q)_s$.\n",
    "\n",
    "If $\\Phi(z)$ and $\\Theta(z)$ make a stationary $ARMA(P, Q)$, then $X_t$ is also a stationary ARMA process.\n",
    "\n",
    "---\n",
    "\n",
    "What would an $ARMA(1,1)_4$ look like?\n",
    "\n",
    "$$\n",
    "(1 - \\Phi_1 B^4) X_t = (1 + \\Theta_1 B^4) W_t\n",
    "$$\n",
    "\n",
    "which is\n",
    "\n",
    "$$\n",
    "X_t = \\Phi_1 X_{t-4} + W_t + \\Theta_1 W_{t-4};\n",
    "$$\n",
    "\n",
    "i.e., a regular $ARMA(4,4)$ model (with certain coefficients being zero).\n",
    "\n",
    "Now, let us think about a monthly model and a seasonal MA; i.e., $ARMA(0,1)_{12}$. The model can be written as\n",
    "\n",
    "$$\n",
    "X_t = W_t + \\Theta_1 W_{t-12}.\n",
    "$$\n",
    "\n",
    "Obviously, it is causal and stationary. Then\n",
    "\n",
    "$$\n",
    "\\gamma_X(h) = E(X_t X_{t+h}) = E\\big((W_t + \\Theta_1 W_{t-12})(W_{t+h} + \\Theta_1 W_{t+h-12})\\big) = (1 + \\Theta_1^2) \\sigma^2 I(h=0) + \\Theta_1 \\sigma^2 I(h=12).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d91872e",
   "metadata": {},
   "source": [
    "Thus, we should see one spike at lag 0 and also at 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876a196",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Number of observations (with extra 50 for initialization)\n",
    "N <- 1050\n",
    "\n",
    "par(bg = \"white\")        \n",
    "\n",
    "# Generate white noise\n",
    "Wt <- rnorm(N, 0, 1)\n",
    "\n",
    "# Set plot margins\n",
    "par(mar = c(4.5, 4.5, 0.1, 0.1))\n",
    "\n",
    "# Define layout matrix for 3 rows and 2 columns (6 plots)\n",
    "design.mat <- matrix(1:6, nrow = 3, ncol = 2)\n",
    "layout(design.mat)\n",
    "\n",
    "# Generate MA(1) process with filter coefficients (1, 0.6)\n",
    "Yt <- filter(Wt, sides = 1, filter = c(1, 0.6))[-(1:50)]\n",
    "\n",
    "# Plot Yt time series\n",
    "plot.ts(Yt, col = \"blue\", ylab = expression(Y[t]))\n",
    "\n",
    "# Plot ACF and PACF of Yt with lag up to 96\n",
    "acf(Yt, type = \"correlation\", lag.max = 96)\n",
    "acf(Yt, type = \"partial\", lag.max = 96)\n",
    "\n",
    "# Generate MA(12) process with coefficients 1 and 0.6 at lag 13\n",
    "Zt <- filter(Wt, sides = 1, filter = c(1, rep(0, 11), 0.6))[-(1:50)]\n",
    "\n",
    "# Plot Zt time series\n",
    "plot.ts(Zt, col = \"blue\", ylab = expression(Z[t]))\n",
    "\n",
    "# Plot ACF and PACF of Zt with lag up to 96\n",
    "acf(Zt, type = \"correlation\", lag.max = 96)\n",
    "acf(Zt, type = \"partial\", lag.max = 96)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16851771",
   "metadata": {},
   "source": [
    "Now, let us check a seasonal AR; i.e., $ARMA(1, 0)_{12}$; i.e.,\n",
    "\n",
    "$$\n",
    "X_t = \\Phi_1 X_{t-12} + W_t.\n",
    "$$\n",
    "\n",
    "Similarly as in the analysis of AR(1) process, we have, recursively,\n",
    "\n",
    "\\begin{aligned}\n",
    "X_t &= \\Phi_1 X_{t-12} + W_t = \\Phi_1^2 X_{t-24} + \\Phi_1 W_{t-12} + W_t \\\\\n",
    "&= \\cdots \\\\\n",
    "&= \\sum_{j=0}^\\infty \\Phi_1^j W_{t-12j}.\n",
    "\\end{aligned}\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$\n",
    "\\gamma_X(0) = \\sum_{j=0}^\\infty \\Phi_1^{2j} \\sigma^2 = \\frac{\\sigma^2}{1 - \\Phi_1^2}.\n",
    "$$\n",
    "\n",
    "What about $\\gamma_X(1), \\gamma_X(2), \\ldots, \\gamma_X(11)$? They are all zero.\n",
    "\n",
    "And\n",
    "\n",
    "\\begin{aligned}\n",
    "\\gamma_X(12) &= E\\left(\\sum_{j=0}^\\infty \\Phi_1^j W_{t-12j} \\right)\n",
    "\\left(\\sum_{j=0}^\\infty \\Phi_1^j W_{t+12 - 12j} \\right) \\\\\n",
    "&= E\\left(\\sum_{j=0}^\\infty \\Phi_1^j W_{t-12j}\\right)\n",
    "\\left(W_{t+12} + \\Phi_1 \\sum_{j=1}^\\infty \\Phi_1^{j-1} W_{t - 12(j-1)} \\right) \\\\\n",
    "&= E\\left(\\sum_{j=0}^\\infty \\Phi_1^j W_{t-12j} \\right)\n",
    "\\left(W_{t+12} + \\Phi_1 \\sum_{j=0}^\\infty \\Phi_1^j W_{t - 12j} \\right) \\\\\n",
    "&= \\Phi_1 \\sum_{j=0}^\\infty \\Phi_1^{2j} \\sigma^2 = \\frac{\\sigma^2 \\Phi_1}{1 - \\Phi_1^2}.\n",
    "\\end{aligned}\n",
    "\n",
    "Further,\n",
    "\n",
    "$$\n",
    "\\gamma_X(h) = \\sigma^2 \\sum_{\\text{integer } k} \\frac{\\Phi_1^k}{1 - \\Phi_1^2} I(h = 12k).\n",
    "$$\n",
    "\n",
    "This is very similar to an AR(1), however, we are ignoring all the lags between multiples of 12. We are not worried about what is going on at 1, 2, 3, 4, $\\ldots$, we are only interested in the lags 12, 24, 36, $\\ldots$.\n",
    "\n",
    "You can certainly generalize it to a general period, like $ARMA(1, 0)_s$, for any integer $ s$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c539dd6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Number of observations (with extra 50 discarded for initialization)\n",
    "N <- 1050\n",
    "\n",
    "par(bg = \"white\")        \n",
    "\n",
    "# Generate white noise\n",
    "Wt <- rnorm(N, 0, 1)\n",
    "\n",
    "# Set plot margins\n",
    "par(mar = c(4.5, 4.5, 0.1, 0.1))\n",
    "\n",
    "# Define layout matrix for 3 rows and 2 columns (6 plots)\n",
    "design.mat <- matrix(1:6, nrow = 3, ncol = 2)\n",
    "layout(design.mat)\n",
    "\n",
    "# Generate AR(1) process with coefficient 0.6 using recursive filter\n",
    "Yt <- filter(Wt, filter = c(0.6), method = \"recursive\")[-(1:50)]\n",
    "\n",
    "# Plot Yt time series\n",
    "plot.ts(Yt, col = \"blue\", ylab = expression(Y[t]))\n",
    "\n",
    "# Plot ACF and PACF of Yt with maximum lag 96\n",
    "acf(Yt, type = \"correlation\", lag.max = 96)\n",
    "acf(Yt, type = \"partial\", lag.max = 96)\n",
    "\n",
    "# Generate AR(12) process with a single non-zero coefficient at lag 12 (0.6)\n",
    "Zt <- filter(Wt, filter = c(rep(0, 11), 0.6), method = \"recursive\")[-(1:50)]\n",
    "\n",
    "# Plot Zt time series\n",
    "plot.ts(Zt, col = \"blue\", ylab = expression(Z[t]))\n",
    "\n",
    "# Plot ACF and PACF of Zt with maximum lag 96\n",
    "acf(Zt, type = \"correlation\", lag.max = 96)\n",
    "acf(Zt, type = \"partial\", lag.max = 96)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6811e282",
   "metadata": {},
   "source": [
    "It is unlikely that the 12 series (in columns) corresponding to the different months are uncorrelated.\n",
    "To incorporate dependence between these series, we assume now that the ${U_t}$ sequence follows an\n",
    "ARMA $(p, q)$ model,\n",
    "\n",
    "$$\n",
    "\\phi(B) U_t = \\theta(B) W_t, \\quad W_t \\sim WN(0, \\sigma^2).\n",
    "$$\n",
    "\n",
    "Then we have\n",
    "\n",
    "$$\n",
    "\\Phi(B^{12}) X_t = \\Theta(B^{12}) U_t = \\Theta(B^{12}) \\phi^{-1}(B) \\theta(B) W_t,\n",
    "$$\n",
    "\n",
    "which implies\n",
    "\n",
    "$$\n",
    "\\phi(B) \\Phi(B^{12}) X_t = \\theta(B) \\Theta(B^{12}) W_t, \\quad W_t \\sim WN(0, \\sigma^2).\n",
    "$$\n",
    "\n",
    "More generally, we have the SARMA model as\n",
    "$ARMA(p, q) \\times (P, Q)_s$,\n",
    "written as\n",
    "\n",
    "$$\n",
    "\\phi(B) \\Phi(B^{s}) X_t = \\theta(B) \\Theta(B^{s}) W_t, \\quad W_t \\sim WN(0, \\sigma^2),\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\phi(z) = 1 - \\phi_1 z - \\cdots - \\phi_p z^p, \\quad \\Phi(z) = 1 - \\Phi_1 z - \\cdots - \\Phi_P z^P,\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta(z) = 1 + \\theta_1 z + \\cdots + \\theta_q z^q, \\quad \\text{and} \\quad \\Theta(z) = 1 + \\Theta_1 z + \\cdots + \\Theta_Q z^Q.\n",
    "$$\n",
    "\n",
    "For example, consider ARMA $(0, 1) \\times (0, 1)_{12}$ ; i.e.,\n",
    "\n",
    "$$\n",
    "X_t = (1 + \\theta_1 B)(1 + \\Theta_1 B^{12}) W_t = W_t + \\theta_1 W_{t-1} + \\Theta_1 W_{t-12} + \\theta_1 \\Theta_1 W_{t-13}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3178e53",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Number of observations (with extra 50 discarded for initialization)\n",
    "N <- 1050\n",
    "\n",
    "par(bg = \"white\")        \n",
    "\n",
    "# Generate white noise\n",
    "Wt <- rnorm(N, 0, 1)\n",
    "\n",
    "# Set plot margins\n",
    "par(mar = c(4.5, 4.5, 0.1, 0.1))\n",
    "\n",
    "# Define layout matrix for 3 rows and 3 columns (9 plots)\n",
    "design.mat <- matrix(1:9, nrow = 3, ncol = 3)\n",
    "layout(design.mat)\n",
    "\n",
    "# MA(1) process with theta = 0.6\n",
    "Yt <- filter(Wt, sides = 1, filter = c(1, 0.6))[-(1:50)]\n",
    "plot.ts(Yt, col = \"blue\", ylab = expression(Y[t]))\n",
    "acf(Yt, type = \"correlation\", lag.max = 48)\n",
    "acf(Yt, type = \"partial\", lag.max = 48)\n",
    "\n",
    "# MA(1) process with theta = 0.4\n",
    "Yt <- filter(Wt, sides = 1, filter = c(1, 0.4))[-(1:50)]\n",
    "plot.ts(Yt, col = \"blue\", ylab = expression(Y[t]))\n",
    "acf(Yt, type = \"correlation\", lag.max = 48)\n",
    "acf(Yt, type = \"partial\", lag.max = 48)\n",
    "\n",
    "# SARMA(0,1)*(0,1)_12 with theta=0.6 and Theta=0.4\n",
    "# Filter coefficients: MA(1) coeff 0.6 at lag 1, seasonal MA(1) coeff 0.4 at lag 12\n",
    "# The product term 0.6 * 0.4 = 0.24 at lag 13\n",
    "Zt <- filter(Wt, sides = 1, filter = c(1, 0.6, rep(0, 10), 0.4, 0.24))[-(1:50)]\n",
    "plot.ts(Zt, col = \"blue\", ylab = expression(Z[t]))\n",
    "acf(Zt, type = \"correlation\", lag.max = 48)\n",
    "acf(Zt, type = \"partial\", lag.max = 48)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf8857b",
   "metadata": {},
   "source": [
    "**What is an ARMA(1, 1) × (1, 1)$_{12}$?**\n",
    "\n",
    "The model is written as\n",
    "\n",
    "$$\n",
    "(1 - \\phi_1 B)(1 - \\Phi_1 B^{12}) X_t = (1 + \\theta_1 B)(1 + \\Theta_1 B^{12}) W_t,\n",
    "$$\n",
    "\n",
    "which expands to\n",
    "\n",
    "$$\n",
    "X_t - \\phi_1 X_{t-1} - \\Phi_1 X_{t-12} + \\phi_1 \\Phi_1 X_{t-13} = W_t + \\theta_1 W_{t-1} + \\Theta_1 W_{t-12} + \\theta_1 \\Theta_1 W_{t-13}.\n",
    "$$\n",
    "\n",
    "Things get messy, especially when you start dealing with higher orders or more seasonal components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d768e066",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Number of observations\n",
    "N <- 1000\n",
    "\n",
    "par(bg = \"white\")        \n",
    "\n",
    "# Generate white noise\n",
    "Wt <- rnorm(N, 0, 1)\n",
    "\n",
    "# Set plot margins\n",
    "par(mar = c(4.5, 4.5, 0.1, 0.1))\n",
    "\n",
    "# Define layout matrix for 3 rows and 3 columns (9 plots)\n",
    "design.mat <- matrix(1:9, nrow = 3, ncol = 3)\n",
    "layout(design.mat)\n",
    "\n",
    "# ARMA(1,1) with phi = 0.6, theta = 0.4\n",
    "Yt <- arima.sim(model = list(ar = 0.6, ma = 0.4), n = N)\n",
    "plot.ts(Yt, col = \"blue\", ylab = expression(Y[t]))\n",
    "acf(Yt, type = \"correlation\", lag.max = 48)\n",
    "acf(Yt, type = \"partial\", lag.max = 48)\n",
    "\n",
    "# ARMA(1,1) with phi = 0.9, theta = 0.1\n",
    "Yt <- arima.sim(model = list(ar = 0.9, ma = 0.1), n = N)\n",
    "plot.ts(Yt, col = \"blue\", ylab = expression(Y[t]))\n",
    "acf(Yt, type = \"correlation\", lag.max = 48)\n",
    "acf(Yt, type = \"partial\", lag.max = 48)\n",
    "\n",
    "# Seasonal ARMA(1,1)*(1,1)_12 model\n",
    "# phi = 0.6, Phi = 0.9, theta = 0.4, Theta = 0.1\n",
    "# Seasonal AR coefficient at lag 12: 0.9\n",
    "# Seasonal MA coefficient at lag 12: 0.1\n",
    "# Interaction terms for AR and MA seasonal are included (e.g., -0.54, 0.04)\n",
    "Yt <- arima.sim(\n",
    "  model = list(\n",
    "    ar = c(0.6, rep(0, 10), 0.9, -0.54),\n",
    "    ma = c(0.4, rep(0, 10), 0.1, 0.04)\n",
    "  ), \n",
    "  n = N\n",
    ")\n",
    "plot.ts(Yt, col = \"blue\", ylab = expression(Y[t]))\n",
    "acf(Yt, type = \"correlation\", lag.max = 48)\n",
    "acf(Yt, type = \"partial\", lag.max = 48)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7102d2",
   "metadata": {},
   "source": [
    "### 7.3.2 Seasonal ARIMA Models\n",
    "\n",
    "From equation (7.1), we have\n",
    "\n",
    "$$\n",
    "\\Phi(B^{12}) X_t = \\Theta(B^{12}) U_t,\n",
    "$$\n",
    "\n",
    "where initially $U_t$ is white noise.\n",
    "\n",
    "Relaxing this, suppose $U_t$ follows an $ARMA(p, q)$ process, giving a Seasonal ARMA model. Now, consider $U_t$ follows an **ARIMA**$(p, d, q)$ process to account for possible trends in $U_t$, such as in monthly temperature data where there is a seasonal trend:\n",
    "\n",
    "$$\n",
    "\\phi(B)(1 - B)^d U_t = \\theta(B) W_t, \\quad W_t \\sim WN(0, \\sigma^2). \\tag{7.2}\n",
    "$$\n",
    "\n",
    "Then, for $X_t$, we have\n",
    "\n",
    "$$\n",
    "\\Phi(B^{12}) X_t = \\Theta(B^{12}) U_t \\implies \\phi(B) \\Phi(B^{12}) (1 - B)^d X_t = \\Theta(B^{12}) \\theta(B) W_t.\n",
    "$$\n",
    "\n",
    "More generally, with period $ s$,\n",
    "\n",
    "$$\n",
    "\\phi(B) \\Phi(B^{s}) \\left\\{ (1 - B)^d X_t \\right\\} = \\theta(B) \\Theta(B^{s}) W_t, \\quad W_t \\sim WN(0, \\sigma^2).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Can we relax this further?\n",
    "\n",
    "In equation (7.1), $X_t$ satisfies\n",
    "\n",
    "$$\n",
    "\\Phi(B^{12}) X_t = \\Theta(B^{12}) U_t,\n",
    "$$\n",
    "\n",
    "which assumes a stationary structure. But what if $X_t$ itself is **non-stationary** regardless of $U_t$? We then put an ARIMA structure on $X_t$ with a seasonal difference component, assuming\n",
    "\n",
    "$$\n",
    "\\Phi(B^{12}) \\left\\{ (1 - B^{12})^{D} X_t \\right\\} = \\Theta(B^{12}) U_t.\n",
    "$$\n",
    "\n",
    "Combining with (7.2), we get\n",
    "\n",
    "$$\n",
    "\\Phi(B^{12}) \\left\\{ (1 - B^{12})^{D} X_t \\right\\} = \\Theta(B^{12}) U_t \\implies \\phi(B) \\Phi(B^{12}) (1 - B)^d (1 - B^{12})^{D} X_t = \\theta(B) \\Theta(B^{12}) W_t.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Generalizing period $ s = 12$ to any integer $ s$, we finally have the definition of a **Seasonal ARIMA (SARIMA)** model:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\phi(B) \\Phi(B^{s}) (1 - B)^d (1 - B^{s})^{D} X_t = \\theta(B) \\Theta(B^{s}) W_t, \\quad W_t \\sim WN(0, \\sigma^2),\n",
    "}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $\\phi(B) = 1 - \\phi_1 B - \\cdots - \\phi_p B^p$ is the non-seasonal AR polynomial,\n",
    "* $\\theta(B) = 1 + \\theta_1 B + \\cdots + \\theta_q B^q$ is the non-seasonal MA polynomial,\n",
    "* $\\Phi(B^s) = 1 - \\Phi_1 B^s - \\cdots - \\Phi_P B^{Ps}$ is the seasonal AR polynomial,\n",
    "* $\\Theta(B^s) = 1 + \\Theta_1 B^s + \\cdots + \\Theta_Q B^{Qs}$ is the seasonal MA polynomial,\n",
    "* $d$ is the order of non-seasonal differencing,\n",
    "* $D$ is the order of seasonal differencing,\n",
    "* $ s$ is the seasonal period (e.g., 12 for monthly data).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb94ad1e",
   "metadata": {},
   "source": [
    "### The $SARIMA(p, d, q) \\times (P, D, Q)_s$ Process\n",
    "\n",
    "If $d$ and $D$ are non-negative integers, then $\\{X_t\\}$ is said to be a seasonal $ARIMA(p, d, q) \\times (P, D, Q)_s$ process with period $ s$ if the differenced process\n",
    "\n",
    "$$\n",
    "Y_t = (1 - B)^d (1 - B^s)^D X_t\n",
    "$$\n",
    "\n",
    "is a causal ARMA process satisfying\n",
    "\n",
    "$$\n",
    "\\phi(B) \\Phi(B^s) Y_t = \\theta(B) \\Theta(B^s) W_t, \\quad W_t \\sim WN(0, \\sigma^2),\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\phi(z) &= 1 - \\phi_1 z - \\cdots - \\phi_p z^p, \\\\\n",
    "\\Phi(z) &= 1 - \\Phi_1 z - \\cdots - \\Phi_P z^P, \\\\\n",
    "\\theta(z) &= 1 + \\theta_1 z + \\cdots + \\theta_q z^q, \\\\\n",
    "\\Theta(z) &= 1 + \\Theta_1 z + \\cdots + \\Theta_Q z^Q.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Example: $SARIMA(0, 1, 1) \\times (0, 1, 1)_{12}$\n",
    "\n",
    "The model is\n",
    "\n",
    "$$\n",
    "(1 - B)(1 - B^{12}) X_t = (1 + \\theta_1 B)(1 + \\Theta_1 B^{12}) W_t,\n",
    "$$\n",
    "\n",
    "which expands to\n",
    "\n",
    "$$\n",
    "X_t - X_{t-1} - X_{t-12} + X_{t-13} = W_t + \\theta_1 W_{t-1} + \\Theta_1 W_{t-12} + \\theta_1 \\Theta_1 W_{t-13}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f686e9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Number of observations with extra for initialization\n",
    "N <- 1100\n",
    "\n",
    "par(bg = \"white\")        \n",
    "\n",
    "# Generate white noise\n",
    "Wt <- rnorm(N, 0, 1)\n",
    "\n",
    "# Set plot margins and 3-row, 1-column plotting layout\n",
    "par(mar = c(4.5, 4.5, 0.1, 0.1))\n",
    "par(mfrow = c(3, 1))\n",
    "\n",
    "# Step 1: Apply MA filter with coefficients at lag 1 and lag 12\n",
    "# Coefficients: 1 (lag 0), 0.4 (lag 1), 0.6 (lag 12), and 0.24 (lag 13)\n",
    "Yt <- filter(Wt, sides = 1, filter = c(1, 0.4, rep(0, 10), 0.6, 0.24))[-(1:50)]\n",
    "\n",
    "# Step 2: Apply recursive AR filter with coefficients: 1, 0,...,0, -1 (lag 11), 1 (lag 12)\n",
    "Yt <- filter(Yt, filter = c(1, rep(0, 10), -1, 1), method = \"recursive\")[-(1:50)]\n",
    "\n",
    "# Plot the resulting series\n",
    "plot.ts(Yt, col = \"blue\", ylab = expression(Y[t]))\n",
    "\n",
    "# Plot the autocorrelation function (ACF) up to lag 48\n",
    "acf(Yt, type = \"correlation\", lag.max = 48)\n",
    "\n",
    "# Plot the partial autocorrelation function (PACF) up to lag 48\n",
    "acf(Yt, type = \"partial\", lag.max = 48)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7b22a",
   "metadata": {},
   "source": [
    "### SARIMA $(1, 1, 0) \\times (1, 1, 0)_{12}$\n",
    "\n",
    "The model is:\n",
    "\n",
    "$$\n",
    "(1 - \\phi_1 B)(1 - \\Phi_1 B^{12})(1 - B)(1 - B^{12}) X_t = W_t.\n",
    "$$\n",
    "\n",
    "Expanding this, we get:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "W_t =\\ & X_t - (1 + \\phi_1) X_{t-1} + \\phi_1 X_{t-2} \\\\\n",
    "& - (1 + \\Phi_1) X_{t-12} + (1 + \\phi_1 + \\Phi_1 + \\phi_1 \\Phi_1) X_{t-13} - (\\phi_1 + \\phi_1 \\Phi_1) X_{t-14} \\\\\n",
    "& + \\Phi_1 X_{t-24} - (\\Phi_1 + \\phi_1 \\Phi_1) X_{t-25} + \\phi_1 \\Phi_1 X_{t-26}.\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b816fca7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Number of observations\n",
    "N <- 1100\n",
    "\n",
    "par(bg = \"white\")        \n",
    "\n",
    "# Generate white noise\n",
    "Wt <- rnorm(N, 0, 1)\n",
    "\n",
    "# Set plot margins and layout (3 rows, 1 column)\n",
    "par(mar = c(4.5, 4.5, 0.1, 0.1))\n",
    "par(mfrow = c(3, 1))\n",
    "\n",
    "# AR parameters\n",
    "phi <- 0.9    # non-seasonal AR(1)\n",
    "Phi <- 0.8    # seasonal AR(1) at lag 12\n",
    "\n",
    "# Recursive filter coefficients for seasonal ARMA model\n",
    "# Coefficients for AR polynomial:\n",
    "# c(1 + phi, -phi, 0,..., 0, 1 + Phi, ..., -Phi, ...)\n",
    "# The vector length corresponds to seasonal lag 12 effects included\n",
    "\n",
    "coef_vec <- c(\n",
    "  1 + phi,          # lag 0\n",
    "  -phi,             # lag 1\n",
    "  rep(0, 9),        # lags 2 to 10 zero\n",
    "  1 + Phi,          # lag 11 (seasonal lag 12 - 1)\n",
    "  -1 - phi - Phi - phi * Phi,  # lag 12\n",
    "  phi + phi * Phi,            # lag 13\n",
    "  rep(0, 9),        # lags 14 to 22 zero\n",
    "  -Phi,             # lag 23 (seasonal lag 24 - 1)\n",
    "  Phi + phi * Phi,  # lag 24\n",
    "  -phi * Phi        # lag 25\n",
    ")\n",
    "\n",
    "# Apply recursive filter with the coefficient vector to simulate seasonal ARMA\n",
    "Yt <- filter(Wt, filter = coef_vec, method = \"recursive\")[-(1:50)]\n",
    "\n",
    "# Plot the time series\n",
    "plot.ts(Yt, col = \"blue\", ylab = expression(Y[t]))\n",
    "\n",
    "# Plot the autocorrelation function (ACF) up to lag 48\n",
    "acf(Yt, type = \"correlation\", lag.max = 48)\n",
    "\n",
    "# Plot the partial autocorrelation function (PACF) up to lag 48\n",
    "acf(Yt, type = \"partial\", lag.max = 48)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38d1c1d",
   "metadata": {},
   "source": [
    "### Seasonal ARIMA Model Parameter Specification and Estimation\n",
    "\n",
    "* **Period $ s$** is usually set based on domain knowledge about the dataset:\n",
    "\n",
    "  * For example:\n",
    "\n",
    "    * Weather or climate data: $ s = 12$ (12 months per year)\n",
    "    * Financial data: $ s = 4$ (4 quarters per year)\n",
    "* The seasonal differencing order $D$ is rarely greater than 1 in practice.\n",
    "* The seasonal AR and MA orders $P$ and $Q$ are commonly less than 3.\n",
    "\n",
    "---\n",
    "\n",
    "### Parameter Estimation\n",
    "\n",
    "Given the orders $p, d, q, P, D, Q$, we estimate:\n",
    "\n",
    "$$\n",
    "\\phi = (\\phi_1, \\ldots, \\phi_p), \\quad \\theta = (\\theta_1, \\ldots, \\theta_q), \\quad \\Phi = (\\Phi_1, \\ldots, \\Phi_P), \\quad \\Theta = (\\Theta_1, \\ldots, \\Theta_Q), \\quad \\sigma^2.\n",
    "$$\n",
    "\n",
    "Once $d$ and $D$ are fixed, define the differenced series:\n",
    "\n",
    "$$\n",
    "Y_t = (1 - B)^d (1 - B^s)^D X_t,\n",
    "$$\n",
    "\n",
    "which follows an ARMA $(p + sP, \\ q + sQ)$ model, where some coefficients are zero and others are functions of $\\phi, \\theta, \\Phi, \\Theta$.\n",
    "\n",
    "Thus, parameter estimation reduces to fitting an ARMA model to the differenced series $Y_t$, using methods such as Maximum Likelihood Estimation (MLE) or Conditional Least Squares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72687e3c",
   "metadata": {},
   "source": [
    "### 7.4 Regression with Stationary Errors\n",
    "\n",
    "Recall the classical decomposition model for a time series $\\{Y_t\\}$:\n",
    "\n",
    "$$\n",
    "Y_t = m_t + s_t + Z_t \\quad (7.3)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "* $m_t$ is the **trend component**,\n",
    "* $ s_t$ is the **periodic (seasonal) component** with known period $ s$, satisfying\n",
    "\n",
    "  $$\n",
    "  s_{t-s} = s_t \\quad \\text{for all integers } t,\n",
    "  $$\n",
    "\n",
    "  and\n",
    "\n",
    "  $$\n",
    "  \\sum_{j=1}^s s_j = 0,\n",
    "  $$\n",
    "* $Z_t$ is a **stationary process with zero mean**.\n",
    "\n",
    "Often, $m_t$ and $ s_t$ are treated as deterministic (non-random).\n",
    "The SARIMA model can capture stochastic $ s_t$, and can also handle deterministic $m_t$ and $ s_t$ through differencing. However, differencing to remove deterministic $m_t$ or $ s_t$ can lead to **over-differencing** of $Z_t$, which is undesirable.\n",
    "\n",
    "---\n",
    "\n",
    "### Alternative Approach: Regression with Stationary Errors\n",
    "\n",
    "Instead of differencing, model (7.3) can be treated as a **regression model with stationary errors**.\n",
    "\n",
    "---\n",
    "\n",
    "### Standard Linear Regression Model\n",
    "\n",
    "$$\n",
    "Y = X \\beta + Z,\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $Y = (Y_1, \\ldots, Y_n)^\\top$ is the vector of responses,\n",
    "* $X$ is an $n \\times k$ matrix with rows $x_t^\\top$, i.e.,\n",
    "\n",
    "  $$\n",
    "  X = \\begin{pmatrix} x_1^\\top \\\\ \\vdots \\\\ x_n^\\top \\end{pmatrix},\n",
    "  $$\n",
    "* $\\beta = (\\beta_1, \\ldots, \\beta_k)^\\top$ are the regression coefficients,\n",
    "* $Z = (Z_1, \\ldots, Z_n)^\\top$ is a vector of white noise errors: $Z_t \\sim WN(0, \\sigma^2)$.\n",
    "\n",
    "---\n",
    "\n",
    "### Examples of Regressions\n",
    "\n",
    "1. **Trend model:**\n",
    "\n",
    "$$\n",
    "Y_t = \\beta_1 + \\beta_2 t + Z_t,\n",
    "$$\n",
    "\n",
    "where the trend $m_t$ is modeled by the linear function $\\beta_1 + \\beta_2 t$.\n",
    "\n",
    "2. **Seasonality model:**\n",
    "\n",
    "$$\n",
    "Y_t = \\beta_1 + \\beta_2 \\cos(2\\pi \\delta t) + \\beta_3 \\sin(2\\pi \\delta t) + Z_t,\n",
    "$$\n",
    "\n",
    "which accounts for seasonal components with frequency $\\delta$.\n",
    "\n",
    "Both examples can be expressed as:\n",
    "\n",
    "$$\n",
    "Y = X \\beta + Z.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Ordinary Least Squares (OLS) Estimation\n",
    "\n",
    "The OLS estimator $\\hat{\\beta}_{\\text{ols}}$ minimizes the sum of squared errors:\n",
    "\n",
    "$$\n",
    "S(\\beta) = \\sum_{t=1}^n (Y_t - x_t^\\top \\beta)^2 = (Y - X \\beta)^\\top (Y - X \\beta).\n",
    "$$\n",
    "\n",
    "Setting the gradient $\\nabla_\\beta S(\\beta) = 0$ yields the **normal equations**:\n",
    "\n",
    "$$\n",
    "X^\\top X \\hat{\\beta} = X^\\top Y.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad042dd9",
   "metadata": {},
   "source": [
    "Since\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_{\\text{ols}} = (X^\\top X)^{-1} X^\\top Y,\n",
    "$$\n",
    "\n",
    "provided that $X^\\top X$ has full rank.\n",
    "\n",
    "If $\\{Z_t\\}$ are white noise, then $\\hat{\\beta}_{\\text{ols}}$ is the **best linear unbiased estimator (BLUE)** of $\\beta$. This means that for any other unbiased estimator $\\tilde{\\beta}$,\n",
    "\n",
    "$$\n",
    "\\operatorname{Var}(c^\\top \\hat{\\beta}_{\\text{ols}}) \\leq \\operatorname{Var}(c^\\top \\tilde{\\beta})\n",
    "$$\n",
    "\n",
    "for any constant vector $c$. Furthermore, the covariance matrix of $\\hat{\\beta}_{\\text{ols}}$ is\n",
    "\n",
    "$$\n",
    "\\operatorname{Cov}(\\hat{\\beta}_{\\text{ols}}) = \\sigma^2 (X^\\top X)^{-1}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### However, for time series:\n",
    "\n",
    "**Uncorrelated errors** $Z_t$ are usually unrealistic. More realistically, the error term $\\{Z_t\\}$ comes from a **stationary process with zero mean**. For example, $\\{Z_t\\}$ might follow a causal ARMA(p, q) process:\n",
    "\n",
    "$$\n",
    "\\phi(B) Z_t = \\theta(B) W_t, \\quad W_t \\sim WN(0, \\sigma^2).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### What should we do in this case?\n",
    "\n",
    "The solution is the **Generalized Least Squares (GLS)** estimator $\\hat{\\beta}_{\\text{gls}}$, which minimizes the weighted sum of squares:\n",
    "\n",
    "$$\n",
    "S(\\beta) = (Y - X\\beta)^\\top \\Gamma_n^{-1} (Y - X\\beta),\n",
    "$$\n",
    "\n",
    "where $\\Gamma_n = \\operatorname{Cov}(Z)$ is the covariance matrix of the error vector $Z = (Z_1, \\ldots, Z_n)^\\top$.\n",
    "\n",
    "The solution is\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_{\\text{gls}} = (X^\\top \\Gamma_n^{-1} X)^{-1} X^\\top \\Gamma_n^{-1} Y.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Why does this work?\n",
    "\n",
    "Recall from the MLE derivation for ARMA(p, q) processes, the covariance matrix $\\Gamma_n$ can be decomposed as\n",
    "\n",
    "$$\n",
    "\\Gamma_n = C D C^\\top,\n",
    "$$\n",
    "\n",
    "where $C$ and $D$ are matrices obtained from the covariance structure.\n",
    "\n",
    "By multiplying both sides of the model by $D^{-1/2} C^{-1}$, we get\n",
    "\n",
    "$$\n",
    "D^{-1/2} C^{-1} Y = D^{-1/2} C^{-1} X \\beta + D^{-1/2} C^{-1} Z.\n",
    "$$\n",
    "\n",
    "Now, the covariance of the transformed errors is\n",
    "\n",
    "$$\n",
    "\\operatorname{Cov}(D^{-1/2} C^{-1} Z) = D^{-1/2} C^{-1} \\Gamma_n (D^{-1/2} C^{-1})^\\top = I_n,\n",
    "$$\n",
    "\n",
    "where $I_n$ is the $n \\times n$ identity matrix.\n",
    "\n",
    "---\n",
    "\n",
    "### Hence, defining\n",
    "\n",
    "$$\n",
    "Y_e = D^{-1/2} C^{-1} Y, \\quad X_e = D^{-1/2} C^{-1} X, \\quad Z_e = D^{-1/2} C^{-1} Z,\n",
    "$$\n",
    "\n",
    "we have a transformed model\n",
    "\n",
    "$$\n",
    "Y_e = X_e \\beta + Z_e, \\quad \\text{with } Z_e \\sim WN(0, I_n).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### By applying OLS to the transformed model, the estimator is\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_{\\text{gls}} = (X_e^\\top X_e)^{-1} X_e^\\top Y_e = (X^\\top \\Gamma_n^{-1} X)^{-1} X^\\top \\Gamma_n^{-1} Y,\n",
    "$$\n",
    "\n",
    "which is the GLS estimator in the original model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ecba84",
   "metadata": {},
   "source": [
    "In principle, we can use MLE under a Gaussian assumption to estimate all parameters in the model\n",
    "\n",
    "$$\n",
    "Y = X\\beta + Z.\n",
    "$$\n",
    "\n",
    "Note that all parameters include $\\beta$ and the $ARMA(p, q)$ model for $Z$. However, in practice, the following iterative scheme for parameter estimation often works well:\n",
    "\n",
    "1. Fit the model by OLS and obtain $\\hat{\\beta}_{ols}$;\n",
    "2. Compute the residuals\n",
    "\n",
    "   $$\n",
    "   Y_t - x_t^\\top \\hat{\\beta}_{ols};\n",
    "   $$\n",
    "3. Fit an $ARMA(p, q)$ or other stationary model to the residuals;\n",
    "4. Using the fitted model, compute $\\hat{\\beta}_{gls}$ and form residuals\n",
    "\n",
    "   $$\n",
    "   Y_t - x_t^\\top \\hat{\\beta}_{gls};\n",
    "   $$\n",
    "5. Fit the same model to the new residuals again;\n",
    "6. Repeat steps 4 and 5 until parameter estimates have stabilized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe37346",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
