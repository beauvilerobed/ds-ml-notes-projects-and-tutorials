{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Networks (CNNs)\n",
    "\n",
    "**Convolutional Networks** are specialized neural networks designed for data with a **grid-like structure**, such as:\n",
    "\n",
    "* **1-D grids:** time series, audio signals, etc.\n",
    "* **2-D grids:** images, video frames, etc.\n",
    "\n",
    "CNNs replace some or all **matrix multiplications** in standard neural networks with **convolutions**, a linear operation designed to capture **local patterns** efficiently.\n",
    "\n",
    "## The Convolution Operation\n",
    "\n",
    "Convolution is a mathematical operation between two functions. For **continuous 1-D functions**:\n",
    "\n",
    "$$\n",
    "s(t) = (x * w)(t) = \\int_{-\\infty}^{\\infty} x(a) w(t-a) , da\n",
    "$$\n",
    "\n",
    "For **discrete signals**, the integral becomes a sum:\n",
    "\n",
    "$$\n",
    "s[t] = (x * w)[t] = \\sum_{a=-\\infty}^{\\infty} x[a] w[t-a]\n",
    "$$\n",
    "\n",
    "* $x$ = input (e.g., signal or image)\n",
    "* $w$ = kernel/filter\n",
    "* $s$ = output (feature map)\n",
    "\n",
    "For **2-D inputs** (images):\n",
    "\n",
    "$$\n",
    "S[i,j] = (I * K)[i,j] = \\sum_m \\sum_n I[m,n] K[i-m, j-n]\n",
    "$$\n",
    "\n",
    "Convolution is **commutative**:\n",
    "\n",
    "$$\n",
    "I * K = K * I\n",
    "$$\n",
    "\n",
    "Neural networks often implement **cross-correlation**, which is similar but **without flipping the kernel**:\n",
    "\n",
    "$$\n",
    "S[i,j] = \\sum_m \\sum_n I[i+m, j+n] K[m,n]\n",
    "$$\n",
    "\n",
    "<img src=\"img/matrix.png\">\n",
    "\n",
    "### Numerical Example: 1-D Convolution\n",
    "\n",
    "Let $x = [1,2,3,4]$ and $w = [1,0,-1]$ (a simple edge detector).\n",
    "\n",
    "Compute $s = x * w$ using discrete convolution (\"valid\" positions only):\n",
    "\n",
    "* Position 0: $s[0] = 1*1 + 2*0 + 3*(-1) = -2$\n",
    "* Position 1: $s[1] = 2*1 + 3*0 + 4*(-1) = -2$\n",
    "\n",
    "Result: $s = [-2, -2]$\n",
    "\n",
    "\n",
    "\n",
    "## Sparse Interactions & Parameter Sharing\n",
    "\n",
    "* **Sparse interactions:** Each output unit depends only on a **small local patch** of the input.\n",
    "* **Parameter sharing:** The same kernel is applied across all input locations.\n",
    "\n",
    "If input has $m$ units and output has $n$ units:\n",
    "\n",
    "* Fully connected layer: $m \\times n$ parameters\n",
    "* Convolution with kernel size $k$: $k \\times n$ parameters\n",
    "\n",
    "This **reduces memory** and **computational cost**, while still capturing complex patterns.\n",
    "\n",
    "<img src=\"img/ex.png\" height=\"10%\" weight=\"10%\">\n",
    "\n",
    "<img src=\"img/ex2.png\" height=\"10%\" weight=\"10%\">\n",
    "\n",
    "<img src=\"img/ex3.png\" height=\"10%\" weight=\"10%\">\n",
    "\n",
    "\n",
    "\n",
    "## Equivariance to Translation\n",
    "\n",
    "A function $f$ is **equivariant** to $g$ if:\n",
    "\n",
    "$$\n",
    "f(g(x)) = g(f(x))\n",
    "$$\n",
    "\n",
    "For convolution, shifting the input by one pixel shifts the output by the same amount:\n",
    "\n",
    "* Let $I'(x, y) = I(x-1, y)$\n",
    "* Then $(I' * K) = (I * K)'$\n",
    "\n",
    "This is why CNNs are excellent for **vision tasks**, where objects can appear at any location.\n",
    "\n",
    "\n",
    "\n",
    "## Pooling\n",
    "\n",
    "Pooling reduces spatial dimensions and introduces **translation invariance**. Common pooling operations:\n",
    "\n",
    "* **Max pooling:** $s[i,j] = \\max {S[\\text{neighbors of } (i,j)]}$\n",
    "* **Average pooling:** $s[i,j] = \\frac{1}{N}\\sum S[\\text{neighbors of } (i,j)]$\n",
    "* **L2 pooling:** $s[i,j] = \\sqrt{\\sum S[\\text{neighbors of } (i,j)]^2}$\n",
    "\n",
    "Pooling also **reduces computation** for subsequent layers.\n",
    "\n",
    "<img src=\"img/ex5.png\" height=\"10%\" weight=\"10%\">\n",
    "\n",
    "### Example: 1-D Max Pooling\n",
    "\n",
    "Let $S = [1, 3, 2, 4]$, pool size = 2, stride = 2:\n",
    "\n",
    "* Pool region 1: $\\max(1,3) = 3$\n",
    "* Pool region 2: $\\max(2,4) = 4$\n",
    "\n",
    "Result: $s_\\text{pooled} = [3, 4]$\n",
    "\n",
    "<img src=\"img/ex6.png\" height=\"10%\" weight=\"10%\">\n",
    "\n",
    "<img src=\"img/ex7.png\" height=\"10%\" weight=\"10%\">\n",
    "\n",
    "<img src=\"img/ex8.png\" height=\"10%\" weight=\"10%\">\n",
    "\n",
    "\n",
    "\n",
    "## Efficiency Example\n",
    "\n",
    "Consider edge detection in an image:\n",
    "\n",
    "* Input: $320 \\times 280$\n",
    "* Output (kernel width 2, edge detection horizontally): $319 \\times 280$\n",
    "\n",
    "**Convolution operations**:\n",
    "\n",
    "$$\n",
    "\\text{FLOPs} = 319 \\times 280 \\times 2 \\approx 178,640\n",
    "$$\n",
    "\n",
    "**Matrix multiplication approach** would require:\n",
    "\n",
    "$$\n",
    "320 \\times 280 \\times 319 \\times 280 \\approx 8 \\text{ billion entries}\n",
    "$$\n",
    "\n",
    "Convolution is therefore **orders of magnitude more efficient**.\n",
    "\n",
    "<img src=\"img/ex4.png\" height=\"10%\" weight=\"10%\">\n",
    "\n",
    "\n",
    "\n",
    "## Summary of Convolutional Layers\n",
    "\n",
    "1. **Convolution:** extract local features using a shared kernel\n",
    "2. **Nonlinearity:** apply activation function (e.g., ReLU)\n",
    "3. **Pooling:** reduce dimensions, gain invariance to small translations\n",
    "\n",
    "<img src=\"img/ex9.png\" height=\"10%\" weight=\"10%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
