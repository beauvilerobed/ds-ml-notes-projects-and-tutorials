{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks\n",
    "\n",
    "# 1. What Is an Artificial Neural Network?\n",
    "\n",
    "An **artificial neural network (ANN)** is a function built by connecting simple computational units called *neurons*.\n",
    "Mathematically, an ANN with layers $1,\\dots,L$ computes a function\n",
    "$$\n",
    "f_\\theta(x) = A_L \\circ \\phi_{L-1} \\circ A_{L-1} \\circ \\cdots \\circ \\phi_1 \\circ A_1(x),\n",
    "$$\n",
    "where each $A_i$ is an affine map, and each $\\phi_i$ is an activation applied componentwise.\n",
    "\n",
    "Even though each neuron is simple, many connected together can represent very complicated functions—this is the main reason ANNs power modern AI (vision, speech, robotics, etc.).\n",
    "\n",
    "\n",
    "\n",
    "# 2. Online Learning\n",
    "\n",
    "**Online learning** means learning from data that arrives one piece at a time:\n",
    "$$(x_1,y_1), (x_2,y_2),\\dots$$\n",
    "\n",
    "At time $t$ an online algorithm updates its parameters $\\theta_t$ using only the data seen so far. This is how systems like speech recognition or financial prediction operate. In contrast, **batch learning** would require all data at once.\n",
    "\n",
    "Online learning is more realistic in many real-world settings and more efficient when datasets are huge.\n",
    "\n",
    "\n",
    "\n",
    "# 3. Neurons\n",
    "\n",
    "A biological neuron fires when its input exceeds a threshold. The simplest mathematical model replicating this idea uses the **step function**:\n",
    "\n",
    "$$\n",
    "H(x) =\n",
    "\\begin{cases}\n",
    "1, & x\\ge 0,\\\n",
    "0, & x<0.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "To give a neuron multiple inputs, we compute a *weighted sum* and then apply the activation:\n",
    "\n",
    "$$\n",
    "y = H(w\\cdot x + b).\n",
    "$$\n",
    "\n",
    "The boundary between firing and not firing is the hyperplane\n",
    "$$\n",
    "w\\cdot x + b = 0.\n",
    "$$\n",
    "\n",
    "This makes the neuron a **linear classifier**.\n",
    "\n",
    "![title](img/picture.png)\n",
    "\n",
    "\n",
    "\n",
    "# 4. The Sigmoid Function\n",
    "\n",
    "The step function is useful conceptually but too “hard” for learning. A smoother alternative that behaves similarly is the **sigmoid**:\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1+e^{-x}}.\n",
    "$$\n",
    "\n",
    "It stays between $0$ and $1$ and transitions from low to high around $x=0$. It is differentiable, which is essential for gradient-based learning.\n",
    "\n",
    "![title](img/picture2.png)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Viewing ANNs as Graphs\n",
    "\n",
    "An ANN can be drawn as a **directed graph**:\n",
    "\n",
    "* each node is a neuron,\n",
    "* each directed edge carries a number (the output of another neuron),\n",
    "* edges have weights.\n",
    "\n",
    "If no cycles occur, the graph is a **directed acyclic graph (DAG)**, meaning computation flows forward only. These are **feedforward networks**.\n",
    "\n",
    "If cycles are allowed, we obtain **recurrent neural networks (RNNs)**, used for sequence data.\n",
    "\n",
    "![title](img/picture3.png)\n",
    "\n",
    "\n",
    "\n",
    "# 6. Layers\n",
    "\n",
    "Neurons that depend on the same preceding computations form a **layer**.\n",
    "Thus an ANN is typically grouped as:\n",
    "\n",
    "* **input layer** $l_0$\n",
    "* **hidden layers** $l_1, \\dots, l_{L-1}$\n",
    "* **output layer** $l_L$\n",
    "\n",
    "Layers help us visualize how information flows through the network.\n",
    "\n",
    "![title](img/picture5.png)\n",
    "\n",
    "\n",
    "\n",
    "# 7. The Universal Approximation Theorem\n",
    "\n",
    "One of the most important facts about neural networks is:\n",
    "\n",
    "## Theorem (Universal Approximation, simplified)\n",
    "\n",
    "Let $K\\subset\\mathbb{R}^n$ be compact and let $f:K\\to\\mathbb{R}$ be continuous.\n",
    "Then for any $\\varepsilon>0$ there exists a neural network with **one hidden layer** and a sigmoidal activation such that\n",
    "$$\n",
    "|f(x) - \\hat f(x)| < \\varepsilon\n",
    "\\quad\\text{for all } x\\in K.\n",
    "$$\n",
    "\n",
    "In short: **neural networks with enough hidden units can approximate any continuous function as closely as we want.**\n",
    "\n",
    "This does *not* say learning is easy; it only establishes that the representation is powerful enough.\n",
    "\n",
    "\n",
    "\n",
    "# 8. Training: Loss Functions\n",
    "\n",
    "Given data $(x_i,y_i)$, we measure how well a network $f_\\theta$ fits them via a **loss function**. A common choice is the empirical loss:\n",
    "\n",
    "$$\n",
    "E(\\theta) = \\frac{1}{N} \\sum_{i=1}^N L(f_\\theta(x_i), y_i).\n",
    "$$\n",
    "\n",
    "Typical losses:\n",
    "\n",
    "* **MSE** for regression: $L(u,v)=|u-v|^2$\n",
    "* **Cross-entropy** for classification\n",
    "\n",
    "We want to adjust $\\theta$ so that $E(\\theta)$ is small.\n",
    "\n",
    "\n",
    "# 9. Gradient Descent\n",
    "\n",
    "Because $E(\\theta)$ is usually too complicated to minimize exactly, we use **gradient descent**:\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\eta_t \\nabla_\\theta E(\\theta_t),\n",
    "$$\n",
    "\n",
    "where $\\eta_t$ is a learning rate.\n",
    "\n",
    "Intuition: the gradient points uphill; subtracting it moves downhill and reduces the loss.\n",
    "\n",
    "When data arrives one point at a time, the same idea yields **stochastic / online gradient descent**, which adjusts $\\theta$ gradually and continuously.\n",
    "\n",
    "\n",
    "\n",
    "# 10. Backpropagation\n",
    "\n",
    "**Backpropagation** is the algorithm that makes gradient descent feasible for deep networks. It applies the chain rule efficiently through the layers.\n",
    "\n",
    "Key idea:\n",
    "\n",
    "1. Compute the outputs forward.\n",
    "2. Compute how changes in each neuron affect the final loss by propagating “error signals” backward.\n",
    "3. Use these signals to compute gradients with respect to all weights and biases.\n",
    "\n",
    "## Theorem (Correctness of Backpropagation, intuitive)\n",
    "\n",
    "For any feedforward network with differentiable activations, backpropagation computes the true gradient\n",
    "$$\n",
    "\\nabla_\\theta E(\\theta)\n",
    "$$\n",
    "using a number of operations proportional to the number of connections in the network.\n",
    "\n",
    "This made training deep networks practical.\n",
    "\n",
    "For recurrent networks, the same idea is applied to the **unfolded** network over time, yielding *Backpropagation Through Time (BPTT)*.\n",
    "\n",
    "\n",
    "\n",
    "# 11. Putting It All Together\n",
    "\n",
    "An ANN:\n",
    "\n",
    "* takes in an input vector $x$,\n",
    "* transforms it through layers of affine maps and activations,\n",
    "* outputs a prediction $f_\\theta(x)$,\n",
    "* and learns by adjusting weights and biases to reduce a loss function.\n",
    "\n",
    "Despite its simple components, the network can learn highly nonlinear functions, thanks to the universal approximation theorem, gradient-based optimization, and the expressive power of layered computation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation\n",
    "\n",
    "We consider a feedforward network with $L$ layers. Dimensions:\n",
    "\n",
    "* Input: $a_0 = x \\in \\mathbb{R}^{n_0}$\n",
    "* Layer $\\ell$ pre-activation: $z_\\ell \\in \\mathbb{R}^{n_\\ell}$\n",
    "* Layer $\\ell$ activation: $a_\\ell \\in \\mathbb{R}^{n_\\ell}$\n",
    "* Weights: $W_\\ell \\in \\mathbb{R}^{n_\\ell \\times n_{\\ell-1}}$\n",
    "* Biases: $b_\\ell \\in \\mathbb{R}^{n_\\ell}$\n",
    "\n",
    "Forward propagation:\n",
    "\n",
    "$\n",
    "z_\\ell = W_\\ell a_{\\ell-1} + b_\\ell,\n",
    "\\qquad\n",
    "a_\\ell = \\phi_\\ell(z_\\ell)\n",
    "$\n",
    "\n",
    "Notation:\n",
    "\n",
    "* $\\phi_\\ell'(z_\\ell)$ elementwise derivative\n",
    "* $\\operatorname{diag}(\\phi_\\ell'(z_\\ell))$ diagonal Jacobian\n",
    "* $\\odot$ elementwise product\n",
    "\n",
    "# Forward Pass (Vectorized)\n",
    "\n",
    "For $\\ell=1,\\dots,L$:\n",
    "\n",
    "$\n",
    "z_\\ell = W_\\ell a_{\\ell-1} + b_\\ell,\n",
    "\\qquad\n",
    "a_\\ell = \\phi_\\ell(z_\\ell)\n",
    "$\n",
    "\n",
    "Loss: $L(a_L,y)$.\n",
    "\n",
    "# Error Signal\n",
    "\n",
    "Define\n",
    "\n",
    "$$\n",
    "\\delta_\\ell := \\frac{\\partial L}{\\partial z_\\ell}\n",
    "$$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_\\ell} = \\delta_\\ell a_{\\ell-1}^\\top,\n",
    "\\qquad\n",
    "\\frac{\\partial L}{\\partial b_\\ell} = \\delta_\\ell\n",
    "$$\n",
    "\n",
    "# Output Layer\n",
    "\n",
    "$$\n",
    "\\delta_L\n",
    "= \\frac{\\partial L}{\\partial a_L}\\odot \\phi_L'(z_L)\n",
    "= \\operatorname{diag}(\\phi_L'(z_L))\\frac{\\partial L}{\\partial a_L}\n",
    "$$\n",
    "\n",
    "# Hidden Layers\n",
    "\n",
    "For $\\ell=L-1,\\dots,1$:\n",
    "\n",
    "$$\n",
    "\\delta_\\ell\n",
    "= (W_{\\ell+1}^\\top \\delta_{\\ell+1}) \\odot \\phi_\\ell'(z_\\ell)\n",
    "= \\operatorname{diag}(\\phi_\\ell'(z_\\ell))W_{\\ell+1}^\\top\\delta_{\\ell+1}\n",
    "$$\n",
    "\n",
    "# Parameter Gradients\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z_\\ell}{\\partial W_\\ell}=a_{\\ell-1}^\\top,\n",
    "\\qquad\n",
    "\\frac{\\partial z_\\ell}{\\partial b_\\ell}=I\n",
    "$$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_\\ell}=\\delta_\\ell a_{\\ell-1}^\\top,\n",
    "\\qquad\n",
    "\\frac{\\partial L}{\\partial b_\\ell}=\\delta_\\ell\n",
    "$$\n",
    "\n",
    "# Backpropagation Summary\n",
    "\n",
    "Forward:\n",
    "\n",
    "$$\n",
    "z_\\ell=W_\\ell a_{\\ell-1}+b_\\ell,\\qquad a_\\ell=\\phi_\\ell(z_\\ell).\n",
    "$$\n",
    "\n",
    "Backward:\n",
    "\n",
    "$$\n",
    "\\delta_L=\\frac{\\partial L}{\\partial a_L}\\odot \\phi_L'(z_L),\n",
    "\\qquad\n",
    "\\delta_\\ell=(W_{\\ell+1}^\\top\\delta_{\\ell+1})\\odot \\phi_\\ell'(z_\\ell)\n",
    "$$\n",
    "\n",
    "Gradients:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_\\ell}=\\delta_\\ell a_{\\ell-1}^\\top,\n",
    "\\qquad\n",
    "\\frac{\\partial L}{\\partial b_\\ell}=\\delta_\\ell\n",
    "$$\n",
    "\n",
    "# Gradient Descent and Convergence\n",
    "\n",
    "We study gradient descent on a differentiable function $f:\\mathbb{R}^p \\to \\mathbb{R}$:\n",
    "\n",
    "$$\n",
    "\\theta_{k+1} = \\theta_k - \\eta \\nabla f(\\theta_k).\n",
    "$$\n",
    "\n",
    "Assume:\n",
    "\n",
    "* $f$ is convex\n",
    "* $\\nabla f$ is $L$-Lipschitz (smooth):\n",
    "  $$\n",
    "  |\\nabla f(u) - \\nabla f(v)| \\le L |u-v|\n",
    "  $$\n",
    "  equivalently\n",
    "  $$\n",
    "  f(v) \\le f(u) + \\nabla f(u)^\\top (v-u) + \\frac{L}{2}|v-u|^2\n",
    "  $$\n",
    "* learning rate $0 < \\eta < 2/L$\n",
    "\n",
    "These are the standard assumptions for convergence of gradient descent.\n",
    "\n",
    "\n",
    "\n",
    "# Monotone Decrease\n",
    "\n",
    "Apply smoothness with\n",
    "$u=\\theta_k$,\n",
    "$v=\\theta_{k+1} = \\theta_k - \\eta\\nabla f(\\theta_k)$:\n",
    "\n",
    "$$\n",
    "f(\\theta_{k+1})\n",
    "\\le\n",
    "f(\\theta_k) - \\eta |\\nabla f(\\theta_k)|^2 + \\frac{L}{2}\\eta^2 |\\nabla f(\\theta_k)|^2.\n",
    "$$\n",
    "\n",
    "Factor:\n",
    "\n",
    "$$\n",
    "f(\\theta_{k+1})\n",
    "\\le\n",
    "f(\\theta_k)\n",
    "-\n",
    "\\left(\\eta - \\frac{L\\eta^2}{2}\\right)\n",
    "|\\nabla f(\\theta_k)|^2.\n",
    "$$\n",
    "\n",
    "Because $0<\\eta<2/L$, the coefficient is positive, so\n",
    "\n",
    "$$\n",
    "f(\\theta_{k+1}) \\le f(\\theta_k),\n",
    "$$\n",
    "\n",
    "with strict inequality unless $\\nabla f(\\theta_k)=0$.\n",
    "\n",
    "Gradient descent is therefore a **descent method**.\n",
    "\n",
    "\n",
    "\n",
    "# Bound on Gradient Norms\n",
    "\n",
    "From the same inequality:\n",
    "\n",
    "$$\n",
    "f(\\theta_k)-f(\\theta_{k+1})\n",
    "\\ge\n",
    "\\left(\\eta - \\frac{L\\eta^2}{2}\\right)|\\nabla f(\\theta_k)|^2.\n",
    "$$\n",
    "\n",
    "Summing for $k=0,\\dots,T-1$:\n",
    "\n",
    "$$\n",
    "\\sum_{k=0}^{T-1}|\\nabla f(\\theta_k)|^2\n",
    "\\le\n",
    "\\frac{f(\\theta_0)-f(\\theta^*)}\n",
    "{\\eta - \\frac{L\\eta^2}{2}}.\n",
    "$$\n",
    "\n",
    "Thus the smallest gradient norm up to step $T$ satisfies\n",
    "\n",
    "$$\n",
    "\\min_{k<T} |\\nabla f(\\theta_k)|^2\n",
    "\\le\n",
    "\\frac{f(\\theta_0)-f(\\theta^*)}{T\\left(\\eta - \\frac{L\\eta^2}{2}\\right)},\n",
    "$$\n",
    "\n",
    "so $|\\nabla f(\\theta_k)| \\to 0$ at rate $O(1/\\sqrt{k})$\n",
    "and the squared norm decreases as $O(1/k)$.\n",
    "\n",
    "\n",
    "# Convergence of Function Values\n",
    "\n",
    "We want to bound the suboptimality\n",
    "\n",
    "$$\n",
    "f(\\theta_k)-f(\\theta^*)\n",
    "$$\n",
    "\n",
    "for convex, $L$-smooth functions.\n",
    "\n",
    "We use only **two facts**:\n",
    "\n",
    "1. **Convexity**\n",
    "   $$\n",
    "   f(u) \\ge f(v) + \\nabla f(v)^\\top(u-v)\n",
    "   $$\n",
    "   or equivalently\n",
    "   $$\n",
    "   f(v)-f(u) \\le \\nabla f(v)^\\top (v-u).\n",
    "   $$\n",
    "\n",
    "2. **Smoothness**\n",
    "   $$\n",
    "   |\\nabla f(x)-\\nabla f(y)|\\le L|x-y|.\n",
    "   $$\n",
    "\n",
    "Baillon–Haddad or Cocoercivity (for convex, L-smooth functions) and 1. implies an upper bound on the gradient:\n",
    "\n",
    "$$\n",
    "|\\nabla f(x)|^2 \\le 2L\\bigl(f(x)-f(\\theta^*)\\bigr).\n",
    "$$\n",
    "\n",
    "(This follows by applying smoothness to the minimizer where $\\nabla f(\\theta^*)=0$.)\n",
    "\n",
    "Expand the squared distance to the minimizer\n",
    "\n",
    "Consider the basic identity:\n",
    "\n",
    "$$\n",
    "|\\theta_{k+1}-\\theta^*|^2\n",
    "=\n",
    "|\\theta_k - \\eta\\nabla f(\\theta_k) - \\theta^*|^2.\n",
    "$$\n",
    "\n",
    "Expand:\n",
    "\n",
    "$$\n",
    "|\\theta_{k+1}-\\theta^*|^2\n",
    "=\n",
    "|\\theta_k-\\theta^*|^2 - 2\\eta\\nabla f(\\theta_k)^\\top(\\theta_k-\\theta^*)\n",
    "\n",
    "+ \\eta^2|\\nabla f(\\theta_k)|^2.\n",
    "  $$\n",
    "\n",
    "Use convexity to replace the inner product\n",
    "\n",
    "Convexity gives:\n",
    "\n",
    "$$\n",
    "f(\\theta_k)-f(\\theta^*)\n",
    "\\le\n",
    "\\nabla f(\\theta_k)^\\top(\\theta_k-\\theta^*).\n",
    "$$\n",
    "\n",
    "Insert this lower bound into the previous expansion:\n",
    "\n",
    "$$\n",
    "|\\theta_{k+1}-\\theta^*|^2\n",
    "\\le\n",
    "|\\theta_k-\\theta^*|^2 - 2\\eta \\bigl(f(\\theta_k)-f(\\theta^*)\\bigr)\n",
    "\n",
    "+ \\eta^2|\\nabla f(\\theta_k)|^2.\n",
    "  $$\n",
    "\n",
    "Use smoothness and to upper-bound the gradient norm\n",
    "\n",
    "Baillon–Haddad or Cocoercivity (for convex, L-smooth functions) and 1. implies:\n",
    "\n",
    "$$\n",
    "|\\nabla f(\\theta_k)|^2\n",
    "\\le\n",
    "2L\\bigl(f(\\theta_k)-f(\\theta^*)\\bigr).\n",
    "$$\n",
    "\n",
    "Plug in:\n",
    "\n",
    "$$\n",
    "|\\theta_{k+1}-\\theta^*|^2\n",
    "\\le\n",
    "|\\theta_k-\\theta^*|^2\n",
    "\n",
    "- 2\\eta \\bigl(f(\\theta_k)-f(\\theta^*)\\bigr)\n",
    "\n",
    "+ 2L\\eta^2 \\bigl(f(\\theta_k)-f(\\theta^*)\\bigr).\n",
    "  $$\n",
    "\n",
    "Factor the suboptimality:\n",
    "\n",
    "$$\n",
    "|\\theta_{k+1}-\\theta^*|^2\n",
    "\\le\n",
    "|\\theta_k-\\theta^*|^2\n",
    "\n",
    "- \\eta(2 - \\eta L)\\bigl(f(\\theta_k) - f(\\theta^*)\\bigr).\n",
    "  $$\n",
    "\n",
    "Because $0<\\eta<2/L$, the factor $(2-\\eta L)$ is positive.\n",
    "\n",
    "Rearrange to isolate the suboptimality\n",
    "\n",
    "$$\n",
    "f(\\theta_k)-f(\\theta^*)\n",
    "\\le\n",
    "\\frac{|\\theta_k-\\theta^*|^2 - |\\theta_{k+1}-\\theta^*|^2}\n",
    "{\\eta(2-\\eta L)}.\n",
    "$$\n",
    "\n",
    "This is the key inequality.\n",
    "\n",
    "Sum over iterations\n",
    "\n",
    "Sum from $k=0$ to $T-1$:\n",
    "\n",
    "Left side is a sum of nonnegative terms:\n",
    "\n",
    "$$\n",
    "\\sum_{k=0}^{T-1} \\bigl(f(\\theta_k)-f(\\theta^*)\\bigr)\n",
    "\\le\n",
    "\\frac{|\\theta_0-\\theta^*|^2}{\\eta(2-\\eta L)}.\n",
    "$$\n",
    "\n",
    "Since the loss decreases monotonically under gradient descent, we have\n",
    "\n",
    "$$\n",
    "f(\\theta_T)-f(\\theta^*)\n",
    "\\le\n",
    "\\frac{|\\theta_0-\\theta^*|^2}\n",
    "{T\\eta(2-\\eta L)}.\n",
    "$$\n",
    "\n",
    "Up to constants, this is:\n",
    "\n",
    "$$\n",
    "f(\\theta_T)-f(\\theta^*)\n",
    "= O\\left(\\frac{1}{T}\\right).\n",
    "$$\n",
    "\n",
    "# Final Result\n",
    "\n",
    "For convex, $L$-smooth $f$ and $0<\\eta<2/L$:\n",
    "\n",
    "$$\n",
    "f(\\theta_T)-f(\\theta^*)\n",
    "\\le\n",
    "\\frac{|\\theta_0-\\theta^*|^2}\n",
    "{T\\eta(2-\\eta L)}.\n",
    "$$\n",
    "\n",
    "Which gives the sublinear rate:\n",
    "\n",
    "$$\n",
    "f(\\theta_T)-f(\\theta^*) = O(1/T).\n",
    "$$\n",
    "\n",
    "This is the standard convergence guarantee for gradient descent in the convex smooth setting.\n",
    "\n",
    "\n",
    "# Final Summary\n",
    "\n",
    "Under convexity, $L$-smoothness, and learning rate $0<\\eta<2/L$:\n",
    "\n",
    "* **Monotonic decrease**:\n",
    "  $$\n",
    "  f(\\theta_{k+1}) \\le f(\\theta_k).\n",
    "  $$\n",
    "\n",
    "* **Gradient norms go to zero** at rate $O(1/\\sqrt{k})$.\n",
    "\n",
    "* **Function values converge** at rate\n",
    "  $$\n",
    "  f(\\theta_k) - f(\\theta^*) \\le \\frac{|\\theta_0-\\theta^*|^2}{2\\eta k}\n",
    "  $$\n",
    "  i.e., $O(1/k)$.\n",
    "\n",
    "# Remarks for Neural Networks\n",
    "\n",
    "* Neural network losses are **nonconvex**, so global convergence guarantees from convex theory do **not** apply.\n",
    "* However, if the loss is **$L$-smooth**, then a sufficiently small learning rate $0<\\eta<2/L$ ensures\n",
    "  $$f(\\theta_{k+1}) \\le f(\\theta_k),$$\n",
    "  so gradient descent still makes **monotone descent** even without convexity.\n",
    "* Modern deep networks are **overparameterized**, and their local regions of the loss often behave *approximately convex*; wide minima and locally positive-semidefinite Hessians appear frequently.\n",
    "* The loss landscape is dominated by **saddle points**, not bad local minima; most local minima are “good” with similar loss values.\n",
    "* Smoothness-based tools (descent lemma, Lipschitz gradient bounds) still apply in the nonconvex setting and explain why training remains stable.\n",
    "* Convex results give a **baseline theory**; neural networks violate convexity, but many convex inequalities still hold locally or approximately, which is enough for gradient-based training to work well in practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Example (2–2–1 Network, Explicit Derivatives)\n",
    "\n",
    "Input and label:\n",
    "\n",
    "$$\n",
    "x=\\begin{bmatrix}1 \\\\ 2\\end{bmatrix},\n",
    "\\qquad\n",
    "y=1.\n",
    "$$\n",
    "\n",
    "Parameters:\n",
    "\n",
    "$$\n",
    "W_1=\\begin{bmatrix}0.1 & -0.2 \\\\ 0.4 & 0.5\\end{bmatrix},\n",
    "\\qquad\n",
    "b_1=\\begin{bmatrix}0.1 \\\\ -0.1\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W_2=\\begin{bmatrix}0.3 & -0.4\\end{bmatrix},\n",
    "\\qquad\n",
    "b_2=0.2.\n",
    "$$\n",
    "\n",
    "# Forward Pass\n",
    "\n",
    "## Hidden pre-activation\n",
    "\n",
    "$$\n",
    "z_1=W_1x+b_1\n",
    "$$\n",
    "\n",
    "Compute:\n",
    "\n",
    "$$\n",
    "W_1x\n",
    "=\n",
    "\\begin{bmatrix}0.1 & -0.2 \\\\ \n",
    "0.4 & 0.5\\end{bmatrix}\n",
    "\\begin{bmatrix}1 \\\\ 2\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}0.1(1) + (-0.2)(2) \\\\ \n",
    "0.4(1) + 0.5(2)\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}0.1 - 0.4 \\\\ \n",
    "0.4 + 1.0\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} -0.3 \\\\ \n",
    "1.4\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Adding $b_1$:\n",
    "\n",
    "$$\n",
    "z_1\n",
    "=\n",
    "\n",
    "\\begin{bmatrix}-0.3 \\\\ 1.4\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}0.1 \\\\ -0.1\\end{bmatrix}\n",
    "=\n",
    "\n",
    "\\begin{bmatrix}-0.2 \\\\ 1.3\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "## Hidden activation (ReLU)\n",
    "\n",
    "$$\n",
    "\\text{ReLU}(u)=\\begin{cases}u & u>0\\\\ 0 & u\\le 0\\end{cases}\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$\n",
    "a_1=\\text{ReLU}(z_1)\n",
    "=\\begin{bmatrix}0 \\\\ 1.3\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "## Output pre-activation\n",
    "\n",
    "$$\n",
    "z_2=W_2 a_1 + b_2\n",
    "$$\n",
    "\n",
    "Compute:\n",
    "\n",
    "$$\n",
    "W_2 a_1\n",
    "=\n",
    "\\begin{bmatrix}0.3 & -0.4\\end{bmatrix}\n",
    "\\begin{bmatrix}0\\\\\n",
    "1.3\\end{bmatrix}\n",
    "=\n",
    "0.3(0)+(-0.4)(1.3) = -0.52\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$\n",
    "z_2 = -0.52 + 0.2 = -0.32\n",
    "$$\n",
    "\n",
    "## Output activation (sigmoid)\n",
    "\n",
    "$$\n",
    "\\sigma(z)=\\frac{1}{1+e^{-z}}\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$\n",
    "a_2 = \\sigma(-0.32)\n",
    "= \\frac{1}{1+e^{0.32}}\n",
    "\\approx 0.420\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "# Output-Layer Delta (Explicit)\n",
    "\n",
    "Binary cross-entropy:\n",
    "\n",
    "$$\n",
    "L = -\\left[y\\ln a_2 + (1-y)\\ln(1-a_2)\\right]\n",
    "$$\n",
    "\n",
    "Derivative:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial z_2}=a_2-y\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial a_2} = 0.420 - 1 = -0.58\n",
    "$$\n",
    "\n",
    "Sigmoid derivative:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial a_2}{\\partial z_2} = \\sigma'(z_2)=a_2(1-a_2)=0.420(1-0.420)\\approx 0.2436\n",
    "$$\n",
    "\n",
    "Output delta:\n",
    "\n",
    "$$\n",
    "\\delta_2\n",
    "=\n",
    "\\frac{\\partial L}{\\partial a_2}\n",
    "\\frac{\\partial a_2}{\\partial z_2}\n",
    "=\n",
    "(-0.58)(0.2436)\n",
    "\\approx -0.141\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "# Output-Layer Gradients\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_2}\n",
    "=\\delta_2 a_1^\\top\n",
    "$$\n",
    "\n",
    "Compute:\n",
    "\n",
    "$$\n",
    "\\delta_2 a_1^\\top\n",
    "= -0.141\n",
    "\\begin{bmatrix}0 & 1.3\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}0 & -0.183\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Bias:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b_2}\n",
    "=\\delta_2=-0.141\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "# Hidden-Layer Delta\n",
    "\n",
    "Backprop term:\n",
    "\n",
    "$$\n",
    "W_2^\\top\\delta_2\n",
    "=\n",
    "\\begin{bmatrix}0.3 \\\\ -0.4\\end{bmatrix}(-0.141)\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0.3(-0.141) \\\\ -0.4(-0.141)\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "-0.0423 \\\\ 0.0564\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "ReLU derivative:\n",
    "\n",
    "$$\n",
    "\\text{ReLU}'(z_1)\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 \\\\ 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$\n",
    "\\delta_1\n",
    "=\n",
    "(W_2^\\top \\delta_2)\\odot \\text{ReLU}'(z_1)\n",
    "=\n",
    "\\begin{bmatrix}-0.0423 \\\\ 0.0564\\end{bmatrix}\n",
    "\\odot\n",
    "\\begin{bmatrix}0 \\\\ 1\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}0 \\\\ 0.0564\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "# Hidden-Layer Gradients\n",
    "\n",
    "Compute:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_1}\n",
    "=\n",
    "\\delta_1 x^\\top\n",
    "=\n",
    "\\begin{bmatrix}0 \\\\ 0.0564\\end{bmatrix}\n",
    "\\begin{bmatrix}1 & 2\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0.0564 & 0.1128\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Bias gradient:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b_1}\n",
    "=\\delta_1\n",
    "=\\begin{bmatrix}0 \\\\ 0.0564\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "# Gradient Summary\n",
    "\n",
    "Output layer:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_2}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 & -0.183\n",
    "\\end{bmatrix},\n",
    "\\qquad\n",
    "\\frac{\\partial L}{\\partial b_2}=-0.141\n",
    "$$\n",
    "\n",
    "Hidden layer:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_1}\n",
    "=\n",
    "\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0.0564 & 0.1128\n",
    "\\end{bmatrix},\n",
    "\\qquad\n",
    "\\frac{\\partial L}{\\partial b_1}\n",
    "=\n",
    "\n",
    "\\begin{bmatrix}0 \\\\ 0.0564\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
