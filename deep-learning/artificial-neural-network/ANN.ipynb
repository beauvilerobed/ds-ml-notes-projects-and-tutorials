{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks\n",
    "\n",
    "# 1. What Is an Artificial Neural Network?\n",
    "\n",
    "An **artificial neural network (ANN)** is a function built by connecting simple computational units called *neurons*.\n",
    "Mathematically, an ANN with layers $1,\\dots,L$ computes a function\n",
    "$$\n",
    "f_\\theta(x) = A_L \\circ \\phi_{L-1} \\circ A_{L-1} \\circ \\cdots \\circ \\phi_1 \\circ A_1(x),\n",
    "$$\n",
    "where each $A_i$ is an affine map, and each $\\phi_i$ is an activation applied componentwise.\n",
    "\n",
    "Even though each neuron is simple, many connected together can represent very complicated functions—this is the main reason ANNs power modern AI (vision, speech, robotics, etc.).\n",
    "\n",
    "\n",
    "\n",
    "# 2. Online Learning\n",
    "\n",
    "**Online learning** means learning from data that arrives one piece at a time:\n",
    "$$(x_1,y_1), (x_2,y_2),\\dots$$\n",
    "\n",
    "At time $t$ an online algorithm updates its parameters $\\theta_t$ using only the data seen so far. This is how systems like speech recognition or financial prediction operate. In contrast, **batch learning** would require all data at once.\n",
    "\n",
    "Online learning is more realistic in many real-world settings and more efficient when datasets are huge.\n",
    "\n",
    "\n",
    "\n",
    "# 3. Neurons\n",
    "\n",
    "A biological neuron fires when its input exceeds a threshold. The simplest mathematical model replicating this idea uses the **step function**:\n",
    "\n",
    "$$\n",
    "H(x) =\n",
    "\\begin{cases}\n",
    "1, & x\\ge 0,\\\n",
    "0, & x<0.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "To give a neuron multiple inputs, we compute a *weighted sum* and then apply the activation:\n",
    "\n",
    "$$\n",
    "y = H(w\\cdot x + b).\n",
    "$$\n",
    "\n",
    "The boundary between firing and not firing is the hyperplane\n",
    "$$\n",
    "w\\cdot x + b = 0.\n",
    "$$\n",
    "\n",
    "This makes the neuron a **linear classifier**.\n",
    "\n",
    "![title](img/picture.png)\n",
    "\n",
    "\n",
    "\n",
    "# 4. The Sigmoid Function\n",
    "\n",
    "The step function is useful conceptually but too “hard” for learning. A smoother alternative that behaves similarly is the **sigmoid**:\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1+e^{-x}}.\n",
    "$$\n",
    "\n",
    "It stays between $0$ and $1$ and transitions from low to high around $x=0$. It is differentiable, which is essential for gradient-based learning.\n",
    "\n",
    "![title](img/picture2.png)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Viewing ANNs as Graphs\n",
    "\n",
    "An ANN can be drawn as a **directed graph**:\n",
    "\n",
    "* each node is a neuron,\n",
    "* each directed edge carries a number (the output of another neuron),\n",
    "* edges have weights.\n",
    "\n",
    "If no cycles occur, the graph is a **directed acyclic graph (DAG)**, meaning computation flows forward only. These are **feedforward networks**.\n",
    "\n",
    "If cycles are allowed, we obtain **recurrent neural networks (RNNs)**, used for sequence data.\n",
    "\n",
    "![title](img/picture3.png)\n",
    "\n",
    "\n",
    "\n",
    "# 6. Layers\n",
    "\n",
    "Neurons that depend on the same preceding computations form a **layer**.\n",
    "Thus an ANN is typically grouped as:\n",
    "\n",
    "* **input layer** $l_0$\n",
    "* **hidden layers** $l_1, \\dots, l_{L-1}$\n",
    "* **output layer** $l_L$\n",
    "\n",
    "Layers help us visualize how information flows through the network.\n",
    "\n",
    "![title](img/picture5.png)\n",
    "\n",
    "\n",
    "\n",
    "# 7. The Universal Approximation Theorem\n",
    "\n",
    "One of the most important facts about neural networks is:\n",
    "\n",
    "## Theorem (Universal Approximation, simplified)\n",
    "\n",
    "Let $K\\subset\\mathbb{R}^n$ be compact and let $f:K\\to\\mathbb{R}$ be continuous.\n",
    "Then for any $\\varepsilon>0$ there exists a neural network with **one hidden layer** and a sigmoidal activation such that\n",
    "$$\n",
    "|f(x) - \\hat f(x)| < \\varepsilon\n",
    "\\quad\\text{for all } x\\in K.\n",
    "$$\n",
    "\n",
    "In short: **neural networks with enough hidden units can approximate any continuous function as closely as we want.**\n",
    "\n",
    "This does *not* say learning is easy; it only establishes that the representation is powerful enough.\n",
    "\n",
    "\n",
    "\n",
    "# 8. Training: Loss Functions\n",
    "\n",
    "Given data $(x_i,y_i)$, we measure how well a network $f_\\theta$ fits them via a **loss function**. A common choice is the empirical loss:\n",
    "\n",
    "$$\n",
    "E(\\theta) = \\frac{1}{N} \\sum_{i=1}^N L(f_\\theta(x_i), y_i).\n",
    "$$\n",
    "\n",
    "Typical losses:\n",
    "\n",
    "* **MSE** for regression: $L(u,v)=|u-v|^2$\n",
    "* **Cross-entropy** for classification\n",
    "\n",
    "We want to adjust $\\theta$ so that $E(\\theta)$ is small.\n",
    "\n",
    "\n",
    "# 9. Gradient Descent\n",
    "\n",
    "Because $E(\\theta)$ is usually too complicated to minimize exactly, we use **gradient descent**:\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\eta_t \\nabla_\\theta E(\\theta_t),\n",
    "$$\n",
    "\n",
    "where $\\eta_t$ is a learning rate.\n",
    "\n",
    "Intuition: the gradient points uphill; subtracting it moves downhill and reduces the loss.\n",
    "\n",
    "When data arrives one point at a time, the same idea yields **stochastic / online gradient descent**, which adjusts $\\theta$ gradually and continuously.\n",
    "\n",
    "\n",
    "\n",
    "# 10. Backpropagation\n",
    "\n",
    "**Backpropagation** is the algorithm that makes gradient descent feasible for deep networks. It applies the chain rule efficiently through the layers.\n",
    "\n",
    "Key idea:\n",
    "\n",
    "1. Compute the outputs forward.\n",
    "2. Compute how changes in each neuron affect the final loss by propagating “error signals” backward.\n",
    "3. Use these signals to compute gradients with respect to all weights and biases.\n",
    "\n",
    "## Theorem (Correctness of Backpropagation, intuitive)\n",
    "\n",
    "For any feedforward network with differentiable activations, backpropagation computes the true gradient\n",
    "$$\n",
    "\\nabla_\\theta E(\\theta)\n",
    "$$\n",
    "using a number of operations proportional to the number of connections in the network.\n",
    "\n",
    "This made training deep networks practical.\n",
    "\n",
    "For recurrent networks, the same idea is applied to the **unfolded** network over time, yielding *Backpropagation Through Time (BPTT)*.\n",
    "\n",
    "\n",
    "\n",
    "# 11. Putting It All Together\n",
    "\n",
    "An ANN:\n",
    "\n",
    "* takes in an input vector $x$,\n",
    "* transforms it through layers of affine maps and activations,\n",
    "* outputs a prediction $f_\\theta(x)$,\n",
    "* and learns by adjusting weights and biases to reduce a loss function.\n",
    "\n",
    "Despite its simple components, the network can learn highly nonlinear functions, thanks to the universal approximation theorem, gradient-based optimization, and the expressive power of layered computation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation\n",
    "\n",
    "We consider a feedforward network with $L$ layers. Dimensions:\n",
    "\n",
    "* Input: $a_0 = x \\in \\mathbb{R}^{n_0}$\n",
    "* Layer $\\ell$ pre-activation: $z_\\ell \\in \\mathbb{R}^{n_\\ell}$\n",
    "* Layer $\\ell$ activation: $a_\\ell \\in \\mathbb{R}^{n_\\ell}$\n",
    "* Weights: $W_\\ell \\in \\mathbb{R}^{n_\\ell \\times n_{\\ell-1}}$\n",
    "* Biases: $b_\\ell \\in \\mathbb{R}^{n_\\ell}$\n",
    "\n",
    "The forward propagation is\n",
    "\n",
    "$\n",
    "z_\\ell = W_\\ell a_{\\ell-1} + b_\\ell,\n",
    "\\qquad\n",
    "a_\\ell = \\phi_\\ell(z_\\ell),\n",
    "$\n",
    "\n",
    "where $\\phi_\\ell$ acts elementwise.\n",
    "\n",
    "We use the following notation:\n",
    "\n",
    "* $\\phi_\\ell'(z_\\ell)$ is the vector of elementwise derivatives.\n",
    "* $\\operatorname{diag}(\\phi_\\ell'(z_\\ell))$ is the diagonal Jacobian matrix of $\\phi_\\ell$ at $z_\\ell$.\n",
    "* $\\odot$ denotes elementwise (Hadamard) product.\n",
    "\n",
    "# Forward Pass (Vectorized)\n",
    "\n",
    "For each layer $\\ell = 1,\\dots,L$:\n",
    "\n",
    "$\n",
    "z_\\ell = W_\\ell a_{\\ell-1} + b_\\ell,\n",
    "\\qquad\n",
    "a_\\ell = \\phi_\\ell(z_\\ell).\n",
    "$\n",
    "\n",
    "If the final output is $a_L$ and the target is $y$, the loss is $L(a_L, y)$.\n",
    "\n",
    "# Error Signal\n",
    "\n",
    "Define the **error signal** at layer $\\ell$:\n",
    "\n",
    "$$\n",
    "\\delta_\\ell := \\frac{\\partial L}{\\partial z_\\ell} \\in \\mathbb{R}^{n_\\ell}.\n",
    "$$\n",
    "\n",
    "This is central because\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_\\ell} = \\delta_\\ell a_{\\ell-1}^\\top,\n",
    "\\qquad\n",
    "\\frac{\\partial L}{\\partial b_\\ell} = \\delta_\\ell.\n",
    "$$\n",
    "\n",
    "Once $\\delta_\\ell$ is known, computing gradients is straightforward.\n",
    "\n",
    "# Output Layer\n",
    "\n",
    "For the output layer $\\ell = L$:\n",
    "\n",
    "$$\n",
    "\\delta_L = \\frac{\\partial L}{\\partial a_L} \\odot \\phi_L'(z_L).\n",
    "$$\n",
    "\n",
    "Equivalently, in Jacobian form:\n",
    "\n",
    "$$\n",
    "\\delta_L = \\operatorname{diag}(\\phi_L'(z_L)) \\frac{\\partial L}{\\partial a_L}.\n",
    "$$\n",
    "\n",
    "This works for any differentiable loss.\n",
    "\n",
    "# Hidden Layers\n",
    "\n",
    "For hidden layers $\\ell = L-1,\\dots,1$:\n",
    "\n",
    "$$\n",
    "\\delta_\\ell = (W_{\\ell+1}^\\top \\delta_{\\ell+1}) \\odot \\phi_\\ell'(z_\\ell).\n",
    "$$\n",
    "\n",
    "Or equivalently in full matrix form:\n",
    "\n",
    "$$\n",
    "\\delta_\\ell = \\operatorname{diag}(\\phi_\\ell'(z_\\ell)) W_{\\ell+1}^\\top \\delta_{\\ell+1}.\n",
    "$$\n",
    "\n",
    "# Gradients with Respect to Parameters\n",
    "\n",
    "Differentiating $z_\\ell = W_\\ell a_{\\ell-1} + b_\\ell$ gives\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z_\\ell}{\\partial W_\\ell} = a_{\\ell-1}^\\top,\n",
    "\\qquad\n",
    "\\frac{\\partial z_\\ell}{\\partial b_\\ell} = I.\n",
    "$$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_\\ell} = \\delta_\\ell a_{\\ell-1}^\\top,\n",
    "\\qquad\n",
    "\\frac{\\partial L}{\\partial b_\\ell} = \\delta_\\ell.\n",
    "$$\n",
    "\n",
    "# Backpropagation Summary\n",
    "\n",
    "**Forward pass** ($\\ell = 1,\\dots,L$):\n",
    "\n",
    "$$\n",
    "z_\\ell = W_\\ell a_{\\ell-1} + b_\\ell,\n",
    "\\qquad\n",
    "a_\\ell = \\phi_\\ell(z_\\ell).\n",
    "$$\n",
    "\n",
    "**Backward pass**:\n",
    "\n",
    "$$\n",
    "\\delta_L = \\frac{\\partial L}{\\partial a_L} \\odot \\phi_L'(z_L),\n",
    "\\qquad\n",
    "\\delta_\\ell = (W_{\\ell+1}^\\top \\delta_{\\ell+1}) \\odot \\phi_\\ell'(z_\\ell), \\ \\ell = L-1,\\dots,1.\n",
    "$$\n",
    "\n",
    "**Gradients**:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_\\ell} = \\delta_\\ell a_{\\ell-1}^\\top,\n",
    "\\qquad\n",
    "\\frac{\\partial L}{\\partial b_\\ell} = \\delta_\\ell.\n",
    "$$\n",
    "\n",
    "Everything follows from standard multivariable calculus and matrix differentials.\n",
    "\n",
    "# Gradient Descent and Convergence\n",
    "\n",
    "Consider gradient descent on a differentiable function $f:\\mathbb{R}^p \\to \\mathbb{R}$:\n",
    "\n",
    "$$\n",
    "\\theta_{k+1} = \\theta_k - \\eta \\nabla f(\\theta_k).\n",
    "$$\n",
    "\n",
    "Assume:\n",
    "\n",
    "* $f$ is convex.\n",
    "* $\\nabla f$ is $L$-Lipschitz: $|\\nabla f(u) - \\nabla f(v)| \\le L|u-v|$.\n",
    "* Learning rate $0 < \\eta < 2/L$.\n",
    "\n",
    "## Monotone Decrease\n",
    "\n",
    "By $L$-smoothness:\n",
    "\n",
    "$$\n",
    "f(v) \\le f(u) + \\nabla f(u)^\\top (v-u) + \\frac{L}{2}|v-u|^2.\n",
    "$$\n",
    "\n",
    "Apply $u = \\theta_k$, $v = \\theta_{k+1} = \\theta_k - \\eta \\nabla f(\\theta_k)$:\n",
    "\n",
    "$$\n",
    "f(\\theta_{k+1}) \\le f(\\theta_k) - \\left(\\eta - \\frac{L \\eta^2}{2}\\right) |\\nabla f(\\theta_k)|^2.\n",
    "$$\n",
    "\n",
    "Since $0 < \\eta < 2/L$, the coefficient is positive, so $f(\\theta_{k+1}) \\le f(\\theta_k)$.\n",
    "\n",
    "## Convergence Rate\n",
    "\n",
    "For any minimizer $\\theta^*$, convexity gives:\n",
    "\n",
    "$$\n",
    "f(\\theta_k) - f(\\theta^*) \\le \\nabla f(\\theta_k)^\\top (\\theta_k - \\theta^*).\n",
    "$$\n",
    "\n",
    "Standard algebra yields:\n",
    "\n",
    "$$\n",
    "f(\\theta_k) - f(\\theta^*) \\le \\frac{|\\theta_0 - \\theta^*|^2}{2\\eta k},\n",
    "$$\n",
    "\n",
    "so $f(\\theta_k) \\to f(\\theta^*)$ as $k \\to \\infty$ (sublinear rate $O(1/k)$).\n",
    "\n",
    "# Remarks for Neural Networks\n",
    "\n",
    "* Losses are not convex, so global convergence is not guaranteed.\n",
    "* Smoothness still implies that small learning rates decrease the loss.\n",
    "* Empirically, large neural networks tend to have many local minima with similar loss values, and saddle points dominate the landscape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
