{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization for Deep Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A central problem in machine learning is how to make an algorithm that willperform well not just on the training data, but also on new inputs. Many strategiesused in machine learning are explicitly designed to reduce the test error, possiblyat the expense of increased training error. These strategies are known collectivelyas regularization. \n",
    "\n",
    "**Definition**: We deﬁned regularization as “any modiﬁcation we make to alearning algorithm that is intended to reduce its generalization error but not itstraining error.”\n",
    "\n",
    "In the context of deep learning, most regularization strategies are based onregularizing estimators. Regularization of an estimator works by trading increasedbias for reduced variance. An eﬀective regularizer is one that makes a proﬁtabletrade, reducing variance signiﬁcantly while not overly increasing the bias.\n",
    "\n",
    "Deep learning algorithms are typically applied to extremely complicated domains such as images, audio sequences and text, for which the true generation process essentially involves simulating the entire universe. To some extent, we are always trying to ﬁt a square peg (the data-generating process) intoa round hole (our model family).\n",
    "\n",
    "We might ﬁnd—and indeed in practical deep learning scenarios,we almost always do ﬁnd—that the best ﬁtting model (in the sense of minimizinggeneralization error) is a large model that has been regularized appropriately."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Norm Penalties\n",
    "\n",
    "Many regularization approaches are based on limiting the capacity of models,such as neural networks, linear regression, or logistic regression, by adding a parameter norm penalty $\\Omega(\\theta)$ to the objective function J. We denote the regularized objective function by $\\tilde{J}$:\n",
    "\n",
    "$$\n",
    "\\tilde{J}(\\theta;\\textbf{X},y) = J(\\theta;\\textbf{X},y) + \\alpha\\Omega(\\theta)\n",
    "$$\n",
    "\n",
    "where $\\alpha\\in[0,\\infty)$ is a hyperparameter that weights the relative contribution of the norm penalty term, $\\Omega$, relative to the standard objective function J. Setting $\\alpha = 0$ results in no regularization. Larger values of $\\alpha$ correspond to more regularization. Minimizes the regularized objective function $\\tilde{J}$ it will decrease both the original objectiveJon the training data and some measure of the size of the parameters $\\theta$ (or some subset of the parameters).\n",
    "\n",
    "**Note:** for neural networks, we typically choose to use a parameter norm penalty $\\Omega$ that penalizes only the weights of the affine transformation at each layer and leaves the baises unregularized. This means that we do not induce too muchvariance by leaving the biases unregularized. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $L^2$ Parameter Regularization\n",
    "\n",
    "one of the simplest and most common kinds of parameter norm penalty: the $L^2$ parameter norm penalty commonly known as **weight decay**. This regularization strategy drives the weights closer to the origin1by adding a regularization term $\\Omega(θ) = \\frac{1}{2}\\Vert w \\Vert_2^2$ to the objective function. $L^2$ regularization is also known as **ridge regression**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can gain some insight into the behavior of weight decay regularizationby studying the gradient of the regularized objective function. To simplify thepresentation, we assume no bias parameter, so $\\theta$ is just $w$. Such a model has thefollowing total objective function:\n",
    "\n",
    "$$\n",
    "\\tilde{J}(w;,\\textbf{X}, y) = \\frac{\\alpha}{2}w^Tw + J(w;,\\textbf{X}, y)\n",
    "$$\n",
    "\n",
    "with corresponding parameter gradient\n",
    "\n",
    "$$\n",
    "\\nabla_w\\tilde{J}(w;,\\textbf{X}, y) = \\alpha w + \\nabla_w J(w;,\\textbf{X}, y)\n",
    "$$\n",
    "\n",
    "To take a single gradient step to update the weights, we perform this update:\n",
    "\n",
    "$$\n",
    "w \\leftarrow w - \\epsilon(\\alpha w + \\nabla_w J(w;,\\textbf{X}, y))\n",
    "$$\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "$$\n",
    "w \\leftarrow (1-\\epsilon\\alpha)w -\\epsilon\\nabla_w J(w;\\textbf{W}, y)\n",
    "$$\n",
    "\n",
    "We can see that the addition of the weight decay term has modiﬁed the learningrule to multiplicatively shrink the weight vector by a constant factor on each step,just before performing the usual gradient update. This describes what happens ina single step. But what happens over the entire course of training?\n",
    "\n",
    "We will further simplify the analysis by making a quadratic approximationto the objective function in the neighborhood of the value of the weights that obtains minimal unregularized training cost, $w_∗= \\argmin_w J(w)$. If the objectivefunction is truly quadratic, as in the case of ﬁtting a linear regression model with mean squared error, then the approximation is perfect. The approximation $\\hat{J}$ is given by\n",
    "\n",
    "$$\n",
    "\\hat{J}(\\theta) = J(w_*) + \\frac{1}{2}(w-w^*)^T\\textbf{H}(w-w^*)\n",
    "$$\n",
    "\n",
    "where H is the Hessian matrix of J with respect to w evaluated at $w^*$. There is no first-order term in this quadratic approximation, because $w^*$ is the location of a minimum of J, we can conclude that $\\textbf{H}$ is positive semidefinite. The minimus of $\\hat{J}$ occurs where its gradient\n",
    "\n",
    "$$\n",
    "\\nabla_w\\hat{J}(w) = \\textbf{H} (w-w^*)\n",
    "$$\n",
    "\n",
    "is equal to $\\textbf{0}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
