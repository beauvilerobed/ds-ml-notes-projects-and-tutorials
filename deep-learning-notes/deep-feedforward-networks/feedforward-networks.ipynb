{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep feedforward networks** (or **feedforward neural networks**, or **multilayer perceptrons** (MLPS)) are the quintessential deep learning models.\n",
    "The goal of a feedforward network is to approximate some function $f^*$. \n",
    "\n",
    "Example: \n",
    "\n",
    "For a classifier $y = f^*(x)$ maps an input $x$ to a category $y$. A feedforward network defines a mapping $y=f(x;\\theta)$ and learns\n",
    "the value of the paremeters $\\theta$ that result in the best function approximation.\n",
    "\n",
    "These models are called **feedforward** because there are no **feedback** connections in which outputs of the model are fed back into itself.\n",
    "When feedforward neural networks are extended to include feedback connections, they are caled **recurrent neural networks**. In commercial applications\n",
    "the convolutional network used for object recognition from photos are a specialized kind of feedforward network. Feedforward neural networks are called\n",
    "**networks** since they are typically represented by composing together  many different functions, associated with a directed acyclic graph.\n",
    "\n",
    "Example:\n",
    "\n",
    "Given $f^{(1)}$ (**first layer**), $f^{(2)}$ (**second layer**), and $f^{(3)}$ (**third layer**) connected in a chain to form $f(x) = f^{(3)}(f^{(2)}(f^{(1)}(x)))$ with **depth** of 3.\n",
    "\n",
    "\n",
    "These chain structures are the most commonly used structures of neural networks. The final layer of a feedforward network is called the **outer layer**. During neural network training, we drive\n",
    "$f(x)$ to match $f^*(x)$.\n",
    "\n",
    "Example:\n",
    "\n",
    "Each example $x$ is accompanied by a label $y \\approx f^*(x)$. The learning algorithm must decide how to use those layers to produce the desired output, but the training\n",
    "data do not say what each indiviudual layer should do. Instead, the learning algorithm must decide how to use these layers to best implement an approximation of $f^*$. Since\n",
    "the training data does not show the desired output for each of these layers, they are called **hidden layers**.\n",
    "\n",
    "Finally, these networks are called *neural* because they are loosely inspired by neuroscience. Each hidden layer of the network is typically vector valued. The dimensionality of \n",
    "these hidden layers determine the **width** of the model. \n",
    "\n",
    "First, training a feedforward network requires making many of the same design decisions as are necessary for a linear model: choosing the optimizer, the cost function, and the form of the output\n",
    "units. Feedfoward networks have introduced the concept of a hidden layer, and this requires us to choose the **activation functions** that will be used to compute the hidden layer values.\n",
    "We must also design the architecture of the network, like how many layers, how these layers should be connected, and how many **units** should be in each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedfoward neural networks are primarily used for supervised learning in cases where the data to be learned\n",
    "is neither sequential nor time-dependent. On the other hand, recurrent neural networks learn sequential data,\n",
    "computing g on variable length input $X_k = \\{x_1, x_2, ..., x_k\\}$ such that $g(X_k) \\approx y_k$ for training\n",
    "pairs $(X_n, Y_n)$ for all $1 \\leq k \\leq n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest type of feedforward neural network is the **perceptron**, a feedforward neural network\n",
    "with not ** hidden units**. Thus, a perceptron has only an input layer and an output layer. The output\n",
    "units are computed directly from the sum of the product of their **weights** with the corresponding\n",
    "input units, plus some **bias**.\n",
    "\n",
    "Generally single-layer perceptrons can use activation functions other than the step function $H(x)$. Typical choices are the identity function $f(x) = x$, the sigmoid function\n",
    "$\\sigma(x) = (1+e^{-x})^{-1}$ and the hyperbolic tangent $tanh(x) = \\frac{e^x+e^{-x}}{e^x-e^{-x}}$. Thus, in general, a perceptron with activation function $g(x)$ has output\n",
    "$$\n",
    "o = g(w\\cdot x + b)\n",
    "$$\n",
    "\n",
    "In order for a perceptron to learn to correctly classify a set of input-output pairs $(x,y)$, it has to adjust the weights $w$ and bias $b$ in order to learn a good classification\n",
    "boundary. The figure below shows many possible classification boundaries, the best of which is the boundary labeled $H_2$.\n",
    "\n",
    "![title](img/picture4.png)\n",
    "\n",
    "If the perceptron uses an activation function other than the step function (e.g. the sigmoid function), then the weights and bias should be adjusted so that the output oo is close \n",
    "to the true label $y$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, the learning process requires the definition of an error function $E$ that quantifies the difference between the computed output of the perceptron $o$ and the true value $y$ for an input $x$ \n",
    "over a set of multiple input-output pairs $(x,y)$. Historically, this error function is the mean squared error (MSE), defined for a set of $N$ input-output pairs \n",
    "$X = \\{ (x_1,y_1), ..., (x_N,y_N) \\}$ as\n",
    "\n",
    "$$\n",
    "E(X) = \\frac{1}{2N} \\sum_{i=1}^N (o_i - y_i)^2 = \\frac{1}{2N} \\sum_{i=1}^N (g(w\\cdot x_i + b) - y_i)^2 \n",
    "$$\n",
    "\n",
    "Where $o_i$ denotes the output of the perceptron on input $x_i$ with activation function $g$. The factor $\\frac{1}{2}$ is included to simplify the calculation\n",
    "of the derivative later. Thus, $E(X) = 0$ when $o_i = y_i$ for all input-output pairs $(x_i, y_i)$ in X, so a natural objective is to attempt to change $w$ and $b$ such that\n",
    "$E(X)$ is as close to zero as possible. Thus, minimizing E(X) w.r.t. $w$ and $b$ should yeild a good classification boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$E(X)$ is typically minimized using **gradient descent**, meaning the perceptron adjusts $w$ and $b$ in the direction of the negative gradient of the error\n",
    "function. Gradient descent works for any error function, not jus the MSE. This iterative process reduces the values of th error function until it converges on a\n",
    "value, usually a local minimum. The values of $w$ and $b$ are typically set randomly then updated using gradient descent. If the random initializations of\n",
    "$w$ and $b$ are denoted $w_0$ and $b_0$, respectively, then gradient updates $w$ and $b$ according to the equations:\n",
    "$$\n",
    "w_{i+1} = w_i -\\alpha \\frac{\\partial E(X)}{\\partial w_i}\n",
    "$$ \n",
    "$$\n",
    "b_{i+1} = b_i -\\alpha \\frac{\\partial E(X)}{\\partial b_i}\n",
    "$$\n",
    "\n",
    "where $w_i$ and $b_i$ are the values of $w$ and $b$ after the $i^{th}$ iteration of gradient descent, and $\\frac{\\partial f}{\\partial x}$ is the partial\n",
    "derivative of $f$ w.r.t. to $x$. $\\alpha$ is known as the **learning rate**, which controls the step size gradient descent takes each iteration, typically\n",
    "chosen to be a small value, e.g. $\\alpha=0.01$. Values of $\\alpha$ that are too large cause learning to be suboptimal (by failing to converge), while values\n",
    "of $\\alpha$ that are too small make learning slow.\n",
    "\n",
    "The weight delta $\\delta w = w_{i+1}-w_{i}$ and bias delta $\\delta b = b_{i+1}-b_{i}$ are calculated using the **delta rule**. The delta rule is a special case\n",
    "of **backpropagation** for single-layer perceptrons, and is used to calculate the updates (or deltas) of the perceptron parameters. The delta rule can be \n",
    "derived by consistent application of the chain rule and power rule for calculating the partial derivatives:\n",
    "$$\n",
    "\\Delta w = \\frac{1}{N}  \\sum_{i=1}^N (y_i - o_i)g'(h_i)x_i\n",
    "$$\n",
    "$$\n",
    "\\Delta w = \\frac{1}{N}  \\sum_{i=1}^N (y_i - o_i)g'(h_i)\n",
    "$$\n",
    "\n",
    "where $o_i = g(w\\cdot x_i + b)$ and $h_i = w\\cdot x_i + b$. Note that the presence of $x_i$ on the right side of the delta rule for $w$ implies that the weight\n",
    "vector's update delta is also a vector, which is expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition:\n",
    "1. Calculate the **forward** values. That is, for $X = \\{ (x_1,y_1), ...,(x_N,y_N) \\}$  calculate $h_i$ and $o_i$ for all  $x_i$.\n",
    "2. Calculate the **backward** values. Using the partial derivatives of the error function, update the weight vector and bias according to gradient\n",
    "descent. Specifically, use the delta rules and values calculated in the foward phase to calculate the deltas for each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was mentioned earlier that single-layer perceptrons are linear classifiers. That is, they can only learn linearly separable patterns. Linearly \n",
    "separable patterns are datasets or functions that can be separated by a linear boundary (a line or hyperplane). Marvin Minsky and Seymour Papert \n",
    "showed in their seminal 1969 book Perceptrons that it was impossible for a perceptron to learn even simple non-linearly separable functions such as \n",
    "the XOR function.\n",
    "\n",
    "![title](img/picture5.png\n",
    "\n",
    "Notice that, for the plot of the XOR function, it is impossible to find a linear boundary that separates the black and white inputs from one another. \n",
    "This is because XOR is not a linearly separable function, and by extension, perceptrons cannot learn the XOR function.\n",
    "\n",
    "Many other (indeed, most other) functions are not linearly separable, so what is needed is an extension to the perceptron. The obvious extension is \n",
    "to add more layers of units so that there are nonlinear computations in between the input and output. For a long time, it was assumed by many in the \n",
    "field that adding more layers of units would fail to solve the linear separability problem (even though Minsky and Papert knew that such an extension \n",
    "could learn the XOR function), so research in the field of artificial neural networks stagnated for a good decade. Indeed, this assumption turned out \n",
    "to be very wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **mulit-layer perceptron** (MLP) is an artificial neural network composed of many perceptrons. Unlike single-layer perceptrons, MLPs are capable of \n",
    "learning to compute non-linearly separable functions. Because they can learn nonlinear functions, they are one of the primary machine learning techniques \n",
    "for both regression and classification in supervised learning.\n",
    "\n",
    "### Layers\n",
    "\n",
    "MLPs are usually organized into something called **layers**. The generalized artificial neural network consists of an input layer, some number (possibly \n",
    "zero) of hidden layers, and an output layer. In the case of a single-layer perceptron, there are no hidden layers, so the total number of layers is two. \n",
    "MLPs, on the other hand, have at least one hidden layer, each composed of multiple perceptrons. An example of a feedforward neural network with two hidden \n",
    "layers is below.\n",
    "\n",
    "![title](img/picture6.png)\n",
    "\n",
    "Feedforward neural networks have the property that information (i.e. computation) flows forward through the network, i.e. there are no loops in the \n",
    "computation graph (it is a directed acyclic graph, or DAG). Another way of saying this is that the layers are connected in such a way that no layer's \n",
    "output depends on itself. In the above figure, this is clear since each layer (other than the input layer) is only connected to the layer directly to\n",
    "its left. Feedforward neural networks, by having DAGs for their computation graphs, have a greatly simplified learning algorithm compared to recurrent \n",
    "neural networks, which have cycles in their dependency graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition:\n",
    "1. The output perceptron has an activation function $g_0$ and hidden layer perceptrons have activation functions $g$.\n",
    "2. Every perceptron in layer $l_i$ is connected to every perceptron in layer $l_{i-1}$; layers are \"fully connected\". Thus, every perceptron depends on \n",
    "the outputs of all the perceptrons in the previous layer (this is without loss of generality since the weight connecting two perceptrons can still be \n",
    "zero, which is the same as no connection being present).\n",
    "3. There are no connections between perceptrons in the same layer.\n",
    "\n",
    "![title](img/picture7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and use the following denotation:\n",
    "\n",
    "##### scalars\n",
    "$w_{ij}^k$ : weight for perceptron j in layer $l_k$ for incoming node i (a perceptron if $k\\geq 1$) in layer $l_{k-1}$\n",
    "\n",
    "$b_{i}^k$ : bias for perceptron i in layer $l_k$\n",
    "\n",
    "$h_{i}^k$ : product sum plus bias for perceptron i in layer $l_k$\n",
    "\n",
    "$o_{i}^k$ : output for node i in layer $l_k$\n",
    "\n",
    "$r_{k}$ : number for nodes in layer $l_k$\n",
    "\n",
    "##### vectors\n",
    "\n",
    "$w_{i}^k$ : weight vector for perceptron i in layer $l_k$ i.e. $w_i = \\{ w_{1j}^k, ..., w_{r_{k}j}^k \\}$\n",
    "\n",
    "\n",
    "$o^k$ : output vector for layer $l_k$ i.e. $o_i = \\{ o_{1j}^k, ..., o_{r_{k}}^k \\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, computation of the MLP's output $o$ proceeds according to the following steps:\n",
    "\n",
    "1. **Initialize the input layer** \n",
    "    - $l_0$, Set the values of the outputs $o_i^0$ for nodes in the input layer $l_0$ to their associated in the vector\n",
    "$x = \\{ x_1, ..., x_n \\}$ i.e. $o_i^0 = x_i$.\n",
    "2. **Calculate the product sums and outputs of each hidden layer in order from $l_1$ to $l_{m-1}$**\n",
    "    - For k from 1 to m-1\n",
    "        - compute $h_i^k = w_{i}^k\\cdot o^k + b_{i}^k$ for $i=1, ..., r_k$;\n",
    "        - compute $o^k = g(h_{i}^k)$ for $i=1, ..., r_k$\n",
    "3. **Compute the output $y$ for output layer $l_m$**\n",
    "    - compute $h_1^m = w_{1}^{m}\\cdot o^{m-1} + b_{1}^{m}$\n",
    "    - compute $o = o_1^m = g_o(h_1^m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the single-layer-perceptron, given a set of $N$ input-ouput pairs $X = \\{ (x_1,y_1), ..., (x_N, y_N) \\}$ learning consists of iteratively updating the values of $w_i^k$ and $b_i^k$ in order\n",
    "to minimize the MSE.\n",
    "\n",
    "$$\n",
    "E(X) = \\frac{1}{2N} \\sum_{i=1}^N (o_i - y_i)^2\n",
    "$$\n",
    "\n",
    "where $o_i$ denotes the output $o$ (the result of step 3 in the computation above) of the MLP on input $x_i$. Analogous to the single-layer perceptron, minimizing with respect to all $w_{ij}^k$ \n",
    "and $b_i^k$ will yield a good classification boundary. Using gradient descent to adjust the parameters $w_{ij}^k$ and $b_i^k$ with a learning rate of $\\alpha$ yields the following delta equations\n",
    "for each iteration:\n",
    "\n",
    "$$\n",
    "\\Delta w_{ij}^k = -\\alpha \\frac{\\partial E(X)}{\\partial w_{ij}^k}\n",
    "$$ \n",
    "$$\n",
    "\\Delta b{i}^k = -\\alpha \\frac{\\partial E(X)}{\\partial b_i^k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expansion of the right-hand side of the delta rules can be found using backpropagation, so called because the gradient information flows backwards through the network (i.e. in the direction\n",
    "opposite of the output compputation flow). This gradient flow originates in the final layer $l_m$ proportional to the difference between the target output $y$ and actual output $o$. Thus, one\n",
    "iteration of training for MLPs consits of two distict computational phases:\n",
    "\n",
    "Definition:\n",
    "1. Calculate the **forward** values. That is, for $X = \\{ (x_1,y_1), ...,(x_N,y_N) \\}$  calculate $h_i$ and $o_i$ for all  $x_i$.\n",
    "2. Calculate the **backward** values. Using the partial derivatives of the error function, update the weights $w_{ij}^k$ and biases $b_i^k$ according to gradient\n",
    "descent. Specifically, use backpropagation and values calculated in the foward phase to calculate the deltas for each."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
