{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Math Behind A/B Testing: Formulas, Calculations, and More...\n",
    "\n",
    "A/B testing is not just a marketing tool—it is a statistical experiment. This guide explains the math behind A/B testing, including how to calculate sample sizes, standard errors, confidence intervals, and how to analyze discrete and continuous metrics. Each formula is derived step by step, with clear justification, so you can understand the reasoning behind every calculation.\n",
    "\n",
    "## What is A/B Testing?\n",
    "\n",
    "A/B testing (split testing) is an experiment where you split your audience to test two or more variations and determine which performs better.  \n",
    "It helps answer questions like: “Does changing this button color increase clicks?”  \n",
    "\n",
    "**Metrics Types:**  \n",
    "- **Continuous metrics:** measurable on a scale (e.g., revenue per user, time on page).  \n",
    "- **Discrete metrics:** countable events (e.g., clicks, signups, purchases).  \n",
    "\n",
    "Choosing the correct metric type determines the statistical method and sample size calculation.\n",
    "\n",
    "## When to Use A/B Testing\n",
    "\n",
    "- **Best for:** incremental changes (UX tweaks, small features, page load optimization).  \n",
    "- **Not ideal for:** major changes (new product, full rebranding, or entirely new UX), as these can introduce confounding emotional effects.\n",
    "\n",
    "## Common Mistakes to Avoid\n",
    "\n",
    "- **Invalid hypothesis:** Be explicit about what you are testing and the expected outcome.  \n",
    "- **Testing too many elements at once:** Makes it hard to identify what caused changes.  \n",
    "- **Ignoring statistical significance:** Let tests run long enough to achieve significance.  \n",
    "- **Ignoring external factors:** Compare similar periods (avoid holiday spikes or promotions).\n",
    "\n",
    "## How A/B Testing Works\n",
    "\n",
    "1. Create two versions of content (control and treatment), changing only **one variable**.  \n",
    "2. Split audiences randomly and equally.  \n",
    "3. Measure results over sufficient duration.  \n",
    "\n",
    "### Example: User Experience\n",
    "\n",
    "- **Version A (control):** Sidebar CTA  \n",
    "- **Version B (challenger):** Top-of-page CTA  \n",
    "- Measure **clicks** (discrete metric) to determine the winner.\n",
    "\n",
    "### Example: Design Test\n",
    "\n",
    "- **Version A (control):** Red CTA button  \n",
    "- **Version B (challenger):** Green CTA button  \n",
    "- Measure **time on page** (continuous metric) to determine engagement difference.\n",
    "\n",
    "## A/B Testing Goals\n",
    "\n",
    "- **Discrete metrics:** conversion rate, signups, purchases  \n",
    "- **Continuous metrics:** revenue per user, session duration  \n",
    "- **Mixed:** cart abandonment, product image improvements  \n",
    "\n",
    "## Designing an A/B Test\n",
    "\n",
    "1. Select **one variable** to test.  \n",
    "2. Identify your **primary metric** (continuous or discrete).  \n",
    "3. Create **control** and **treatment** versions.  \n",
    "4. Randomly split your audience equally.  \n",
    "5. Calculate required **sample size**.  \n",
    "6. Decide significance thresholds: $\\alpha$ (Type I error) and $\\beta$ (Type II error).  \n",
    "7. Run **one test at a time**.\n",
    "\n",
    "\n",
    "\n",
    "## Step 1: Test Statistic\n",
    "\n",
    "For measuring the difference between two groups:\n",
    "\n",
    "$$\n",
    "T = \\frac{\\text{observed difference} - \\text{expected difference under $H_0$}}{SE}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- **Observed difference:** difference in metrics between treatment and control.  \n",
    "- **Expected difference under $H_0$:** usually 0 (no difference).  \n",
    "- **SE (standard error):** accounts for variability in the metric.\n",
    "\n",
    "### Standard Error Formulas\n",
    "\n",
    "#### Continuous Metrics\n",
    "\n",
    "$$\n",
    "SE = \\sqrt{\\frac{s_c^2}{n_c} + \\frac{s_t^2}{n_t}}\n",
    "$$`\n",
    "\n",
    "- $s_c^2$, $s_t^2$: sample variances  \n",
    "- $n_c$, $n_t$: sample sizes\n",
    "\n",
    "> **Note:** Variances add for independent samples; divide by sample size to adjust for averaging; square root returns SE in original units.\n",
    "\n",
    "#### Discrete Metrics (Binary)\n",
    "\n",
    "$$\n",
    "SE = \\sqrt{\\frac{p_c(1-p_c)}{n_c} + \\frac{p_t(1-p_t)}{n_t}}\n",
    "$$\n",
    "\n",
    "- $p_c$, $p_t$: conversion rates  \n",
    "- $n_c$, $n_t$: sample sizes  \n",
    "\n",
    "> **Note:** Variance of Bernoulli $p(1-p)$, divided by sample size for mean; sum for independent groups.\n",
    "\n",
    "\n",
    "\n",
    "## Step 2: Confidence Interval\n",
    "\n",
    "95% CI for difference:\n",
    "\n",
    "$$\n",
    "(p_t - p_c) \\pm Z_{0.975} \\cdot SE\n",
    "$$\n",
    "\n",
    "- $Z_{0.975} = 1.96$  \n",
    "- CI shows plausible range of true difference.\n",
    "\n",
    "\n",
    "\n",
    "## Step 3: Sample Size Calculation\n",
    "\n",
    "### Continuous Metrics\n",
    "\n",
    "Goal: detect a difference $\\Delta$ with significance $\\alpha$ and power $1-\\beta$.\n",
    "\n",
    "1. Test statistic:\n",
    "\n",
    "$$\n",
    "T = \\frac{\\bar{X}_t - \\bar{X}_c}{\\sqrt{\\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n}}} = \\frac{\\Delta}{\\sqrt{2\\sigma^2 / n}}\n",
    "$$\n",
    "\n",
    "2. Solve for $n$:\n",
    "\n",
    "$$\n",
    "Z_{\\alpha/2} + Z_\\beta = \\frac{\\Delta}{\\sqrt{2\\sigma^2 / n}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sqrt{\\frac{2\\sigma^2}{n}} = \\frac{\\Delta}{Z_{\\alpha/2} + Z_\\beta}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{2\\sigma^2}{n} = \\frac{\\Delta^2}{(Z_{\\alpha/2} + Z_\\beta)^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "n = \\frac{2 (Z_{\\alpha/2} + Z_\\beta)^2 \\sigma^2}{\\Delta^2}\n",
    "$$\n",
    "\n",
    "> **Note:** Includes variance, confidence, and desired power.\n",
    "\n",
    "### Discrete Metrics (Binary)\n",
    "\n",
    "$$\n",
    "n = \\frac{2 (Z_{\\alpha/2} + Z_\\beta)^2 \\hat{p}(1-\\hat{p})}{\\Delta^2}\n",
    "$$\n",
    "\n",
    "- $\\hat{p}$: baseline conversion rate  \n",
    "- $\\Delta$: minimum detectable effect  \n",
    "\n",
    "> **Note:** Variance of Bernoulli distribution and two independent groups included.\n",
    "\n",
    "### Example: Discrete Metric\n",
    "\n",
    "- Baseline $p_c = 0.10$  \n",
    "- Minimum detectable effect $\\Delta = 0.02$  \n",
    "- 95% confidence ($Z_{0.975}=1.96$)  \n",
    "- 80% power ($Z_{0.8}=0.84$)\n",
    "\n",
    "Step-by-step:\n",
    "\n",
    "1. $Z_{0.975}+Z_{0.8} = 1.96+0.84 = 2.8$  \n",
    "2. Square: $(2.8)^2 = 7.84$  \n",
    "3. Multiply by $2 \\cdot \\hat{p}(1-\\hat{p}) = 2 \\cdot 0.1 \\cdot 0.9 = 0.18$  \n",
    "4. $7.84 \\cdot 0.18 = 1.4112$  \n",
    "5. Divide by $\\Delta^2 = 0.0004$ → $1.4112 / 0.0004 = 3528$\n",
    "\n",
    "Required sample size per group: **≈ 3528 users**\n",
    "\n",
    "\n",
    "\n",
    "## Step 4: Running the Test\n",
    "\n",
    "- Use a testing tool  \n",
    "- Split users randomly  \n",
    "- Run for sufficient duration to collect enough events for SE and CI  \n",
    "- Collect qualitative feedback if needed  \n",
    "\n",
    "\n",
    "\n",
    "## Step 5: Analyzing Results\n",
    "\n",
    "### Discrete Metric\n",
    "\n",
    "- Standard error:\n",
    "\n",
    "$$\n",
    "SE = \\sqrt{\\frac{p_c (1-p_c)}{n_c} + \\frac{p_t (1-p_t)}{n_t}}\n",
    "$$\n",
    "\n",
    "- Confidence interval:\n",
    "\n",
    "$$\n",
    "(p_t - p_c) \\pm Z_{0.975} \\cdot SE\n",
    "$$`\n",
    "\n",
    "### Continuous Metric\n",
    "\n",
    "- Standard error:\n",
    "\n",
    "$$\n",
    "SE = \\sqrt{\\frac{s_c^2}{n_c} + \\frac{s_t^2}{n_t}}\n",
    "$$\n",
    "\n",
    "- Confidence interval:\n",
    "\n",
    "$$\n",
    "(\\bar{X}_t - \\bar{X}_c) \\pm Z_{0.975} \\cdot SE\n",
    "$$\n",
    "\n",
    "Take action based on CI and practical significance ($\\Delta$).\n",
    "\n",
    "\n",
    "\n",
    "## Advanced Concepts\n",
    "\n",
    "### Multi-Armed Bandit\n",
    "\n",
    "The multi-armed bandit approach dynamically allocates traffic to the best-performing variant, instead of splitting traffic equally like traditional A/B testing. This can improve overall performance during the test by favoring better options earlier.  \n",
    "\n",
    "- **Thompson Sampling** is commonly used for discrete metrics (e.g., clicks, conversions). It models the conversion probability of each variant with a Beta distribution:\n",
    "\n",
    "$$\n",
    "\\theta_i \\sim \\text{Beta}(\\alpha_i + \\text{successes}_i, \\beta_i + \\text{failures}_i)\n",
    "$$\n",
    "\n",
    "Here, $\\theta_i$ is the estimated conversion rate for variant $i$, updated as data arrives.  \n",
    "\n",
    "- **Expected regret** quantifies the loss from not always choosing the best variant:\n",
    "\n",
    "$$\n",
    "R(T) = \\sum_{t=1}^{T} (\\mu^* - \\mu_{a_t})\n",
    "$$\n",
    "\n",
    "Where $\\mu^*$ is the conversion rate of the optimal variant and $\\mu_{a_t}$ is the conversion rate of the variant chosen at time $t$.\n",
    "\n",
    "### Sequential Testing\n",
    "\n",
    "Sequential testing allows you to continuously monitor results and stop the experiment early if there is enough evidence, rather than waiting for a fixed sample size. This can save time and resources but requires adjusting significance thresholds to avoid false positives.  \n",
    "\n",
    "- Adjust the significance threshold over time:\n",
    "\n",
    "$$\n",
    "\\alpha(t) = \\alpha \\cdot \\frac{t}{T}\n",
    "$$\n",
    "\n",
    "- Use the **Sequential Probability Ratio Test (SPRT)** to compare likelihoods of hypotheses as data accumulates:\n",
    "\n",
    "$$\n",
    "\\Lambda_t = \\frac{L(\\text{data}_t | H_1)}{L(\\text{data}_t | H_0)}\n",
    "$$\n",
    "\n",
    "**Stop rules:**  \n",
    "- Accept $H_1$ if $\\Lambda_t > B$ (enough evidence for treatment effect)  \n",
    "- Accept $H_0$ if $\\Lambda_t < A$ (enough evidence for no effect)  \n",
    "- Continue collecting data otherwise  \n",
    "\n",
    "### Bayesian A/B Testing\n",
    "\n",
    "Bayesian A/B testing incorporates prior beliefs about metrics and updates them with observed data, giving a probability distribution over the true effect rather than a single point estimate.  \n",
    "\n",
    "- **Posterior update:**\n",
    "\n",
    "$$\n",
    "p(\\theta | \\text{data}) \\propto p(\\text{data} | \\theta) \\cdot p(\\theta)\n",
    "$$\n",
    "\n",
    "- The 95% **credible interval** provides the range where the true parameter lies with 95% probability:\n",
    "\n",
    "$$\n",
    "\\text{CI}_{95\\%} = [\\theta_{\\text{lower}}, \\theta_{\\text{upper}}]\n",
    "$$\n",
    "\n",
    "- Bayesian methods allow **probability-based decisions**, e.g., “There is a 90% chance that variant B is better than A,” which can be more intuitive than p-values.\n",
    "\n",
    "## How to Read Results\n",
    "\n",
    "When analyzing A/B test results, consider both statistical and practical significance:  \n",
    "\n",
    "1. **Verify statistical significance** – Check p-values or credible intervals to ensure observed differences are unlikely to be due to chance.  \n",
    "2. **Compute confidence intervals** – For discrete or continuous metrics, intervals quantify uncertainty around the estimated difference.  \n",
    "3. **Assess practical effect size ($\\Delta$)** – Consider if the difference is meaningful for business or user experience.  \n",
    "4. **Decide next steps** – Roll out the winning variant, iterate with new tests, or discard changes that don’t show improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Flow\n",
    "```\n",
    "Start\n",
    "  │\n",
    "  ▼\n",
    "Select Metric\n",
    "  │\n",
    "  ├─► Is it Discrete? (clicks, signups, purchases)\n",
    "  │       │\n",
    "  │       ├─► Yes \n",
    "  │       │     │\n",
    "  │       │     ├─► Use standard A/B test for proportions\n",
    "  │       │     ├─► Optional: Multi-Armed Bandit for faster allocation\n",
    "  │       │     └─► Sample size via binary formula\n",
    "  │       │\n",
    "  │       └─► No (continuous: time on page, revenue)\n",
    "  │             │\n",
    "  │             ├─► Use t-test / ANOVA\n",
    "  │             ├─► Optional: Sequential or Bayesian testing\n",
    "  │             └─► Sample size via variance-based formula\n",
    "  │\n",
    "  ▼\n",
    "Randomly split audience\n",
    "  │\n",
    "  ▼\n",
    "Run test (ensure sufficient duration)\n",
    "  │\n",
    "  ▼\n",
    "Analyze Results\n",
    "  │\n",
    "  ├─► Statistically Significant?\n",
    "  │       │\n",
    "  │       ├─► Yes ─► Implement winning variant\n",
    "  │       │\n",
    "  │       └─► No ─► Iterate or increase sample size\n",
    "  │\n",
    "  ▼\n",
    "End"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
