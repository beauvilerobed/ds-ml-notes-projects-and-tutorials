{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7744eeb0",
   "metadata": {
    "papermill": {
     "duration": 0.013077,
     "end_time": "2024-06-17T06:39:53.775504",
     "exception": false,
     "start_time": "2024-06-17T06:39:53.762427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A/B Testing: A Quick Guide\n",
    "\n",
    "A/B testing (or split testing) compares two versions of a webpage, app, or user experience to see which performs better. It’s widely used in marketing, product development, and UX design to make data-driven decisions.  \n",
    "\n",
    "## What You’ll Learn\n",
    "\n",
    "- **Binary A/B Testing:** Compare two versions with yes/no outcomes.  \n",
    "- **Continuous A/B Testing:** Compare averages for numerical data and check statistical significance.   \n",
    "\n",
    "## How to Use\n",
    "\n",
    "1. **Run the code cells** to follow along.  \n",
    "2. **Experiment** with your own datasets after finishing the tutorials.  \n",
    "\n",
    "Unlock the power of A/B testing and turn data into better decisions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96999072",
   "metadata": {
    "papermill": {
     "duration": 0.011111,
     "end_time": "2024-06-17T06:39:53.798431",
     "exception": false,
     "start_time": "2024-06-17T06:39:53.787320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1: Exploratory Data Analysis (EDA) & Problem Definition\n",
    "\n",
    "### EDA\n",
    "Before running the A/B test, understand your dataset:\n",
    "\n",
    "1. **Load Dataset**: Import and inspect the data.  \n",
    "2. **Summary Statistics**: Check central tendency, dispersion, and distribution.  \n",
    "3. **Missing Values**: Identify and handle missing data.  \n",
    "4. **Data Types**: Verify column types.  \n",
    "5. **Group Descriptions**: Compute statistics by `version` (calculated descriptive statistics, including skewness and kurtosis).  \n",
    "6. **Cross-tabulations**: Compare retention rates across versions.  \n",
    "7. **Plots**: Visualize distributions and retention rates.  \n",
    "\n",
    "### Problem Definition\n",
    "- **Control Group**: No treatment.  \n",
    "- **Treatment Group**: Receives the treatment.  \n",
    "\n",
    "### Hypotheses\n",
    "- **Null ($H_0$)**: No difference between groups.  \n",
    "- **Alternative (H1)**: Significant difference exists.  \n",
    "\n",
    "## Step 2: Data Preprocessing\n",
    "Prepare data for testing:\n",
    "\n",
    "1. Handle missing values.  \n",
    "2. Detect and manage outliers.  \n",
    "3. Transform/normalize data if needed.  \n",
    "4. Create new features if necessary.  \n",
    "\n",
    "## Step 3: Set Type I & II Error Probabilities\n",
    "- **Type I (Alpha)**: Reject $H_0$ when true (commonly 0.05).  \n",
    "- **Type II (Beta)**: Fail to reject $H_0$ when false (commonly 0.20).  \n",
    "- **Power**: 1 - Beta (usually 0.80).  \n",
    "\n",
    "## Step 4: Sample Size & Selection\n",
    "\n",
    "### Calculate Sample Size\n",
    "**Binary Outcomes:**\n",
    "\n",
    "$$\n",
    "n = \\left( Z_{1-\\alpha/2} + Z_{1-\\beta} \\right)^2 \\frac{p_1(1 - p_1) + p_2(1 - p_2)}{(p_1 - p_2)^2}\n",
    "$$\n",
    "\n",
    "**Continuous Outcomes:**\n",
    "\n",
    "$$\n",
    "n = \\left( \\frac{Z_{\\alpha/2} + Z_{\\beta}}{\\mu_1 - \\mu_2} \\right)^2 \\cdot 2\\sigma^2\n",
    "$$\n",
    "\n",
    "### Choose Samples\n",
    "- Randomly select control and treatment groups.  \n",
    "- Ensure samples represent the population.  \n",
    "\n",
    "## Step 5: Assign Users\n",
    "- Randomly assign users to control or treatment groups.  \n",
    "\n",
    "## Step 6: Perform Statistical Test\n",
    "- **Binary Outcomes**: Z-test (or Chi-Square/Fisher’s Exact).  \n",
    "- **Continuous Outcomes**: t-test.  \n",
    "\n",
    "## Step 7: Analyze Results\n",
    "\n",
    "### Practical Significance\n",
    "- Evaluate if results are meaningful in real-world context.  \n",
    "\n",
    "### Reporting\n",
    "- Summarize test statistic, p-value, confidence intervals, and implications.  \n",
    "- Use charts/graphs for clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dd5466",
   "metadata": {
    "papermill": {
     "duration": 0.010955,
     "end_time": "2024-06-17T06:39:53.820766",
     "exception": false,
     "start_time": "2024-06-17T06:39:53.809811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1.1 EDA and Dataset Check\n",
    "\n",
    "Before running an A/B test, perform exploratory data analysis (EDA) to understand the dataset's structure and characteristics:\n",
    "\n",
    "1. **Loading the Dataset**  \n",
    "   - Import `Cookie_Cats_cleaned_v01.csv` and inspect the first few rows.  \n",
    "   - Helps identify columns and understand the initial structure.  \n",
    "\n",
    "2. **Summary Statistics**  \n",
    "   - Compute mean, median, standard deviation, variance, and overall distribution.  \n",
    "\n",
    "3. **Missing Values**  \n",
    "   - Check for missing values and handle them appropriately.  \n",
    "   - Ensures data integrity and avoids biases.  \n",
    "\n",
    "4. **Data Types**  \n",
    "   - Verify column data types for accurate calculations and analyses.  \n",
    "\n",
    "5. **Descriptive Statistics by Group**  \n",
    "   - Group by `version` (control vs. treatment) and calculate group statistics.  \n",
    "   - Includes mean, standard deviation, skewness, and kurtosis to spot outliers.  \n",
    "\n",
    "6. **Cross-tabulations**  \n",
    "   - Cross-tab `version` with `retention_1` and `retention_7` to see retention rates.  \n",
    "   - Understand relationships between categorical variables and group performance.  \n",
    "\n",
    "7. **Plots**  \n",
    "   - Use bar plots, box plots, and heatmaps to visualize distributions and correlations.  \n",
    "   - Provides graphical insight into patterns and relationships in the data.  \n",
    "\n",
    "Performing these EDA steps ensures a strong understanding of the dataset, highlights potential issues, and prepares the data for meaningful A/B testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b82b27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:39:53.845587Z",
     "iopub.status.busy": "2024-06-17T06:39:53.845154Z",
     "iopub.status.idle": "2024-06-17T06:39:56.083503Z",
     "shell.execute_reply": "2024-06-17T06:39:56.082416Z"
    },
    "papermill": {
     "duration": 2.25394,
     "end_time": "2024-06-17T06:39:56.086227",
     "exception": false,
     "start_time": "2024-06-17T06:39:53.832287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Cookie_Cats_cleaned_v01.csv')\n",
    "\n",
    "# Check for duplicate user IDs\n",
    "if df['userid'].duplicated().any():\n",
    "    print(\"Duplicates found in user_id. Dropping duplicates...\")\n",
    "    df = df.drop_duplicates(subset='userid')\n",
    "\n",
    "# Set user_id as the index\n",
    "df.set_index('userid', inplace=True)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary statistics of the dataset:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Display data types and non-null counts\n",
    "print(\"\\nData types and non-null counts:\")\n",
    "print(df.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in the dataset:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcec97fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:39:56.112422Z",
     "iopub.status.busy": "2024-06-17T06:39:56.112030Z",
     "iopub.status.idle": "2024-06-17T06:39:56.149409Z",
     "shell.execute_reply": "2024-06-17T06:39:56.147754Z"
    },
    "papermill": {
     "duration": 0.053826,
     "end_time": "2024-06-17T06:39:56.151779",
     "exception": false,
     "start_time": "2024-06-17T06:39:56.097953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Descriptive statistics\n",
    "descriptive_stats = df[numeric_cols].describe().T\n",
    "descriptive_stats['skewness'] = df[numeric_cols].skew()\n",
    "descriptive_stats['kurtosis'] = df[numeric_cols].kurtosis()\n",
    "\n",
    "print(\"\\nDescriptive Statistics (including skewness and kurtosis):\")\n",
    "print(descriptive_stats)\n",
    "\n",
    "\n",
    "# Percentage of each category in categorical features\n",
    "version_counts = df['version'].value_counts(normalize=True) * 100\n",
    "retention_1_counts = df['retention_1'].value_counts(normalize=True) * 100\n",
    "retention_7_counts = df['retention_7'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"\\nPercentage of each category in 'version':\")\n",
    "print(version_counts)\n",
    "\n",
    "print(\"\\nPercentage of each category in 'retention_1':\")\n",
    "print(retention_1_counts)\n",
    "\n",
    "print(\"\\nPercentage of each category in 'retention_7':\")\n",
    "print(retention_7_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd2eef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:39:56.177905Z",
     "iopub.status.busy": "2024-06-17T06:39:56.177544Z",
     "iopub.status.idle": "2024-06-17T06:39:56.235121Z",
     "shell.execute_reply": "2024-06-17T06:39:56.233622Z"
    },
    "papermill": {
     "duration": 0.074154,
     "end_time": "2024-06-17T06:39:56.237442",
     "exception": false,
     "start_time": "2024-06-17T06:39:56.163288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cross-tabulation for version and retention_1\n",
    "crosstab_retention_1 = pd.crosstab(df['version'], df['retention_1'], normalize='index')\n",
    "crosstab_retention_1.columns = ['Did Not Return', 'Returned']\n",
    "crosstab_retention_1 = crosstab_retention_1.reset_index()\n",
    "\n",
    "# Cross-tabulation for version and retention_7\n",
    "crosstab_retention_7 = pd.crosstab(df['version'], df['retention_7'], normalize='index')\n",
    "crosstab_retention_7.columns = ['Did Not Return', 'Returned']\n",
    "crosstab_retention_7 = crosstab_retention_7.reset_index()\n",
    "\n",
    "print(\"\\nCross-tabulation for version and retention_1:\")\n",
    "print(crosstab_retention_1)\n",
    "\n",
    "print(\"\\nCross-tabulation for version and retention_7:\")\n",
    "print(crosstab_retention_7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa4b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric columns\n",
    "# numeric_cols = df.select_dtypes(include=np.number).columns.tolist()  # if not already defined\n",
    "\n",
    "# Aggregation functions\n",
    "agg_funcs = ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'skew', 'kurt']\n",
    "\n",
    "# Compute descriptive statistics including skewness and kurtosis\n",
    "grouped_stats = df.groupby('version')[numeric_cols].agg(['count', 'mean', 'std', 'min', \n",
    "                                                        lambda x: x.quantile(0.25), \n",
    "                                                        lambda x: x.quantile(0.5), \n",
    "                                                        lambda x: x.quantile(0.75), \n",
    "                                                        'max', \n",
    "                                                        lambda x: x.skew(), \n",
    "                                                        lambda x: x.kurtosis()])\n",
    "\n",
    "# Rename lambda columns for clarity\n",
    "grouped_stats.columns = ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'skewness', 'kurtosis']\n",
    "\n",
    "# Reset index for a clean table\n",
    "grouped_stats = grouped_stats.reset_index()\n",
    "\n",
    "print(\"\\nDescriptive Statistics with Skewness and Kurtosis by Version:\")\n",
    "print(grouped_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06935afb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:39:56.355680Z",
     "iopub.status.busy": "2024-06-17T06:39:56.355325Z",
     "iopub.status.idle": "2024-06-17T06:40:00.043250Z",
     "shell.execute_reply": "2024-06-17T06:40:00.041984Z"
    },
    "papermill": {
     "duration": 3.704882,
     "end_time": "2024-06-17T06:40:00.046997",
     "exception": false,
     "start_time": "2024-06-17T06:39:56.342115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# Function to calculate percentages\n",
    "def value_counts_percent(df, col):\n",
    "    return df[col].value_counts(normalize=True) * 100\n",
    "\n",
    "# Function to plot bar chart with percentages\n",
    "def plot_bar(ax, data, title, xlabel, ylabel='Percentage', color='steelblue'):\n",
    "    sns.barplot(x=data.index, y=data.values, ax=ax, color=color)\n",
    "    for i, val in enumerate(data.values):\n",
    "        ax.text(i, val + 1, f'{val:.1f}%', ha='center', va='bottom')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "# Calculate distributions\n",
    "version_counts = value_counts_percent(df, 'version')\n",
    "retention_1_counts = value_counts_percent(df, 'retention_1')\n",
    "retention_7_counts = value_counts_percent(df, 'retention_7')\n",
    "\n",
    "# Retention by version\n",
    "def retention_by_version(df, retention_col):\n",
    "    ret = df.groupby(['version', retention_col]).size().reset_index(name='counts')\n",
    "    ret['percentage'] = ret['counts'] / ret.groupby('version')['counts'].transform('sum') * 100\n",
    "    return ret\n",
    "\n",
    "retention_1_by_version = retention_by_version(df, 'retention_1')\n",
    "retention_7_by_version = retention_by_version(df, 'retention_7')\n",
    "\n",
    "# Create figure and axes\n",
    "fig, axes = plt.subplots(4, 2, figsize=(18, 25))\n",
    "fig.suptitle('Data Distributions and Analysis', fontsize=20)\n",
    "\n",
    "# Plot distributions\n",
    "plot_bar(axes[0, 0], version_counts, 'Distribution of Version', 'Version', color='mediumseagreen')\n",
    "plot_bar(axes[0, 1], retention_1_counts, 'Distribution of Retention 1 Day After Installation', 'Retention 1', color='steelblue')\n",
    "plot_bar(axes[1, 0], retention_7_counts, 'Distribution of Retention 7 Days After Installation', 'Retention 7', color='coral')\n",
    "\n",
    "# Boxplots\n",
    "sns.boxplot(ax=axes[1, 1], y=df['sum_gamerounds'], color='skyblue')\n",
    "axes[1, 1].set_title('Distribution of Sum of Game Rounds')\n",
    "axes[1, 1].set_ylabel('Sum of Game Rounds')\n",
    "axes[1, 1].set_yscale('log')\n",
    "\n",
    "sns.boxplot(ax=axes[2, 0], x='version', y='sum_gamerounds', data=df, color='mediumorchid')\n",
    "axes[2, 0].set_title('Sum of Game Rounds by Version')\n",
    "axes[2, 0].set_yscale('log')\n",
    "\n",
    "# Retention by version barplots\n",
    "def plot_retention(ax, data, retention_col, title):\n",
    "    sns.barplot(ax=ax, x='version', y='percentage', hue=retention_col, data=data, palette='viridis')\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        ax.text(p.get_x() + p.get_width()/2., height + 1, f'{height:.1f}%', ha='center', va='bottom')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Version')\n",
    "    ax.set_ylabel(f'{retention_col.replace(\"_\", \" \").title()} Rate (%)')\n",
    "\n",
    "plot_retention(axes[2, 1], retention_1_by_version, 'retention_1', 'Retention 1 Day After Installation by Version')\n",
    "plot_retention(axes[3, 0], retention_7_by_version, 'retention_7', 'Retention 7 Days After Installation by Version')\n",
    "\n",
    "# Remove empty subplot\n",
    "fig.delaxes(axes[3, 1])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d66e414",
   "metadata": {},
   "source": [
    "## Dataset Description and Findings\n",
    "\n",
    "The dataset used is `Cookie_Cats_cleaned_v01.csv`, containing user behavior and retention data from the Cookie Cats game before and after an intervention.\n",
    "\n",
    "### Columns\n",
    "\n",
    "1. **version** (object)  \n",
    "   - Indicates control or treatment group: `gate_30` (control), `gate_40` (treatment)  \n",
    "   - **Distribution:** gate_30: 49.56%, gate_40: 50.44%  \n",
    "   - Nearly equal distribution, making it suitable for A/B testing.  \n",
    "\n",
    "2. **sum_gamerounds** (int64)  \n",
    "   - Total number of game rounds played by the user  \n",
    "   - **Stats:** Mean: 51.87, SD: 195.05, Min: 0, Median: 16, Max: 49,854, Skewness: 185.44, Kurtosis: 47,130.37  \n",
    "   - **Insight:** Highly skewed with extreme outliers; most users play few rounds, but a few play a lot.  \n",
    "\n",
    "3. **retention_1** (bool)  \n",
    "   - Whether the user returned one day after installation  \n",
    "   - **Distribution:** True: 44.52%, False: 55.48%  \n",
    "   - **Insight:** Less than half of users return after one day.  \n",
    "\n",
    "4. **retention_7** (bool)  \n",
    "   - Whether the user returned seven days after installation  \n",
    "   - **Distribution:** True: 18.61%, False: 81.39%  \n",
    "   - **Insight:** Very few users return after seven days.  \n",
    "\n",
    "### Dataset Overview\n",
    "\n",
    "- **Total Entries:** 90,189\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215b0556",
   "metadata": {
    "papermill": {
     "duration": 0.015595,
     "end_time": "2024-06-17T06:40:00.108040",
     "exception": false,
     "start_time": "2024-06-17T06:40:00.092445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1.2 Define the Problem\n",
    "\n",
    "The goal of this A/B test is to compare two groups (control vs. treatment) to see if the intervention had a significant effect.\n",
    "\n",
    "- **Control Group:** No treatment.  \n",
    "- **Treatment Group:** Receives the intervention.  \n",
    "\n",
    "We aim to answer three questions:\n",
    "\n",
    "### Question 1: Increase in Average Game Sessions\n",
    "- **Objective:** Has the average number of game sessions increased by 5?  \n",
    "- **Null Hypothesis ($H_0$):** No increase of 5 sessions in the treatment group.  \n",
    "- **Alternative Hypothesis ($H_1$):** Average sessions increased by 5 in the treatment group.  \n",
    "\n",
    "### Question 2: 1-Day Player Retention\n",
    "- **Objective:** Has 1-day retention increased by 2%?  \n",
    "- **Null Hypothesis ($H_0$):** No 2% increase in 1-day retention in the treatment group.  \n",
    "- **Alternative Hypothesis ($H_1$):** 1-day retention increased by 2% in the treatment group.  \n",
    "\n",
    "### Question 3: 7-Day Player Retention\n",
    "- **Objective:** Has 7-day retention increased by 5%?  \n",
    "- **Null Hypothesis ($H_0$):** No 5% increase in 7-day retention in the treatment group.  \n",
    "- **Alternative Hypothesis ($H_1$):** 7-day retention increased by 5% in the treatment group.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac039a2",
   "metadata": {
    "papermill": {
     "duration": 0.014521,
     "end_time": "2024-06-17T06:40:00.137326",
     "exception": false,
     "start_time": "2024-06-17T06:40:00.122805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Preprocessing Steps\n",
    "\n",
    "Before running the A/B test, preprocess the data to ensure it’s clean and ready for analysis.\n",
    "\n",
    "### Key Steps:\n",
    "\n",
    "1. **Handling Missing Values**  \n",
    "   - Remove or impute missing values to maintain data integrity and avoid biases.  \n",
    "\n",
    "2. **Outlier Detection**  \n",
    "   - Identify and handle outliers that may skew results.  \n",
    "   - Outliers can distort statistical tests and lead to incorrect conclusions.  \n",
    "\n",
    "3. **Data Transformation**  \n",
    "   - Normalize or standardize variables if necessary, especially for continuous data.  \n",
    "   - Ensures variables on different scales do not affect the analysis.  \n",
    "\n",
    "4. **Feature Engineering**  \n",
    "   - Create new features if needed, e.g., interaction terms or derived metrics.  \n",
    "   - Helps better capture patterns in the data.  \n",
    "\n",
    "### Preprocessing in Our Case\n",
    "\n",
    "- The dataset is already clean with no missing values.  \n",
    "- Focus is on handling outliers identified during EDA.  \n",
    "- Data transformation and feature engineering are not required since we are performing statistical tests, not predictive modeling.  \n",
    "\n",
    "By preprocessing the data, we ensure the dataset is suitable for accurate and reliable A/B testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e499ec7",
   "metadata": {
    "papermill": {
     "duration": 0.01969,
     "end_time": "2024-06-17T06:40:00.174862",
     "exception": false,
     "start_time": "2024-06-17T06:40:00.155172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Removing Outliers Using the IQR Method\n",
    "\n",
    "To avoid skewed results from extreme values, we remove outliers using the Interquartile Range (IQR) method:\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. Calculate the IQR for each version (control and treatment).  \n",
    "2. Determine the lower and upper bounds for outliers.  \n",
    "3. Filter out the outliers from the dataset.  \n",
    "\n",
    "**Note:**  \n",
    "Preprocessing steps like outlier removal, normalization, and missing value handling should be done **after splitting the data** into control and treatment groups.  \n",
    "This ensures unbiased results and maintains the independence of each group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b22591",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:40:00.248872Z",
     "iopub.status.busy": "2024-06-17T06:40:00.247720Z",
     "iopub.status.idle": "2024-06-17T06:40:00.334046Z",
     "shell.execute_reply": "2024-06-17T06:40:00.332927Z"
    },
    "papermill": {
     "duration": 0.105043,
     "end_time": "2024-06-17T06:40:00.336283",
     "exception": false,
     "start_time": "2024-06-17T06:40:00.231240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate groups\n",
    "groups = {v: df[df['version'] == v] for v in ['gate_30', 'gate_40']}\n",
    "\n",
    "# Function to remove outliers using IQR\n",
    "def remove_outliers_iqr(df, col):\n",
    "    Q1, Q3 = df[col].quantile([0.25, 0.75])\n",
    "    IQR = Q3 - Q1\n",
    "    lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "    return df[df[col].between(lower, upper)]\n",
    "\n",
    "# Clean each group\n",
    "groups_cleaned = {name: remove_outliers_iqr(data, 'sum_gamerounds') \n",
    "                  for name, data in groups.items()}\n",
    "\n",
    "# Show original vs cleaned shapes\n",
    "for name in groups:\n",
    "    print(f\"{name} - original: {groups[name].shape}, cleaned: {groups_cleaned[name].shape}\")\n",
    "\n",
    "# Assign back to variables if needed\n",
    "control_group = groups_cleaned['gate_30']\n",
    "treatment_group = groups_cleaned['gate_40']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deedc989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:40:00.367873Z",
     "iopub.status.busy": "2024-06-17T06:40:00.367407Z",
     "iopub.status.idle": "2024-06-17T06:40:00.383114Z",
     "shell.execute_reply": "2024-06-17T06:40:00.381650Z"
    },
    "papermill": {
     "duration": 0.034561,
     "end_time": "2024-06-17T06:40:00.385579",
     "exception": false,
     "start_time": "2024-06-17T06:40:00.351018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concatenate the cleaned control and treatment groups\n",
    "df = pd.concat([control_group, treatment_group])\n",
    "\n",
    "# Verify the concatenation by checking the new shape and by sampling the data\n",
    "print(f\"Shape of the concatenated dataframe: {df.shape}\")\n",
    "print(df.sample(5))  # Display a random sample of 5 rows to verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c600883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric columns\n",
    "# numeric_cols = df.select_dtypes(include=np.number).columns.tolist()  # if not already defined\n",
    "\n",
    "# Aggregation functions\n",
    "agg_funcs = ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'skew', 'kurt']\n",
    "\n",
    "# Compute descriptive statistics including skewness and kurtosis\n",
    "grouped_stats = df.groupby('version')[numeric_cols].agg(['count', 'mean', 'std', 'min', \n",
    "                                                        lambda x: x.quantile(0.25), \n",
    "                                                        lambda x: x.quantile(0.5), \n",
    "                                                        lambda x: x.quantile(0.75), \n",
    "                                                        'max', \n",
    "                                                        'skew', \n",
    "                                                        lambda x: x.kurtosis()])\n",
    "\n",
    "# Rename lambda columns for clarity\n",
    "grouped_stats.columns = ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'skewness', 'kurtosis']\n",
    "\n",
    "# Reset index for a clean table\n",
    "grouped_stats = grouped_stats.reset_index()\n",
    "\n",
    "print(\"\\nDescriptive Statistics with Skewness and Kurtosis by Version:\")\n",
    "print(grouped_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b9dcca",
   "metadata": {
    "papermill": {
     "duration": 0.016745,
     "end_time": "2024-06-17T06:40:00.530892",
     "exception": false,
     "start_time": "2024-06-17T06:40:00.514147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Set the Probability of Type I and Type II Errors\n",
    "\n",
    "In hypothesis testing, we define acceptable probabilities for Type I and Type II errors to ensure robust test results.\n",
    "\n",
    "### Type I Error (Alpha)\n",
    "\n",
    "- **Definition**: Probability of rejecting the null hypothesis when it is true.  \n",
    "  - Risk of concluding there is an effect when there isn’t.\n",
    "- **Common Value**: 0.05 (5%)  \n",
    "- **Implications for Our Dataset**:\n",
    "  - **Question 1**: Incorrectly concluding the average number of game sessions increased by 5.\n",
    "  - **Question 2**: Incorrectly concluding 1-day player retention increased by 2%.\n",
    "  - **Question 3**: Incorrectly concluding 7-day player retention increased by 5%.\n",
    "\n",
    "### Type II Error (Beta)\n",
    "\n",
    "- **Definition**: Probability of failing to reject the null hypothesis when it is false.  \n",
    "  - Risk of missing a true effect.\n",
    "- **Common Value**: 0.20 (20%)  \n",
    "- **Power of the Test**: $1 - \\beta = 0.80$ (80%)  \n",
    "- **Implications for Our Dataset**:\n",
    "  - **Question 1**: Failing to detect a real increase of 5 sessions.\n",
    "  - **Question 2**: Failing to detect a real 2% increase in 1-day retention.\n",
    "  - **Question 3**: Failing to detect a real 5% increase in 7-day retention.\n",
    "\n",
    "### Chosen Values for Our A/B Tests\n",
    "\n",
    "- **Alpha ($\\alpha$)**: 0.05  \n",
    "- **Beta ($\\beta$)**: 0.20  \n",
    "- **Power**: 0.80  \n",
    "\n",
    "These values balance the risks of Type I and Type II errors while ensuring reliable and statistically significant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e9951f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:40:00.566806Z",
     "iopub.status.busy": "2024-06-17T06:40:00.566394Z",
     "iopub.status.idle": "2024-06-17T06:40:00.572345Z",
     "shell.execute_reply": "2024-06-17T06:40:00.571028Z"
    },
    "papermill": {
     "duration": 0.024932,
     "end_time": "2024-06-17T06:40:00.574827",
     "exception": false,
     "start_time": "2024-06-17T06:40:00.549895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Define alpha, beta, and power\n",
    "alpha = 0.05\n",
    "beta = 0.20\n",
    "power = 1 - beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08954e5",
   "metadata": {
    "papermill": {
     "duration": 0.014622,
     "end_time": "2024-06-17T06:40:00.604598",
     "exception": false,
     "start_time": "2024-06-17T06:40:00.589976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4.1 Calculate Sample Size and Choose Samples for Binary A/B Test\n",
    "\n",
    "To calculate the sample size for a binary A/B test, we need to determine the proportions of success in both the control and treatment groups. The formula for calculating the required sample size for each group in a binary A/B test is:\n",
    "\n",
    "$$\n",
    "n = \\left( \\frac{Z_{\\alpha/2} + Z_{\\beta}}{p_1 - p_2} \\right)^2 \\left( p_1(1 - p_1) + p_2(1 - p_2) \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $Z_{\\alpha/2}$ is the Z-score for the chosen significance level.\n",
    "- $Z_{\\beta}$ is the Z-score for the chosen power.\n",
    "- $p_1$ is the proportion of success in the control group.\n",
    "- $p_2$ is the proportion of success in the treatment group.\n",
    "\n",
    "### Steps:\n",
    "1. Define the baseline proportions ($p_1$) for retention rates in the control group.\n",
    "2. Define the expected proportions ($p_2$) for retention rates in the treatment group, including the effect size.\n",
    "3. Use the `statsmodels` library to calculate the required sample size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7806efe4",
   "metadata": {
    "papermill": {
     "duration": 0.014708,
     "end_time": "2024-06-17T06:40:00.634240",
     "exception": false,
     "start_time": "2024-06-17T06:40:00.619532",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Method 1 First implementation approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea34cc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:40:00.667428Z",
     "iopub.status.busy": "2024-06-17T06:40:00.666133Z",
     "iopub.status.idle": "2024-06-17T06:40:01.119667Z",
     "shell.execute_reply": "2024-06-17T06:40:01.118446Z"
    },
    "papermill": {
     "duration": 0.47318,
     "end_time": "2024-06-17T06:40:01.122531",
     "exception": false,
     "start_time": "2024-06-17T06:40:00.649351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statsmodels.stats.api as sms\n",
    "\n",
    "# Recompute crosstabs for retention rates by version\n",
    "crosstab_retention_1 = pd.crosstab(df['version'], df['retention_1'], normalize='index')\n",
    "crosstab_retention_7 = pd.crosstab(df['version'], df['retention_7'], normalize='index')\n",
    "\n",
    "# Extract baseline proportions from crosstab results\n",
    "p1_retention_1 = crosstab_retention_1.loc['gate_30', True]\n",
    "p1_retention_7 = crosstab_retention_7.loc['gate_30', True]\n",
    "\n",
    "# Define expected improvements\n",
    "p2_retention_1 = p1_retention_1 + 0.02  # 2% increase for retention after 1 day\n",
    "p2_retention_7 = p1_retention_7 + 0.05  # 5% increase for retention after 7 days\n",
    "\n",
    "# Define alpha, beta, and calculate power\n",
    "alpha = 0.05\n",
    "beta = 0.20\n",
    "power = 1 - beta\n",
    "\n",
    "# Calculate effect sizes and required sample sizes\n",
    "effect_size_retention_1 = sms.proportion_effectsize(p1_retention_1, p2_retention_1)\n",
    "n_retention_1 = sms.NormalIndPower().solve_power(effect_size=effect_size_retention_1, power=power, alpha=alpha, ratio=1)\n",
    "\n",
    "effect_size_retention_7 = sms.proportion_effectsize(p1_retention_7, p2_retention_7)\n",
    "n_retention_7 = sms.NormalIndPower().solve_power(effect_size=effect_size_retention_7, power=power, alpha=alpha, ratio=1)\n",
    "\n",
    "required_sample_sizes = {\n",
    "    \"Required sample size for retention rate after 1 day test\": int(n_retention_1),\n",
    "    \"Required sample size for retention rate after 7 days test\": int(n_retention_7)\n",
    "}\n",
    "\n",
    "required_sample_sizes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7fc442",
   "metadata": {
    "papermill": {
     "duration": 0.015291,
     "end_time": "2024-06-17T06:40:01.153185",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.137894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Method 1 Second implementation approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c957cb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:40:01.187091Z",
     "iopub.status.busy": "2024-06-17T06:40:01.185867Z",
     "iopub.status.idle": "2024-06-17T06:40:01.218919Z",
     "shell.execute_reply": "2024-06-17T06:40:01.216997Z"
    },
    "papermill": {
     "duration": 0.052973,
     "end_time": "2024-06-17T06:40:01.221698",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.168725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statsmodels.stats.api as sms\n",
    "\n",
    "# Define alpha, beta, and power\n",
    "alpha = 0.05\n",
    "beta = 0.20\n",
    "power = 1 - beta\n",
    "\n",
    "# Baseline and expected proportions for retention rates\n",
    "p1_retention_1 = control_group['retention_1'].mean()\n",
    "p2_retention_1 = p1_retention_1 + 0.02  # 2% increase for retention after 1 day\n",
    "\n",
    "p1_retention_7 = control_group['retention_7'].mean()\n",
    "p2_retention_7 = p1_retention_7 + 0.05  # 5% increase for retention after 7 days\n",
    "\n",
    "# Calculate sample sizes using statsmodels\n",
    "effect_size_retention_1 = sms.proportion_effectsize(p1_retention_1, p2_retention_1)\n",
    "n_retention_1 = sms.NormalIndPower().solve_power(effect_size=effect_size_retention_1, power=power, alpha=alpha, ratio=1)\n",
    "\n",
    "effect_size_retention_7 = sms.proportion_effectsize(p1_retention_7, p2_retention_7)\n",
    "n_retention_7 = sms.NormalIndPower().solve_power(effect_size=effect_size_retention_7, power=power, alpha=alpha, ratio=1)\n",
    "\n",
    "print(f\"Required sample size for retention rate after 1 day test: {int(n_retention_1)}\")\n",
    "print(f\"Required sample size for retention rate after 7 days test: {int(n_retention_7)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4199fb02",
   "metadata": {
    "papermill": {
     "duration": 0.015778,
     "end_time": "2024-06-17T06:40:01.310686",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.294908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Method 2 Implement from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3df18a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:40:01.343921Z",
     "iopub.status.busy": "2024-06-17T06:40:01.343494Z",
     "iopub.status.idle": "2024-06-17T06:40:01.355267Z",
     "shell.execute_reply": "2024-06-17T06:40:01.353961Z"
    },
    "papermill": {
     "duration": 0.031075,
     "end_time": "2024-06-17T06:40:01.357690",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.326615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Define alpha, beta, and power\n",
    "alpha = 0.05\n",
    "beta = 0.20\n",
    "power = 1 - beta\n",
    "\n",
    "# Z-scores for the significance level (alpha) and power\n",
    "Z_alpha = stats.norm.ppf(1 - alpha / 2)\n",
    "Z_beta = stats.norm.ppf(power)\n",
    "\n",
    "# Baseline and expected proportions for retention rates\n",
    "p1_retention_1 = control_group['retention_1'].mean()\n",
    "p2_retention_1 = p1_retention_1 + 0.02  # 2% increase for retention after 1 day\n",
    "\n",
    "p1_retention_7 = control_group['retention_7'].mean()\n",
    "p2_retention_7 = p1_retention_7 + 0.05  # 5% increase for retention after 7 days\n",
    "\n",
    "# Function to calculate sample size for binary outcome\n",
    "def calculate_sample_size_binary(p1, p2, Z_alpha, Z_beta):\n",
    "    pooled_prob = (p1 + p2) / 2\n",
    "    return int(((Z_alpha * (2 * pooled_prob * (1 - pooled_prob)) ** 0.5 + Z_beta * (p1 * (1 - p1) + p2 * (1 - p2)) ** 0.5) / (p1 - p2)) ** 2)\n",
    "\n",
    "# Calculate sample sizes\n",
    "n_retention_1 = calculate_sample_size_binary(p1_retention_1, p2_retention_1, Z_alpha, Z_beta)\n",
    "n_retention_7 = calculate_sample_size_binary(p1_retention_7, p2_retention_7, Z_alpha, Z_beta)\n",
    "\n",
    "print(f\"Required sample size for retention rate after 1 day test: {n_retention_1}\")\n",
    "print(f\"Required sample size for retention rate after 7 days test: {n_retention_7}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f183ff8",
   "metadata": {
    "papermill": {
     "duration": 0.015215,
     "end_time": "2024-06-17T06:40:01.388484",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.373269",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4.2 Calculate Sample Size and Choose Samples for Continuous A/B Test\n",
    "\n",
    "To calculate the sample size for a continuous A/B test, we need to know the standard deviation of the population and the expected effect size. The formula for calculating the required sample size for each group in a continuous A/B test is:\n",
    "\n",
    "$$\n",
    "n = \\left( \\frac{Z_{\\alpha/2} + Z_{\\beta}}{\\mu_1 - \\mu_2} \\right)^2 \\cdot 2\\sigma^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $Z_{\\alpha/2}$ is the Z-score for the chosen significance level.\n",
    "- $Z_{\\beta}$ is the Z-score for the chosen power.\n",
    "- $\\mu_1$ and $\\mu_2$ are the means of the control and treatment groups, respectively.\n",
    "- $\\sigma$ is the standard deviation of the population.\n",
    "\n",
    "### Steps:\n",
    "1. Define the expected effect size ($\\mu_1 - \\mu_2$) for the average number of game sessions.\n",
    "2. Calculate the standard deviation ($\\sigma$) of the `sum_gamerounds` column.\n",
    "3. Use the `statsmodels` library to calculate the required sample size.\n",
    "\n",
    "Here's the Python code to perform these calculations:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d72b2f8",
   "metadata": {
    "papermill": {
     "duration": 0.015406,
     "end_time": "2024-06-17T06:40:01.419229",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.403823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Method 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187bace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:40:01.453033Z",
     "iopub.status.busy": "2024-06-17T06:40:01.452597Z",
     "iopub.status.idle": "2024-06-17T06:40:01.468140Z",
     "shell.execute_reply": "2024-06-17T06:40:01.466718Z"
    },
    "papermill": {
     "duration": 0.035,
     "end_time": "2024-06-17T06:40:01.470654",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.435654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "effect_size_sessions = 5      # Expected mean difference\n",
    "alpha = 0.05                  # Significance level\n",
    "power = 0.8                   # Desired power (80%)\n",
    "\n",
    "# Combine groups and calculate pooled standard deviation\n",
    "std_dev_sessions = pd.concat([\n",
    "    control_group['sum_gamerounds'],\n",
    "    treatment_group['sum_gamerounds']\n",
    "]).std()\n",
    "\n",
    "# Compute Cohen’s d (standardized effect size)\n",
    "cohens_d = effect_size_sessions / std_dev_sessions\n",
    "\n",
    "# Calculate required sample size per group\n",
    "n_sessions = sms.NormalIndPower().solve_power(\n",
    "    effect_size=cohens_d, \n",
    "    power=power, \n",
    "    alpha=alpha, \n",
    "    ratio=1  # equal-sized groups\n",
    ")\n",
    "\n",
    "print(f\"Required sample size per group for average number of game sessions test: {int(np.ceil(n_sessions))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9248b65",
   "metadata": {
    "papermill": {
     "duration": 0.016933,
     "end_time": "2024-06-17T06:40:01.503736",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.486803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Method 2: Implement from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7a7b70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:40:01.539597Z",
     "iopub.status.busy": "2024-06-17T06:40:01.539173Z",
     "iopub.status.idle": "2024-06-17T06:40:01.548484Z",
     "shell.execute_reply": "2024-06-17T06:40:01.546789Z"
    },
    "papermill": {
     "duration": 0.029709,
     "end_time": "2024-06-17T06:40:01.551016",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.521307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "effect_size_sessions = 5   # Expected mean difference between groups\n",
    "alpha = 0.05               # Significance level (two-tailed)\n",
    "power = 0.8                # Desired power (80%)\n",
    "\n",
    "# Z-scores for alpha and power\n",
    "Z_alpha = stats.norm.ppf(1 - alpha / 2)\n",
    "Z_beta = stats.norm.ppf(power)\n",
    "\n",
    "# Standard deviation of combined groups\n",
    "std_dev_sessions = pd.concat([\n",
    "    control_group['sum_gamerounds'],\n",
    "    treatment_group['sum_gamerounds']\n",
    "]).std()\n",
    "\n",
    "# Sample size per group (two-sample t-test, equal groups)\n",
    "n_sessions = int(np.ceil(2 * ((Z_alpha + Z_beta) * std_dev_sessions / effect_size_sessions) ** 2))\n",
    "\n",
    "print(f\"Required sample size per group for average number of game sessions test: {n_sessions}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bef82b",
   "metadata": {
    "papermill": {
     "duration": 0.016092,
     "end_time": "2024-06-17T06:40:01.583111",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.567019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5.1 Assign Users for Retention After 1 Day\n",
    "\n",
    "To test 1-day retention, users must be randomly assigned to the control and treatment groups based on the calculated sample size.  \n",
    "This ensures equal representation and reliable test results.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Randomly select the required number of users for each group (control and treatment).  \n",
    "2. Confirm that both groups meet the sample size requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe62a599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:40:01.616788Z",
     "iopub.status.busy": "2024-06-17T06:40:01.616340Z",
     "iopub.status.idle": "2024-06-17T06:40:01.629515Z",
     "shell.execute_reply": "2024-06-17T06:40:01.628298Z"
    },
    "papermill": {
     "duration": 0.032776,
     "end_time": "2024-06-17T06:40:01.631780",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.599004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Randomly select users for control and treatment groups based on the calculated sample size for retention after 1 day\n",
    "control_users_retention_1 = control_group.sample(n=int(n_retention_1), random_state=42)\n",
    "treatment_users_retention_1 = treatment_group.sample(n=int(n_retention_1), random_state=42)\n",
    "\n",
    "# Verify the sample sizes\n",
    "print(f\"Sample size for control group (retention 1 day): {len(control_users_retention_1)}\")\n",
    "print(f\"Sample size for treatment group (retention 1 day): {len(treatment_users_retention_1)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e21a263",
   "metadata": {
    "papermill": {
     "duration": 0.015478,
     "end_time": "2024-06-17T06:40:01.662874",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.647396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5.2 Assign Users for Retention After 7 Days\n",
    "\n",
    "To test 7-day retention, users must be randomly assigned to the control and treatment groups based on the calculated sample size.  \n",
    "This ensures equal representation and reliable test results.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Randomly select the required number of users for each group (control and treatment).  \n",
    "2. Confirm that both groups meet the sample size requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8b2160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:40:01.695880Z",
     "iopub.status.busy": "2024-06-17T06:40:01.695469Z",
     "iopub.status.idle": "2024-06-17T06:40:01.707843Z",
     "shell.execute_reply": "2024-06-17T06:40:01.706648Z"
    },
    "papermill": {
     "duration": 0.031732,
     "end_time": "2024-06-17T06:40:01.710192",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.678460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Randomly select users for control and treatment groups based on the calculated sample size for retention after 7 days\n",
    "control_users_retention_7 = control_group.sample(n=int(n_retention_7), random_state=43)\n",
    "treatment_users_retention_7 = treatment_group.sample(n=int(n_retention_7), random_state=43)\n",
    "\n",
    "# Verify the sample sizes\n",
    "print(f\"Sample size for control group (retention 7 days): {len(control_users_retention_7)}\")\n",
    "print(f\"Sample size for treatment group (retention 7 days): {len(treatment_users_retention_7)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cb4bb9",
   "metadata": {
    "papermill": {
     "duration": 0.015561,
     "end_time": "2024-06-17T06:40:01.741346",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.725785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5.3 Assign Users for Sum of Game Rounds\n",
    "\n",
    "To test the total number of game rounds, users must be randomly assigned to the control and treatment groups based on the calculated sample size.  \n",
    "This ensures equal representation and reliable test results.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Randomly select the required number of users for each group (control and treatment).  \n",
    "2. Confirm that both groups meet the sample size requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc61db5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:40:01.774539Z",
     "iopub.status.busy": "2024-06-17T06:40:01.774161Z",
     "iopub.status.idle": "2024-06-17T06:40:01.785521Z",
     "shell.execute_reply": "2024-06-17T06:40:01.784288Z"
    },
    "papermill": {
     "duration": 0.030777,
     "end_time": "2024-06-17T06:40:01.787794",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.757017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Randomly select users for control and treatment groups based on the calculated sample size for sum of game rounds\n",
    "control_users_gamerounds = control_group.sample(n=int(n_sessions), random_state=42)\n",
    "treatment_users_gamerounds = treatment_group.sample(n=int(n_sessions), random_state=42)\n",
    "\n",
    "# Verify the sample sizes\n",
    "print(f\"Sample size for control group (sum of game rounds): {len(control_users_gamerounds)}\")\n",
    "print(f\"Sample size for treatment group (sum of game rounds): {len(treatment_users_gamerounds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285cbc86",
   "metadata": {
    "papermill": {
     "duration": 0.015905,
     "end_time": "2024-06-17T06:40:01.820415",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.804510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6.1 Perform A/B Test for Retention After 1 Day\n",
    "\n",
    "**Question:** Has player retention increased by 2% after 1 day?\n",
    "\n",
    "To test if 1-day retention has increased by 2% in the treatment group compared to the control group, we perform a **Z-test for proportions**.\n",
    "\n",
    "### Assumptions for the Z-Test\n",
    "\n",
    "1. **Independence**  \n",
    "   - Observations must be independent.  \n",
    "   - Ensured through random sampling and proper experimental design.  \n",
    "\n",
    "2. **Normality**  \n",
    "   - The sampling distribution of the sample proportion is approximately normal.  \n",
    "   - Holds when both $np$ and $n(1-p)$ are greater than 5.  \n",
    "\n",
    "3. **Large Sample Size**  \n",
    "   - The number of successes and failures in each group should be large enough for the normal approximation to the binomial distribution.  \n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Calculate the observed proportions of retention in both groups.  \n",
    "2. Perform a Z-test for proportions to compare retention rates.  \n",
    "3. Determine if the difference is statistically significant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb7dfd8",
   "metadata": {
    "papermill": {
     "duration": 0.015878,
     "end_time": "2024-06-17T06:40:01.853300",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.837422",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Method 1 First implementation approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8b00d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:40:01.889357Z",
     "iopub.status.busy": "2024-06-17T06:40:01.888952Z",
     "iopub.status.idle": "2024-06-17T06:40:01.901110Z",
     "shell.execute_reply": "2024-06-17T06:40:01.900009Z"
    },
    "papermill": {
     "duration": 0.033512,
     "end_time": "2024-06-17T06:40:01.903471",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.869959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# Significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Observed proportions\n",
    "p_control = control_users_retention_1['retention_1'].mean()\n",
    "p_treatment = treatment_users_retention_1['retention_1'].mean()\n",
    "n_control = len(control_users_retention_1)\n",
    "n_treatment = len(treatment_users_retention_1)\n",
    "\n",
    "# Check assumptions: np > 5 and n(1-p) > 5 for both groups\n",
    "assumptions_met = all([\n",
    "    n_control * p_control > 5,\n",
    "    n_control * (1 - p_control) > 5,\n",
    "    n_treatment * p_treatment > 5,\n",
    "    n_treatment * (1 - p_treatment) > 5\n",
    "])\n",
    "\n",
    "if not assumptions_met:\n",
    "    print(\"Z-test assumptions not met, cannot perform the test.\")\n",
    "else:\n",
    "    print(\"All assumptions are met for the Z-test.\")\n",
    "\n",
    "    # Number of successes and observations\n",
    "    successes = [treatment_users_retention_1['retention_1'].sum(),\n",
    "                 control_users_retention_1['retention_1'].sum()]\n",
    "    n_obs = [n_treatment, n_control]\n",
    "\n",
    "    # One-tailed Z-test (alternative='larger' since we expect treatment > control)\n",
    "    z_stat, p_val = proportions_ztest(successes, n_obs, alternative='larger')\n",
    "\n",
    "    print(f\"Z-statistic: {z_stat:.3f}\")\n",
    "    print(f\"P-value: {p_val:.3f}\")\n",
    "\n",
    "    # Interpretation\n",
    "    if p_val < alpha:\n",
    "        print(\"Reject null hypothesis: Retention after 1 day is significantly higher in the treatment group.\")\n",
    "    else:\n",
    "        print(\"Fail to reject null hypothesis: No significant increase in retention after 1 day.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26040c78",
   "metadata": {
    "papermill": {
     "duration": 0.015828,
     "end_time": "2024-06-17T06:40:01.935604",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.919776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Method 1 Second implementation approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d1fd8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:40:01.971048Z",
     "iopub.status.busy": "2024-06-17T06:40:01.970646Z",
     "iopub.status.idle": "2024-06-17T06:40:01.982222Z",
     "shell.execute_reply": "2024-06-17T06:40:01.980999Z"
    },
    "papermill": {
     "duration": 0.033337,
     "end_time": "2024-06-17T06:40:01.985206",
     "exception": false,
     "start_time": "2024-06-17T06:40:01.951869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# Define alpha\n",
    "alpha = 0.05\n",
    "\n",
    "# Observed proportions and sample sizes\n",
    "p_control = control_users_retention_1['retention_1'].mean()\n",
    "p_treatment = treatment_users_retention_1['retention_1'].mean()\n",
    "n_control = len(control_users_retention_1)\n",
    "n_treatment = len(treatment_users_retention_1)\n",
    "\n",
    "# Check assumptions for Z-test\n",
    "assumptions_met = all([\n",
    "    n_control * p_control > 5,\n",
    "    n_control * (1 - p_control) > 5,\n",
    "    n_treatment * p_treatment > 5,\n",
    "    n_treatment * (1 - p_treatment) > 5\n",
    "])\n",
    "\n",
    "if not assumptions_met:\n",
    "    print(\"Z-test assumptions not met, cannot perform the test.\")\n",
    "else:\n",
    "    print(\"All assumptions are met for the Z-test.\")\n",
    "\n",
    "    # Number of successes and observations\n",
    "    successes = [control_users_retention_1['retention_1'].sum(), treatment_users_retention_1['retention_1'].sum()]\n",
    "    n_obs = [n_control, n_treatment]\n",
    "\n",
    "    # One-tailed Z-test (check if treatment is worse than control)\n",
    "    z_stat, p_val = proportions_ztest(successes, n_obs, alternative='smaller')\n",
    "\n",
    "    # Results\n",
    "    print(f\"Z-statistic: {z_stat}\")\n",
    "    print(f\"P-value: {p_val}\")\n",
    "\n",
    "    if p_val < alpha:\n",
    "        print(\"Reject the null hypothesis: Retention is significantly lower in treatment.\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis: No significant decrease in retention.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae68273",
   "metadata": {
    "papermill": {
     "duration": 0.015942,
     "end_time": "2024-06-17T06:40:02.018073",
     "exception": false,
     "start_time": "2024-06-17T06:40:02.002131",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6.2 Perform A/B Test for Retention After 7 Days\n",
    "\n",
    "**Question:** Has player retention increased by 5% after 7 days?\n",
    "\n",
    "To test if 7-day retention has increased by 5% in the treatment group compared to the control group, we perform a **Z-test for proportions**.\n",
    "\n",
    "### Assumptions for the Z-Test\n",
    "\n",
    "1. **Independence**  \n",
    "   - Observations must be independent.  \n",
    "   - Ensured through random sampling and proper experimental design.  \n",
    "\n",
    "2. **Normality**  \n",
    "   - The sampling distribution of the sample proportion is approximately normal.  \n",
    "   - Holds when both $np$ and $n(1-p)$ are greater than 5.  \n",
    "\n",
    "3. **Large Sample Size**  \n",
    "   - The number of successes and failures in each group should be large enough for the normal approximation to the binomial distribution.  \n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Calculate the observed proportions of retention in both groups.  \n",
    "2. Perform a Z-test for proportions to compare retention rates.  \n",
    "3. Determine if the difference is statistically significant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c88141b",
   "metadata": {
    "papermill": {
     "duration": 0.015923,
     "end_time": "2024-06-17T06:40:02.050189",
     "exception": false,
     "start_time": "2024-06-17T06:40:02.034266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Method 1 First implementation approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9657c8d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:40:02.085398Z",
     "iopub.status.busy": "2024-06-17T06:40:02.085037Z",
     "iopub.status.idle": "2024-06-17T06:40:02.097088Z",
     "shell.execute_reply": "2024-06-17T06:40:02.095870Z"
    },
    "papermill": {
     "duration": 0.032806,
     "end_time": "2024-06-17T06:40:02.099556",
     "exception": false,
     "start_time": "2024-06-17T06:40:02.066750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# Define alpha\n",
    "alpha = 0.05\n",
    "\n",
    "# Observed proportions and sample sizes\n",
    "p_control_7 = control_users_retention_7['retention_7'].mean()\n",
    "p_treatment_7 = treatment_users_retention_7['retention_7'].mean()\n",
    "n_control_7 = len(control_users_retention_7)\n",
    "n_treatment_7 = len(treatment_users_retention_7)\n",
    "\n",
    "# Check Z-test assumptions\n",
    "assumptions_met = all([\n",
    "    n_control_7 * p_control_7 > 5,\n",
    "    n_control_7 * (1 - p_control_7) > 5,\n",
    "    n_treatment_7 * p_treatment_7 > 5,\n",
    "    n_treatment_7 * (1 - p_treatment_7) > 5\n",
    "])\n",
    "\n",
    "if not assumptions_met:\n",
    "    print(\"Z-test assumptions not met, cannot perform the test.\")\n",
    "else:\n",
    "    print(\"All assumptions are met for the Z-test.\")\n",
    "\n",
    "    # Number of successes and observations\n",
    "    successes = [treatment_users_retention_7['retention_7'].sum(), control_users_retention_7['retention_7'].sum()]\n",
    "    n_obs = [n_treatment_7, n_control_7]\n",
    "\n",
    "    # One-tailed Z-test (check if treatment is better than control)\n",
    "    z_stat, p_val = proportions_ztest(successes, n_obs, alternative='larger')\n",
    "\n",
    "    # Results\n",
    "    print(f\"Z-statistic: {z_stat}\")\n",
    "    print(f\"P-value: {p_val}\")\n",
    "\n",
    "    if p_val < alpha:\n",
    "        print(\"Reject the null hypothesis: Retention after 7 days has significantly increased in treatment.\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis: No significant increase in 7-day retention.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f961b9e",
   "metadata": {
    "papermill": {
     "duration": 0.016431,
     "end_time": "2024-06-17T06:40:02.132131",
     "exception": false,
     "start_time": "2024-06-17T06:40:02.115700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Method 1 Second implementation approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c80c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:40:02.166812Z",
     "iopub.status.busy": "2024-06-17T06:40:02.165841Z",
     "iopub.status.idle": "2024-06-17T06:40:02.177405Z",
     "shell.execute_reply": "2024-06-17T06:40:02.176233Z"
    },
    "papermill": {
     "duration": 0.03167,
     "end_time": "2024-06-17T06:40:02.180072",
     "exception": false,
     "start_time": "2024-06-17T06:40:02.148402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# Define alpha\n",
    "alpha = 0.05\n",
    "\n",
    "# Observed proportions and sample sizes\n",
    "p_control_7 = control_users_retention_7['retention_7'].mean()\n",
    "p_treatment_7 = treatment_users_retention_7['retention_7'].mean()\n",
    "n_control_7 = len(control_users_retention_7)\n",
    "n_treatment_7 = len(treatment_users_retention_7)\n",
    "\n",
    "# Check Z-test assumptions\n",
    "assumptions_met = all([\n",
    "    n_control_7 * p_control_7 > 5,\n",
    "    n_control_7 * (1 - p_control_7) > 5,\n",
    "    n_treatment_7 * p_treatment_7 > 5,\n",
    "    n_treatment_7 * (1 - p_treatment_7) > 5\n",
    "])\n",
    "\n",
    "if not assumptions_met:\n",
    "    print(\"Z-test assumptions not met, cannot perform the test.\")\n",
    "else:\n",
    "    print(\"All assumptions are met for the Z-test.\")\n",
    "\n",
    "    # Number of successes and observations\n",
    "    successes = [control_users_retention_7['retention_7'].sum(), treatment_users_retention_7['retention_7'].sum()]\n",
    "    n_obs = [n_control_7, n_treatment_7]\n",
    "\n",
    "    # One-tailed Z-test (check if treatment is worse than control)\n",
    "    z_stat, p_val = proportions_ztest(successes, n_obs, alternative='smaller')\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Z-statistic: {z_stat}\")\n",
    "    print(f\"P-value: {p_val}\")\n",
    "\n",
    "    if p_val < alpha:\n",
    "        print(\"Reject the null hypothesis: Retention is significantly lower in treatment.\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis: No significant decrease in retention.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e80d1a",
   "metadata": {
    "papermill": {
     "duration": 0.018969,
     "end_time": "2024-06-17T06:40:02.215218",
     "exception": false,
     "start_time": "2024-06-17T06:40:02.196249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6.3 Perform A/B Test for Sum of Game Rounds\n",
    "\n",
    "**Question:** Has the average number of game sessions increased by 5 sessions?\n",
    "\n",
    "To test if the average number of game sessions has increased by 5 sessions in the treatment group compared to the control group, we perform a **two-sample t-test**.\n",
    "\n",
    "### Assumptions for the T-Test\n",
    "\n",
    "1. **Independence**  \n",
    "   - Observations must be independent.  \n",
    "   - Ensured through random sampling and proper experimental design.  \n",
    "\n",
    "2. **Normality**  \n",
    "   - Samples are assumed to be drawn from normally distributed populations.  \n",
    "   - This assumption can be relaxed for large sample sizes due to the Central Limit Theorem.  \n",
    "\n",
    "3. **Equal Variances**  \n",
    "   - The t-test assumes equal variances between the two groups.  \n",
    "   - Can be formally tested using Levene’s test.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Calculate the means and standard deviations of the sum of game rounds in both groups.  \n",
    "2. Perform a two-sample t-test to compare the means.  \n",
    "3. Determine if the difference is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6ea0ac",
   "metadata": {
    "papermill": {
     "duration": 0.015998,
     "end_time": "2024-06-17T06:40:02.248270",
     "exception": false,
     "start_time": "2024-06-17T06:40:02.232272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Method 1 First implementation approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222cc3b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:40:02.283049Z",
     "iopub.status.busy": "2024-06-17T06:40:02.281886Z",
     "iopub.status.idle": "2024-06-17T06:40:02.297643Z",
     "shell.execute_reply": "2024-06-17T06:40:02.296354Z"
    },
    "papermill": {
     "duration": 0.035803,
     "end_time": "2024-06-17T06:40:02.300098",
     "exception": false,
     "start_time": "2024-06-17T06:40:02.264295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, levene\n",
    "\n",
    "# Define alpha\n",
    "alpha = 0.05\n",
    "\n",
    "# Calculate means and standard deviations\n",
    "mean_control = control_users_gamerounds['sum_gamerounds'].mean()\n",
    "std_control = control_users_gamerounds['sum_gamerounds'].std()\n",
    "mean_treatment = treatment_users_gamerounds['sum_gamerounds'].mean()\n",
    "std_treatment = treatment_users_gamerounds['sum_gamerounds'].std()\n",
    "\n",
    "print(f\"Control - Mean: {mean_control}, Std: {std_control}\")\n",
    "print(f\"Treatment - Mean: {mean_treatment}, Std: {std_treatment}\")\n",
    "\n",
    "# Levene's test for equality of variances\n",
    "_, p_levene = levene(control_users_gamerounds['sum_gamerounds'], treatment_users_gamerounds['sum_gamerounds'])\n",
    "equal_var = p_levene >= alpha\n",
    "print(\"Variances are equal.\" if equal_var else \"Variances are not equal; using Welch's t-test.\")\n",
    "\n",
    "# One-tailed t-test (check if treatment > control)\n",
    "t_stat, p_val = ttest_ind(\n",
    "    treatment_users_gamerounds['sum_gamerounds'], \n",
    "    control_users_gamerounds['sum_gamerounds'], \n",
    "    equal_var=equal_var, \n",
    "    alternative='greater'\n",
    ")\n",
    "\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_val}\")\n",
    "\n",
    "if p_val < alpha:\n",
    "    print(\"Reject the null hypothesis: Treatment group has significantly more game sessions.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant increase in game sessions in treatment group.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2657cfb9",
   "metadata": {
    "papermill": {
     "duration": 0.016581,
     "end_time": "2024-06-17T06:40:02.333300",
     "exception": false,
     "start_time": "2024-06-17T06:40:02.316719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Method 1 Second implementation approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0dd3b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T06:40:02.368222Z",
     "iopub.status.busy": "2024-06-17T06:40:02.367767Z",
     "iopub.status.idle": "2024-06-17T06:40:02.379809Z",
     "shell.execute_reply": "2024-06-17T06:40:02.378711Z"
    },
    "papermill": {
     "duration": 0.032588,
     "end_time": "2024-06-17T06:40:02.382571",
     "exception": false,
     "start_time": "2024-06-17T06:40:02.349983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, levene\n",
    "\n",
    "# Define alpha\n",
    "alpha = 0.05\n",
    "\n",
    "# Calculate means and standard deviations\n",
    "mean_control = control_users_gamerounds['sum_gamerounds'].mean()\n",
    "std_control = control_users_gamerounds['sum_gamerounds'].std()\n",
    "mean_treatment = treatment_users_gamerounds['sum_gamerounds'].mean()\n",
    "std_treatment = treatment_users_gamerounds['sum_gamerounds'].std()\n",
    "\n",
    "print(f\"Control - Mean: {mean_control}, Std: {std_control}\")\n",
    "print(f\"Treatment - Mean: {mean_treatment}, Std: {std_treatment}\")\n",
    "\n",
    "# Levene's test for equality of variances\n",
    "_, p_levene = levene(control_users_gamerounds['sum_gamerounds'], treatment_users_gamerounds['sum_gamerounds'])\n",
    "equal_var = p_levene >= alpha\n",
    "print(\"Variances are equal.\" if equal_var else \"Variances are not equal; using Welch's t-test.\")\n",
    "\n",
    "# One-tailed t-test (check if treatment > control)\n",
    "t_stat, p_val = ttest_ind(\n",
    "    control_users_gamerounds['sum_gamerounds'],\n",
    "    treatment_users_gamerounds['sum_gamerounds'],\n",
    "    equal_var=equal_var,\n",
    "    alternative='less'  # H0: control >= treatment; H1: control < treatment\n",
    ")\n",
    "\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_val}\")\n",
    "\n",
    "if p_val < alpha:\n",
    "    print(\"Reject the null hypothesis: Treatment group has significantly more game sessions than control.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant increase in treatment group game sessions.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a85261",
   "metadata": {},
   "source": [
    "# 7. Analyze the Test Results\n",
    "\n",
    "### Practical Significance\n",
    "\n",
    "Statistical significance alone does not ensure that an observed effect is meaningful in a real-world context. Practical significance evaluates whether the effect has tangible value. Consider the following:\n",
    "\n",
    "1. **Effect Size**  \n",
    "   - Quantifies the magnitude of the difference between control and treatment groups.  \n",
    "   - For retention rates: difference in proportions (e.g., 2% increase).  \n",
    "   - For sum of game rounds: difference in means (e.g., 5 additional sessions).\n",
    "\n",
    "2. **Real-World Impact**  \n",
    "   - Assess the practical implications of the observed effect:  \n",
    "     - A 2% increase in 1-day retention may boost short-term engagement and revenue.  \n",
    "     - A 5% increase in 7-day retention signals improved long-term engagement.  \n",
    "     - A 5-session increase per user indicates enhanced user experience.\n",
    "\n",
    "3. **Cost-Benefit Analysis**  \n",
    "   - Compare the cost of implementing the treatment with the potential benefits.  \n",
    "   - Consider development costs, marketing expenses, and potential revenue gains.\n",
    "\n",
    "### Reporting Findings\n",
    "\n",
    "1. **Summary of Results**  \n",
    "   - Summarize key findings for each A/B test: 1-day retention, 7-day retention, and sum of game rounds.\n",
    "\n",
    "2. **Statistical Analysis**  \n",
    "   - Present Z-statistics and p-values for retention tests, and T-statistics and p-values for game rounds.  \n",
    "   - Clearly indicate whether the null hypothesis is rejected for each test.\n",
    "\n",
    "3. **Practical Implications**  \n",
    "   - Discuss effect sizes and real-world impact.  \n",
    "   - Highlight benefits and costs associated with implementing the changes.\n",
    "\n",
    "4. **Visualizations**  \n",
    "   - Use bar charts, line graphs, or box plots to illustrate differences between control and treatment groups.  \n",
    "   - Visuals make results more accessible and understandable.\n",
    "\n",
    "5. **Recommendations**  \n",
    "   - Provide actionable recommendations: implement the treatment, conduct further testing, or explore alternatives.  \n",
    "   - Offer next steps based on the A/B test findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef46685d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5205512,
     "sourceId": 8682953,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.258694,
   "end_time": "2024-06-17T06:40:03.086440",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-17T06:39:50.827746",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
