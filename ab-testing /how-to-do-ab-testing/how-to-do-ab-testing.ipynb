{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Do A/B Testing\n",
    "\n",
    "## What is A/B Testing?\n",
    "\n",
    "A/B testing, or **split testing**, is an experiment where you split your audience to test variations and determine which performs better.  \n",
    "It is valuable because different audiences behave differently — what works for one company may not work for another.  \n",
    "\n",
    "**Continuous vs. Discrete Perspective:**  \n",
    "- **Continuous metrics**: measurable on a scale (e.g., time on page, revenue per user).  \n",
    "- **Discrete metrics**: countable events (e.g., clicks, signups, purchases).  \n",
    "\n",
    "Understanding your metric type is crucial because it determines the statistical method and sample size calculation.\n",
    "\n",
    "\n",
    "\n",
    "## How Does A/B Testing Work?\n",
    "\n",
    "You create two versions of content, changing only **one variable**, then show them to two similarly sized audiences.  \n",
    "Analyze which performs better over a sufficient period to draw accurate conclusions.\n",
    "\n",
    "![A/B Testing Explanation](img/a-b-testing-explanation.webp)\n",
    "\n",
    "### Example: User Experience Test\n",
    "- Version A: Sidebar CTA (**control**)  \n",
    "- Version B: Top-of-page CTA (**challenger**)  \n",
    "\n",
    "Compare performance among randomly selected, equally sized visitors using discrete metrics like click counts.\n",
    "\n",
    "### Example: Design Test\n",
    "- Version A: Red CTA button (**control**)  \n",
    "- Version B: Green CTA button (**challenger**)  \n",
    "\n",
    "Compare using **continuous metrics** like average time spent on page or scroll depth.\n",
    "\n",
    "\n",
    "\n",
    "## A/B Testing Goals\n",
    "\n",
    "- **Higher Conversion Rate** (discrete)  \n",
    "- **Increased Website Traffic** (discrete)  \n",
    "- **Lower Bounce Rate** (continuous)  \n",
    "- **Better Product Images** (continuous/discrete mix)  \n",
    "- **Lower Cart Abandonment** (discrete)\n",
    "\n",
    "\n",
    "\n",
    "## Designing an A/B Test\n",
    "\n",
    "1. **Select one variable** (independent variable)  \n",
    "2. **Identify your primary metric** (dependent variable, continuous or discrete)  \n",
    "3. **Create control and challenger versions**  \n",
    "4. **Split your audience randomly and equally**  \n",
    "5. **Calculate required sample size**  \n",
    "6. **Decide significance thresholds** ($\\alpha$, $\\beta$)  \n",
    "7. **Run only one test at a time**  \n",
    "\n",
    "### Sample Size Calculation\n",
    "\n",
    "- **For discrete (binary) metrics** like conversion rate:\n",
    "\n",
    "$$\n",
    "n = \\frac{2 \\cdot (Z_{\\alpha/2} + Z_\\beta)^2 \\cdot \\hat{p}(1-\\hat{p})}{\\Delta^2}\n",
    "$$\n",
    "\n",
    "- **For continuous metrics** like revenue per user:\n",
    "\n",
    "$$\n",
    "n = \\frac{2 \\cdot (Z_{\\alpha/2} + Z_\\beta)^2 \\cdot \\sigma^2}{\\Delta^2}\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $\\hat{p}$ = baseline conversion rate (discrete)  \n",
    "- $\\sigma^2$ = variance of the continuous metric  \n",
    "- $\\Delta$ = minimum detectable effect  \n",
    "- $Z_{\\alpha/2}, Z_\\beta$ = critical values for confidence and power  \n",
    "\n",
    "\n",
    "\n",
    "## During the A/B Test\n",
    "\n",
    "- Use a testing tool  \n",
    "- Test variations simultaneously  \n",
    "- Allow sufficient duration for statistical significance  \n",
    "- Collect qualitative user feedback  \n",
    "\n",
    "**Tip:** Continuous monitoring is easier for continuous metrics (e.g., revenue), but discrete metrics (e.g., signups) may need longer periods for enough events.\n",
    "\n",
    "\n",
    "\n",
    "## After the A/B Test\n",
    "\n",
    "- Focus on your goal metric  \n",
    "- Compare conversion rates:\n",
    "\n",
    "$$\n",
    "SE = \\sqrt{\\frac{p_c (1-p_c)}{n_c} + \\frac{p_t (1-p_t)}{n_t}} \\quad \\text{(discrete)}\n",
    "$$\n",
    "\n",
    "- Confidence interval (95%):\n",
    "\n",
    "$$\n",
    "(p_t - p_c) \\pm Z_{0.975} \\cdot SE\n",
    "$$\n",
    "\n",
    "- For continuous metrics, use:\n",
    "\n",
    "$$\n",
    "SE = \\sqrt{\\frac{s_c^2}{n_c} + \\frac{s_t^2}{n_t}}\n",
    "$$\n",
    "\n",
    "- Take action based on results  \n",
    "- Plan your next test  \n",
    "\n",
    "\n",
    "\n",
    "## Advanced A/B Testing Concepts with Practical Examples\n",
    "\n",
    "### 1. Multi-Armed Bandit Testing\n",
    "- **Concept:** Dynamically allocate traffic to better-performing variants to maximize expected reward.\n",
    "- **Metrics:** Discrete (clicks, signups), Continuous (revenue, time on site).\n",
    "- **Thompson Sampling Example (Discrete):**\n",
    "\n",
    "$$\n",
    "\\theta_i \\sim \\text{Beta}(\\alpha_i + \\text{successes}_i, \\beta_i + \\text{failures}_i)\n",
    "$$\n",
    "\n",
    "- **Traffic Allocation Rule:** Choose variant with highest sampled $\\theta_i$ for each new user.\n",
    "- **Expected Regret Formula:**\n",
    "\n",
    "$$\n",
    "R(T) = \\sum_{t=1}^{T} (\\mu^* - \\mu_{a_t})\n",
    "$$\n",
    "\n",
    "where:  \n",
    "$\\mu^*$ = mean reward of best variant, $\\mu_{a_t}$ = mean reward of chosen variant at time $t$.\n",
    "\n",
    "**Practical Example:**  \n",
    "- Website has 3 headline variants.  \n",
    "- Initial prior: $\\text{Beta}(1,1)$ for each.  \n",
    "- Users arrive sequentially; Thompson Sampling updates $\\alpha, \\beta$ for each variant based on clicks.  \n",
    "- Over time, most traffic is sent to the variant performing best while still exploring others.\n",
    "\n",
    "### 2. Sequential Testing\n",
    "- **Concept:** Continuous monitoring without inflating Type I error if done correctly.\n",
    "- **Adjusted significance threshold:**\n",
    "\n",
    "$$\n",
    "\\alpha(t) = \\alpha \\cdot \\frac{t}{T}\n",
    "$$\n",
    "\n",
    "- **Sequential Probability Ratio Test (SPRT):**  \n",
    "\n",
    "$$\n",
    "\\Lambda_t = \\frac{L(\\text{data}_t \\mid H_1)}{L(\\text{data}_t \\mid H_0)}\n",
    "$$\n",
    "\n",
    "Stop rules:  \n",
    "- Accept $H_1$ if $\\Lambda_t > B$  \n",
    "- Accept $H_0$ if $\\Lambda_t < A$  \n",
    "- Continue sampling otherwise  \n",
    "\n",
    "**Practical Example:**  \n",
    "- Email click-through test (variant A vs B).  \n",
    "- Check results daily.  \n",
    "- SPRT thresholds set to stop early if one variant clearly outperforms the other, saving time and resources.\n",
    "\n",
    "### 3. Bayesian A/B Testing\n",
    "- **Concept:** Updates posterior distribution as new data arrives. Provides probability-based decision-making.\n",
    "- **Posterior:**\n",
    "\n",
    "$$\n",
    "p(\\theta \\mid \\text{data}) \\propto p(\\text{data} \\mid \\theta) \\cdot p(\\theta)\n",
    "$$\n",
    "\n",
    "- **Credible Interval:**  \n",
    "95% credible interval for a metric $\\theta$:\n",
    "\n",
    "$$\n",
    "\\text{CI}_{95\\%} = [\\theta_{\\text{lower}}, \\theta_{\\text{upper}}] \\quad \\text{such that} \\quad P(\\theta \\in \\text{CI}_{95\\%} \\mid \\text{data}) = 0.95\n",
    "$$\n",
    "\n",
    "**Practical Example:**  \n",
    "- A/B test for revenue per user (continuous metric).  \n",
    "- Prior: $\\theta \\sim \\text{Normal}(50, 20^2)$  \n",
    "- Data collected: 200 users per variant.  \n",
    "- Posterior shows $P(\\text{Variant B > Variant A}) = 0.92$, giving strong evidence to roll out B.\n",
    "\n",
    "### 4. Metric Selection & Pitfalls\n",
    "- **Continuous metrics:** revenue, session duration → detect subtle improvements.\n",
    "- **Discrete metrics:** signups, purchases → clear actions.\n",
    "- **Pitfalls:**\n",
    "  - Multiple comparisons inflate Type I error.\n",
    "  - Peeking at data without correction biases results.\n",
    "  \n",
    "**Practical Example:**  \n",
    "- Testing 4 product layouts.  \n",
    "- Tracking both average revenue (continuous) and purchase count (discrete).  \n",
    "- Adjust significance using Bonferroni correction when comparing multiple variants.\n",
    "\n",
    "### 5. Practical Considerations\n",
    "- **Segmentation:** device, geography, traffic source.\n",
    "- **Duration:** ensure enough users for reliable results (consider both discrete & continuous metrics).\n",
    "- **Randomization:** prevent allocation bias.\n",
    "- **External confounders:** holidays, marketing campaigns, or outages.\n",
    "\n",
    "**Practical Example:**  \n",
    "- Mobile app A/B test with two variants of onboarding flow.  \n",
    "- Segment by OS (iOS/Android), traffic source (organic/paid).  \n",
    "- Run for 4 weeks to capture weekday/weekend usage patterns.  \n",
    "- Check metrics separately for each segment to detect interaction effects.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## How to Read Results\n",
    "\n",
    "1. Verify statistical significance  \n",
    "2. Compute confidence intervals for discrete or continuous metrics  \n",
    "3. Examine heterogeneous effects  \n",
    "4. Assess practical significance ($\\Delta$)  \n",
    "5. Decide next steps: rollout, iterate, or discard  \n",
    "\n",
    "\n",
    "# A/B Testing Decision Flowchart\n",
    "```\n",
    "Start\n",
    "  │\n",
    "  ▼\n",
    "Select Metric\n",
    "  │\n",
    "  ├─► Is it Discrete? (clicks, signups, purchases)\n",
    "  │       │\n",
    "  │       ├─► Yes \n",
    "  │       │     │\n",
    "  │       │     ├─► Use standard A/B test for proportions\n",
    "  │       │     ├─► Optional: Multi-Armed Bandit for faster allocation\n",
    "  │       │     └─► Sample size via binary formula\n",
    "  │       │\n",
    "  │       └─► No (continuous: time on page, revenue)\n",
    "  │             │\n",
    "  │             ├─► Use t-test / ANOVA\n",
    "  │             ├─► Optional: Sequential or Bayesian testing\n",
    "  │             └─► Sample size via variance-based formula\n",
    "  │\n",
    "  ▼\n",
    "Randomly split audience\n",
    "  │\n",
    "  ▼\n",
    "Run test (ensure sufficient duration)\n",
    "  │\n",
    "  ▼\n",
    "Analyze Results\n",
    "  │\n",
    "  ├─► Statistically Significant?\n",
    "  │       │\n",
    "  │       ├─► Yes ─► Implement winning variant\n",
    "  │       │\n",
    "  │       └─► No ─► Iterate or increase sample size\n",
    "  │\n",
    "  ▼\n",
    "End\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
